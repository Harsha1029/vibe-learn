conceptLinks:
  Helmfile: "#lesson-helmfile----declarative-release-management"
  CI/CD with Helm: "#lesson-cicd-with-helm"
  Chart Versioning: "#lesson-chart-versioning"
  Managing Secrets in Helm: "#lesson-managing-secrets-in-helm"
  Release Management Best Practices: "#lesson-release-management-best-practices"
  Upgrading and Rollback Strategies: "#lesson-upgrading-and-rollback-strategies"
  Chart Testing: "#lesson-chart-testing"
  Multi-Cluster Deployments: "#lesson-multi-cluster-deployments"
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: Helmfile
      variants:
        - id: v1
          title: Basic Helmfile with Two Releases
          description: >-
            Write a <code>helmfile.yaml</code> that declares two releases: <code>nginx</code> using the
            <code>bitnami/nginx</code> chart version <code>15.14.0</code> in namespace <code>web</code>, and
            <code>redis</code> using <code>bitnami/redis</code> version <code>18.6.1</code> in namespace <code>cache</code>.
            Include the bitnami repository definition.
          hints:
            - "Start with a <code>repositories</code> block listing the bitnami repo URL."
            - "Each release needs <code>name</code>, <code>namespace</code>, <code>chart</code>, and <code>version</code>."
            - "The bitnami repo URL is <code>https://charts.bitnami.com/bitnami</code>."
          solution: |-
            repositories:
              - name: bitnami
                url: https://charts.bitnami.com/bitnami

            releases:
              - name: nginx
                namespace: web
                chart: bitnami/nginx
                version: 15.14.0

              - name: redis
                namespace: cache
                chart: bitnami/redis
                version: 18.6.1
          annotations:
            - type: idiom
              label: Helmfile Releases
              text: >-
                Each release in helmfile.yaml maps to one Helm release. The chart field uses the
                repository-name/chart-name format.
        - id: v2
          title: Helmfile with helmDefaults
          description: >-
            Write a <code>helmfile.yaml</code> that sets <code>helmDefaults</code> with <code>wait: true</code>,
            <code>timeout: 300</code>, and <code>createNamespace: true</code>. Add a single release for
            <code>prometheus</code> using the <code>prometheus-community/kube-prometheus-stack</code> chart version
            <code>56.6.2</code> in namespace <code>monitoring</code>.
          hints:
            - "<code>helmDefaults</code> applies default flags to all releases in the file."
            - "You still need a <code>repositories</code> block for the prometheus-community repo."
          solution: |-
            repositories:
              - name: prometheus-community
                url: https://prometheus-community.github.io/helm-charts

            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true

            releases:
              - name: prometheus
                namespace: monitoring
                chart: prometheus-community/kube-prometheus-stack
                version: 56.6.2
          annotations:
            - type: idiom
              label: helmDefaults
              text: >-
                helmDefaults applies settings to every release. Common defaults include wait, timeout,
                createNamespace, and historyMax.
        - id: v3
          title: Helmfile with Values Files
          description: >-
            Write a <code>helmfile.yaml</code> with a release named <code>api</code> using a local chart at
            <code>./charts/api</code> version <code>2.5.0</code> in namespace <code>app</code>. The release should load
            two values files: <code>values/api-common.yaml</code> and <code>values/api-prod.yaml</code>.
          hints:
            - "Local charts use a relative path like <code>./charts/api</code> instead of a repo/chart reference."
            - "The <code>values</code> field takes a list of file paths."
          solution: |-
            releases:
              - name: api
                namespace: app
                chart: ./charts/api
                version: 2.5.0
                values:
                  - values/api-common.yaml
                  - values/api-prod.yaml
          annotations:
            - type: idiom
              label: Multiple Values Files
              text: >-
                Values files are merged in order. Later files override earlier ones. Use common + environment-specific
                files for layered configuration.
        - id: v4
          title: Helmfile with Environments
          description: >-
            Write a <code>helmfile.yaml</code> with three environments: <code>dev</code>, <code>staging</code>, and
            <code>prod</code>. Each environment should load its own values file from the <code>environments/</code>
            directory. Add a single release named <code>api</code> that uses the environment name in the namespace
            (e.g., <code>api-dev</code>).
          hints:
            - "Use the <code>environments</code> block at the top of the helmfile."
            - "Reference the environment name with <code>{{ .Environment.Name }}</code> in templates."
          solution: |-
            environments:
              dev:
                values:
                  - environments/dev.yaml
              staging:
                values:
                  - environments/staging.yaml
              prod:
                values:
                  - environments/prod.yaml

            releases:
              - name: api
                namespace: api-{{ .Environment.Name }}
                chart: ./charts/api
                values:
                  - values/api-common.yaml
                  - values/api-{{ .Environment.Name }}.yaml
          annotations:
            - type: idiom
              label: Helmfile Environments
              text: >-
                Use helmfile -e prod apply to deploy for a specific environment. The .Environment.Name template variable
                lets you dynamically select namespaces and values files.
        - id: v5
          title: Helmfile with Inline Values
          description: >-
            Write a <code>helmfile.yaml</code> with a release named <code>nginx</code> using
            <code>bitnami/nginx</code> version <code>15.14.0</code>. Instead of a values file, set
            <code>replicaCount: 3</code> and <code>service.type: ClusterIP</code> using inline values.
          hints:
            - "Inline values are specified directly under the <code>values</code> key as YAML objects in a list."
            - "Each list item under <code>values</code> can be either a file path or an inline YAML mapping."
          solution: |-
            repositories:
              - name: bitnami
                url: https://charts.bitnami.com/bitnami

            releases:
              - name: nginx
                namespace: web
                chart: bitnami/nginx
                version: 15.14.0
                values:
                  - replicaCount: 3
                  - service:
                      type: ClusterIP
          annotations:
            - type: idiom
              label: Inline Values
              text: >-
                Inline values are useful for simple overrides. For complex configurations, use external values files
                for readability.
        - id: v6
          title: Helmfile with set Overrides
          description: >-
            Write a <code>helmfile.yaml</code> release for <code>api</code> that uses a values file
            <code>values/api.yaml</code> but overrides <code>replicaCount</code> using the <code>set</code> field with a
            value from the environment (e.g., <code>{{ .Environment.Values.replicas }}</code>).
          hints:
            - "The <code>set</code> field takes a list of name/value pairs, similar to <code>helm install --set</code>."
            - "You can use Go template expressions in the <code>value</code> field."
          solution: |-
            environments:
              dev:
                values:
                  - environments/dev.yaml
              prod:
                values:
                  - environments/prod.yaml

            releases:
              - name: api
                namespace: app
                chart: ./charts/api
                values:
                  - values/api.yaml
                set:
                  - name: replicaCount
                    value: {{ .Environment.Values.replicas }}
          annotations:
            - type: idiom
              label: set Overrides
              text: >-
                The set field is like helm --set. It takes priority over values files. Useful for injecting
                environment-specific values from helmfile environments.
        - id: v7
          title: Helmfile Targeting a Single Release
          description: >-
            You have a helmfile with releases named <code>api</code>, <code>redis</code>, and <code>nginx</code>. Write
            the <code>helmfile</code> command to apply changes only to the <code>api</code> release.
          hints:
            - "Use the <code>-l</code> (label selector) flag to target a specific release by name."
          solution: |-
            helmfile -l name=api apply
          annotations:
            - type: idiom
              label: Release Selectors
              text: >-
                Use helmfile -l name=release-name to target a single release. You can also use custom labels defined
                in the release definition.
        - id: v8
          title: Helmfile sync vs apply
          description: >-
            Explain the difference between <code>helmfile sync</code> and <code>helmfile apply</code>. Which one should
            you use in CI/CD and why?
          hints:
            - "<code>helmfile sync</code> always upgrades every release, even if nothing changed."
            - "<code>helmfile apply</code> runs <code>diff</code> first, then only upgrades releases that changed."
          solution: |-
            # helmfile sync — always upgrades all releases (even if unchanged)
            helmfile sync

            # helmfile apply — diffs first, only upgrades changed releases
            helmfile apply

            # Use helmfile apply in CI/CD because:
            # 1. It's idempotent — running it twice does nothing the second time
            # 2. It's faster — unchanged releases are skipped
            # 3. It's safer — no unnecessary upgrades that could introduce drift
          annotations:
            - type: idiom
              label: helmfile apply
              text: >-
                helmfile apply is the recommended command for CI/CD. It requires the helm-diff plugin and only
                touches releases that actually changed.
        - id: v9
          title: Helmfile with historyMax
          description: >-
            Write a <code>helmfile.yaml</code> with <code>helmDefaults</code> that limits release history to 10 revisions.
            Include a release named <code>api</code> using chart <code>./charts/api</code> version <code>2.5.0</code>.
          hints:
            - "Use <code>historyMax</code> in <code>helmDefaults</code> to set <code>--history-max</code> for all releases."
          solution: |-
            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true
              historyMax: 10

            releases:
              - name: api
                namespace: app
                chart: ./charts/api
                version: 2.5.0
          annotations:
            - type: gotcha
              label: History Bloat
              text: >-
                Every helm upgrade creates a new revision stored in etcd. Without historyMax, old revisions accumulate
                and consume cluster storage. Always set this in production.
        - id: v10
          title: Helmfile destroy
          description: >-
            You have deployed releases via helmfile and need to tear down the entire environment. Write the command to
            uninstall all releases declared in the helmfile, and the command to target only the <code>staging</code>
            environment.
          hints:
            - "<code>helmfile destroy</code> uninstalls all releases in the helmfile."
            - "Use <code>-e</code> to target a specific environment."
          solution: |-
            # Uninstall all releases
            helmfile destroy

            # Uninstall only the staging environment
            helmfile -e staging destroy
          annotations:
            - type: idiom
              label: helmfile destroy
              text: >-
                helmfile destroy runs helm uninstall for every release. It does not delete namespaces — you must
                clean those up separately with kubectl delete namespace.
        - id: v11
          title: Helmfile with Multiple Repositories
          description: >-
            Write a <code>helmfile.yaml</code> that defines three repositories: <code>bitnami</code>,
            <code>ingress-nginx</code>, and <code>prometheus-community</code>. Add one release from each repository: nginx
            ingress controller, a bitnami PostgreSQL instance, and kube-prometheus-stack.
          hints:
            - "Each repository needs a <code>name</code> and <code>url</code>."
            - "The ingress-nginx repo URL is <code>https://kubernetes.github.io/ingress-nginx</code>."
          solution: |-
            repositories:
              - name: bitnami
                url: https://charts.bitnami.com/bitnami
              - name: ingress-nginx
                url: https://kubernetes.github.io/ingress-nginx
              - name: prometheus-community
                url: https://prometheus-community.github.io/helm-charts

            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true

            releases:
              - name: nginx-ingress
                namespace: ingress-system
                chart: ingress-nginx/ingress-nginx
                version: 4.9.1

              - name: postgresql
                namespace: database
                chart: bitnami/postgresql
                version: 14.0.5

              - name: monitoring
                namespace: monitoring
                chart: prometheus-community/kube-prometheus-stack
                version: 56.6.2
          annotations:
            - type: pattern
              label: Multi-Repository Helmfile
              text: >-
                Production helmfiles typically reference multiple chart repositories. Always pin chart versions to
                ensure reproducible deployments.
    - id: warmup_2
      concept: CI/CD with Helm
      variants:
        - id: v1
          title: Idempotent Deploy Command
          description: >-
            Write the <code>helm</code> command to deploy a release named <code>api</code> from chart
            <code>./charts/api</code> in namespace <code>app</code>. The command should be idempotent (works whether
            the release exists or not), wait for Pods to be ready, and auto-rollback on failure with a 5-minute timeout.
          hints:
            - "<code>--install</code> makes <code>helm upgrade</code> idempotent."
            - "<code>--wait</code> blocks until Pods are ready. <code>--atomic</code> auto-rollbacks on failure."
            - "Always pair <code>--wait</code> with <code>--atomic</code> in CI/CD."
          solution: |-
            helm upgrade --install api ./charts/api \
              --namespace app \
              --values values/prod.yaml \
              --wait \
              --timeout 5m \
              --atomic
          annotations:
            - type: idiom
              label: upgrade --install
              text: >-
                helm upgrade --install is the standard CI/CD deploy command. It creates the release on first run
                and upgrades it on subsequent runs.
            - type: gotcha
              label: --wait without --atomic
              text: >-
                Using --wait without --atomic will fail the pipeline if Pods don't become ready, but leaves the
                broken release deployed. Always use both together.
        - id: v2
          title: helm diff Preview
          description: >-
            Write the <code>helm diff</code> command to preview what would change if you upgraded the <code>api</code>
            release in namespace <code>app</code> using chart <code>./charts/api</code> with values from
            <code>values/prod.yaml</code>.
          hints:
            - "<code>helm diff upgrade</code> shows what would change without applying."
            - "It requires the helm-diff plugin to be installed."
          solution: |-
            helm diff upgrade api ./charts/api \
              --namespace app \
              --values values/prod.yaml
          annotations:
            - type: idiom
              label: helm-diff Plugin
              text: >-
                helm diff shows a colored diff of what would change. Essential for code review in pull requests and
                CI safety checks.
        - id: v3
          title: helm lint Command
          description: >-
            Write the <code>helm lint</code> command to validate a chart at <code>./charts/api</code> using production
            values from <code>values/prod.yaml</code>.
          hints:
            - "<code>helm lint</code> checks a chart for possible issues and best practice violations."
            - "Pass values with <code>--values</code> to lint with specific configurations."
          solution: |-
            helm lint ./charts/api --values values/prod.yaml
          annotations:
            - type: idiom
              label: helm lint
              text: >-
                helm lint is the first CI step. It catches missing required fields, invalid YAML, and template errors
                before any deployment attempt.
        - id: v4
          title: helm template with Dry Run
          description: >-
            Write the commands to render the <code>api</code> chart templates locally and then validate the output
            against the Kubernetes API schema using <code>kubectl --dry-run=client</code>.
          hints:
            - "<code>helm template</code> renders templates to stdout without contacting a cluster."
            - "Pipe the output to <code>kubectl apply --dry-run=client -f -</code> for schema validation."
          solution: |-
            helm template api ./charts/api \
              --values values/prod.yaml \
              | kubectl apply --dry-run=client -f -
          annotations:
            - type: idiom
              label: Template + Dry Run
              text: >-
                This two-step validation catches both template errors (helm template) and Kubernetes schema violations
                (kubectl dry-run) without needing cluster access.
        - id: v5
          title: helm test Command
          description: >-
            After deploying the <code>api</code> release in namespace <code>app</code>, write the command to run the
            chart's test suite. Then write the command to view the test Pod logs if a test fails.
          hints:
            - "<code>helm test</code> runs Pods annotated with <code>helm.sh/hook: test</code>."
            - "Use <code>--logs</code> to see test Pod output directly."
          solution: |-
            # Run chart tests
            helm test api -n app

            # Run tests and show logs on failure
            helm test api -n app --logs
          annotations:
            - type: idiom
              label: helm test
              text: >-
                Chart tests are Pods annotated with helm.sh/hook: test. They run after install/upgrade to verify the
                release is working. Use them in CI after deploy.
        - id: v6
          title: CI Pipeline Lint-Template-Diff-Deploy
          description: >-
            Write the four <code>helm</code> commands that form a complete CI/CD pipeline for the <code>api</code> chart:
            (1) lint, (2) template and validate, (3) diff against live, (4) deploy with safety flags. Use namespace
            <code>app</code> and values file <code>values/prod.yaml</code>.
          hints:
            - "The four steps in order: lint, template+dry-run, diff, upgrade --install."
            - "Each step catches different classes of errors before reaching the cluster."
          solution: |-
            # Step 1: Lint
            helm lint ./charts/api --values values/prod.yaml

            # Step 2: Template and validate
            helm template api ./charts/api --values values/prod.yaml \
              | kubectl apply --dry-run=client -f -

            # Step 3: Diff (preview changes)
            helm diff upgrade api ./charts/api \
              --namespace app \
              --values values/prod.yaml

            # Step 4: Deploy
            helm upgrade --install api ./charts/api \
              --namespace app \
              --create-namespace \
              --values values/prod.yaml \
              --wait \
              --timeout 5m \
              --atomic
          annotations:
            - type: pattern
              label: CI Pipeline Steps
              text: >-
                Lint catches syntax errors. Template catches rendering errors. Diff shows what will change.
                Deploy with --atomic ensures safe rollback. Each layer catches different issues.
        - id: v7
          title: Install helm-diff Plugin
          description: >-
            Write the command to install the <code>helm-diff</code> plugin. Then write the command to list all installed
            Helm plugins.
          hints:
            - "Use <code>helm plugin install</code> with the GitHub repository URL."
            - "Use <code>helm plugin list</code> to see installed plugins."
          solution: |-
            # Install helm-diff
            helm plugin install https://github.com/databus23/helm-diff

            # List installed plugins
            helm plugin list
          annotations:
            - type: idiom
              label: Helm Plugins
              text: >-
                Helm plugins extend the CLI with commands like diff, secrets, and unittest. Install from GitHub URLs
                and manage with helm plugin list/update/uninstall.
        - id: v8
          title: Deploy with --create-namespace
          description: >-
            Write the <code>helm</code> command to deploy a release named <code>monitoring</code> using
            <code>prometheus-community/kube-prometheus-stack</code> version <code>56.6.2</code> into namespace
            <code>monitoring</code>. The namespace may not exist yet. Include wait, timeout, and atomic flags.
          hints:
            - "Use <code>--create-namespace</code> to create the namespace if it does not exist."
            - "Always pair <code>--version</code> to pin the chart version."
          solution: |-
            helm upgrade --install monitoring \
              prometheus-community/kube-prometheus-stack \
              --version 56.6.2 \
              --namespace monitoring \
              --create-namespace \
              --wait \
              --timeout 10m \
              --atomic
          annotations:
            - type: idiom
              label: --create-namespace
              text: >-
                The --create-namespace flag creates the target namespace if it doesn't exist. Without it, Helm fails
                if the namespace is missing. Essential for first-time deployments.
        - id: v9
          title: Server-Side Dry Run
          description: >-
            Write the commands to render the <code>api</code> chart and validate it with server-side dry run (which catches
            more issues than client-side). Explain when you would use server-side vs client-side dry run.
          hints:
            - "<code>--dry-run=server</code> sends the manifests to the API server for validation without applying."
            - "Server-side catches issues like invalid field values and admission webhook rejections."
          solution: |-
            # Server-side dry run — validates against the actual cluster API
            helm template api ./charts/api --values values/prod.yaml \
              | kubectl apply --dry-run=server -f -

            # Client-side dry run — validates against local schema only
            helm template api ./charts/api --values values/prod.yaml \
              | kubectl apply --dry-run=client -f -

            # Use server-side when you have cluster access (catches more errors).
            # Use client-side in early CI stages without cluster credentials.
          annotations:
            - type: idiom
              label: Server vs Client Dry Run
              text: >-
                Server-side dry run validates against admission webhooks, CRD schemas, and real API validation.
                Client-side only checks against the local OpenAPI schema.
        - id: v10
          title: ct lint and install
          description: >-
            Write the <code>ct</code> (chart-testing) commands to lint all changed charts against the <code>main</code>
            branch, then install and test those changed charts.
          hints:
            - "<code>ct lint</code> lints charts that changed relative to the target branch."
            - "<code>ct install</code> installs changed charts and runs their test suites."
          solution: |-
            # Lint changed charts
            ct lint --target-branch main

            # Install and test changed charts
            ct install --target-branch main
          annotations:
            - type: idiom
              label: chart-testing (ct)
              text: >-
                The ct tool detects which charts changed compared to a target branch and runs lint/install/test
                only on those charts. Perfect for monorepos with multiple charts.
    - id: warmup_3
      concept: Chart Versioning
      variants:
        - id: v1
          title: Chart Version vs appVersion
          description: >-
            Given a <code>Chart.yaml</code> with <code>version: 1.3.0</code> and <code>appVersion: "2.8.1"</code>,
            explain what each field tracks. You changed a template to add a new optional values field. Which version
            do you bump and to what?
          hints:
            - "<code>version</code> tracks the chart packaging — templates, helpers, structure."
            - "<code>appVersion</code> tracks the application inside the chart — the container image."
            - "Adding a new optional values field is backward-compatible — it's a minor bump."
          solution: |-
            # version: tracks the chart itself (templates, defaults, structure)
            # appVersion: tracks the application the chart deploys (container image)

            # Adding a new optional values field is a MINOR change:
            # version: 1.3.0 -> 1.4.0
            # appVersion stays at "2.8.1" (app did not change)

            apiVersion: v2
            name: api
            version: 1.4.0
            appVersion: "2.8.1"
          annotations:
            - type: idiom
              label: version vs appVersion
              text: >-
                Chart version and appVersion are independent. You can bump the chart version without changing the
                app version (template changes) or vice versa (new image tag).
        - id: v2
          title: SemVer Major Bump
          description: >-
            Your chart at version <code>1.5.2</code> renames the values key <code>database.host</code> to
            <code>db.hostname</code>. What is the correct new version number and why?
          hints:
            - "Renaming a values key breaks existing values files that use the old key."
            - "Breaking changes require a MAJOR version bump."
          solution: |-
            # Renaming database.host to db.hostname is a BREAKING change.
            # Existing users' values files will stop working.
            # Correct: MAJOR bump from 1.5.2 to 2.0.0

            apiVersion: v2
            name: api
            version: 2.0.0
            appVersion: "2.8.1"
          annotations:
            - type: gotcha
              label: Breaking Changes
              text: >-
                Renaming or removing values keys, changing template structure, or changing default behavior
                are all breaking changes that require a MAJOR bump.
        - id: v3
          title: SemVer Patch Bump
          description: >-
            Your chart at version <code>2.1.0</code> has a bug: the readiness probe path was hardcoded as
            <code>/health</code> instead of using <code>.Values.readinessProbe.path</code>. You fix the template. What is
            the correct new version?
          hints:
            - "A bug fix with no new features is a PATCH bump."
            - "The fix doesn't change the API or add functionality — it corrects existing behavior."
          solution: |-
            # Fixing a template bug is a PATCH change.
            # No new features, no breaking changes — just a correction.
            # Correct: PATCH bump from 2.1.0 to 2.1.1

            apiVersion: v2
            name: api
            version: 2.1.1
            appVersion: "2.8.1"
          annotations:
            - type: idiom
              label: Patch Bumps
              text: >-
                Patch versions fix bugs without changing features or breaking compatibility. Users should always
                be safe upgrading to a new patch version.
        - id: v4
          title: Push Chart to OCI Registry
          description: >-
            Write the commands to package the chart at <code>./charts/api</code> and push it to the OCI registry
            <code>registry.example.com/charts</code>. Include the login step.
          hints:
            - "Use <code>helm package</code> to create the .tgz archive."
            - "Use <code>helm push</code> with the <code>oci://</code> prefix."
          solution: |-
            # Log in to the registry
            helm registry login registry.example.com \
              --username myuser \
              --password-stdin <<< "$REGISTRY_PASSWORD"

            # Package the chart
            helm package ./charts/api

            # Push to OCI registry
            helm push api-2.5.0.tgz oci://registry.example.com/charts
          annotations:
            - type: idiom
              label: OCI Registries
              text: >-
                OCI registries store charts alongside container images. Use the oci:// prefix with helm push, pull,
                and install. Supports ECR, GCR, ACR, GHCR, and Docker Hub.
        - id: v5
          title: Pull Chart from OCI Registry
          description: >-
            Write the commands to pull chart version <code>1.3.0</code> of the <code>api</code> chart from
            <code>oci://registry.example.com/charts</code>, and then install it directly from the registry as release
            <code>api</code> in namespace <code>app</code>.
          hints:
            - "Use <code>helm pull</code> with <code>--version</code> to download a specific version."
            - "Use <code>helm install</code> with the full <code>oci://</code> URL to install directly."
          solution: |-
            # Pull chart to local directory
            helm pull oci://registry.example.com/charts/api --version 1.3.0

            # Or install directly from the registry
            helm install api oci://registry.example.com/charts/api \
              --version 1.3.0 \
              --namespace app
          annotations:
            - type: idiom
              label: helm pull
              text: >-
                helm pull downloads a chart archive locally. helm install with an oci:// URL installs directly
                from the registry without downloading first.
        - id: v6
          title: CI Publishing Workflow
          description: >-
            Write a CI script that extracts the chart version from <code>charts/api/Chart.yaml</code>, packages the chart,
            and pushes it to an OCI registry.
          hints:
            - "Use <code>grep</code> and <code>awk</code> to extract the version from Chart.yaml."
            - "The version line looks like <code>version: 1.3.0</code>."
          solution: |-
            # Extract version from Chart.yaml
            CHART_VERSION=$(grep '^version:' charts/api/Chart.yaml | awk '{print $2}')

            # Package the chart
            helm package ./charts/api

            # Push to OCI registry
            helm push "api-${CHART_VERSION}.tgz" oci://registry.example.com/charts

            echo "Published api chart version ${CHART_VERSION}"
          annotations:
            - type: pattern
              label: CI Chart Publishing
              text: >-
                Automate chart publishing in CI after merging chart changes. Extract the version from Chart.yaml
                to build the correct .tgz filename for helm push.
        - id: v7
          title: Bump appVersion Only
          description: >-
            The application team releases a new container image <code>v3.0.0</code> but the chart templates have not
            changed. The current chart is <code>version: 1.4.0</code>, <code>appVersion: "2.9.0"</code>. Write the
            updated <code>Chart.yaml</code>.
          hints:
            - "Only the <code>appVersion</code> changes — the chart templates are the same."
            - "Updating appVersion alone still requires a chart version bump (at least patch) to signal the change."
          solution: |-
            apiVersion: v2
            name: api
            version: 1.4.1
            appVersion: "3.0.0"

            # version bumped from 1.4.0 to 1.4.1 (patch)
            # because even though templates didn't change,
            # the chart package is different (new appVersion).
            # appVersion updated from "2.9.0" to "3.0.0"
          annotations:
            - type: gotcha
              label: appVersion Change
              text: >-
                Even when only appVersion changes, bump the chart version (at least patch) so the chart registry
                shows a new version. Same chart version with different content causes confusion.
        - id: v8
          title: Adding an Optional Value
          description: >-
            Your chart at version <code>3.2.1</code> adds a new optional value <code>podDisruptionBudget.enabled</code>
            (defaults to <code>false</code>). Existing users are unaffected. What is the correct version bump?
          hints:
            - "New optional features that don't break existing users are MINOR bumps."
            - "The default of false means existing deployments behave identically."
          solution: |-
            # New optional feature (backward-compatible) = MINOR bump
            # From 3.2.1 to 3.3.0

            apiVersion: v2
            name: api
            version: 3.3.0
            appVersion: "3.0.0"
          annotations:
            - type: idiom
              label: Minor Bumps
              text: >-
                New optional values, new templates that are disabled by default, and new helper functions are
                all MINOR changes. Existing values files continue to work without modification.
        - id: v9
          title: Version Pinning in helmfile
          description: >-
            Write a <code>helmfile.yaml</code> snippet showing the correct way to pin chart versions for two releases.
            Then show the incorrect way (no version pinning) and explain why it's dangerous.
          hints:
            - "Always include the <code>version</code> field in each release."
            - "Omitting version installs whatever is 'latest' at the time — not reproducible."
          solution: |-
            # CORRECT — pinned versions, reproducible
            releases:
              - name: redis
                chart: bitnami/redis
                version: 18.6.1

              - name: nginx
                chart: bitnami/nginx
                version: 15.14.0

            # INCORRECT — no versions, installs latest
            # releases:
            #   - name: redis
            #     chart: bitnami/redis      # danger! version changes without warning
            #   - name: nginx
            #     chart: bitnami/nginx      # not reproducible across deploys
          annotations:
            - type: gotcha
              label: Unpinned Versions
              text: >-
                Without version pinning, the same helmfile can produce different deployments on different days
                as upstream charts release new versions. Always pin versions.
        - id: v10
          title: Checking Installed Chart Version
          description: >-
            Write the commands to check what chart version and app version are currently deployed for the <code>api</code>
            release in namespace <code>app</code>.
          hints:
            - "<code>helm list</code> shows deployed releases with their chart versions."
            - "<code>helm get metadata</code> shows detailed release metadata."
          solution: |-
            # List releases with chart and app versions
            helm list -n app
            # NAME  NAMESPACE  REVISION  STATUS    CHART       APP VERSION
            # api   app        3         deployed  api-2.5.0   1.5.1

            # Get detailed metadata for a specific release
            helm get metadata api -n app
          annotations:
            - type: idiom
              label: helm list
              text: >-
                helm list shows chart version in the CHART column (e.g., api-2.5.0) and the application version
                in APP VERSION. Use -n to specify the namespace.
    - id: warmup_4
      concept: Release Management Best Practices
      variants:
        - id: v1
          title: Explicit Namespace Flag
          description: >-
            Show the difference between deploying without a namespace flag (bad) and with an explicit namespace (good).
            Include the <code>--create-namespace</code> flag for first-time installs.
          hints:
            - "Without <code>--namespace</code>, Helm uses whatever your kubeconfig defaults to."
            - "Always be explicit about which namespace receives the release."
          solution: |-
            # BAD — deploys to whatever namespace kubeconfig defaults to
            helm upgrade --install api ./charts/api

            # GOOD — explicit namespace
            helm upgrade --install api ./charts/api --namespace app

            # GOOD — create namespace if it doesn't exist
            helm upgrade --install api ./charts/api \
              --namespace app \
              --create-namespace
          annotations:
            - type: gotcha
              label: Default Namespace
              text: >-
                Without --namespace, Helm uses the default namespace from your kubeconfig context. This leads to
                accidental deployments to the wrong namespace, especially when switching between clusters.
        - id: v2
          title: Pin Chart Version on Install
          description: >-
            Write the correct <code>helm install</code> command for <code>redis</code> from <code>bitnami/redis</code> that
            pins the version to <code>18.6.1</code>. Then show the incorrect version without pinning.
          hints:
            - "Use <code>--version</code> to pin the chart version."
            - "Without <code>--version</code>, Helm installs the latest version available."
          solution: |-
            # GOOD — pinned version, reproducible
            helm install redis bitnami/redis \
              --version 18.6.1 \
              --namespace cache

            # BAD — installs whatever version is latest today
            helm install redis bitnami/redis \
              --namespace cache
          annotations:
            - type: gotcha
              label: Unpinned Installs
              text: >-
                Without --version, helm install pulls the latest chart version. A chart update between your test
                and production deploy could introduce breaking changes.
        - id: v3
          title: History Max Setting
          description: >-
            Write a <code>helm upgrade</code> command that keeps only the last 10 revisions of history. Then show the
            command to view the release history.
          hints:
            - "Use <code>--history-max</code> to limit stored revisions."
            - "Use <code>helm history</code> to view past revisions."
          solution: |-
            # Deploy with history limit
            helm upgrade --install api ./charts/api \
              --namespace app \
              --history-max 10

            # View release history
            helm history api -n app
          annotations:
            - type: gotcha
              label: etcd Storage
              text: >-
                Each revision is stored as a Secret in etcd. Without --history-max, old revisions accumulate
                and consume etcd storage, potentially impacting cluster performance.
        - id: v4
          title: Full Production Deploy Command
          description: >-
            Write the complete <code>helm upgrade --install</code> command with all recommended production flags:
            namespace, create-namespace, version pinning, values file, wait, timeout, atomic, and history-max.
          hints:
            - "Combine all safety flags into one command."
            - "This is the 'gold standard' deploy command for CI/CD pipelines."
          solution: |-
            helm upgrade --install api ./charts/api \
              --namespace app \
              --create-namespace \
              --version 2.5.0 \
              --values values/prod.yaml \
              --wait \
              --timeout 5m \
              --atomic \
              --history-max 10
          annotations:
            - type: pattern
              label: Production Deploy
              text: >-
                This command is idempotent (--install), creates the namespace if needed (--create-namespace),
                pins the version, waits for readiness (--wait), auto-rollbacks on failure (--atomic), and
                manages history (--history-max).
        - id: v5
          title: Naming Conventions
          description: >-
            You manage releases for three teams (platform, backend, frontend) each deploying to dev and prod environments.
            Show how you would name the releases using the <code>&lt;team&gt;-&lt;app&gt;</code> pattern for a
            <code>redis</code> instance owned by the platform team.
          hints:
            - "Consistent naming helps identify who owns a release."
            - "The team prefix prevents name collisions across teams."
          solution: |-
            # Single environment per cluster: <team>-<app>
            helm upgrade --install platform-redis bitnami/redis \
              --namespace platform \
              --version 18.6.1

            # Multiple environments in one cluster: <team>-<app>-<env>
            helm upgrade --install platform-redis-prod bitnami/redis \
              --namespace platform-prod \
              --version 18.6.1
          annotations:
            - type: pattern
              label: Release Naming
              text: >-
                Consistent naming conventions make it easy to identify releases with helm list. Common patterns
                are app, app-env, or team-app depending on cluster organization.
        - id: v6
          title: helm secrets Encrypt Workflow
          description: >-
            Write the commands to install the <code>helm-secrets</code> plugin, encrypt a values file called
            <code>values-secret.yaml</code>, and then use it during a Helm upgrade.
          hints:
            - "Use <code>helm plugin install</code> for the helm-secrets plugin."
            - "<code>helm secrets enc</code> encrypts a file in place."
            - "<code>helm secrets upgrade</code> decrypts on the fly during deploy."
          solution: |-
            # Install helm-secrets plugin
            helm plugin install https://github.com/jkroepke/helm-secrets

            # Encrypt the secrets file (uses SOPS)
            helm secrets enc values-secret.yaml

            # Deploy with encrypted secrets (decrypted at deploy time)
            helm secrets upgrade --install api ./charts/api \
              --namespace app \
              --values values/prod.yaml \
              --values values-secret.yaml
          annotations:
            - type: idiom
              label: helm-secrets
              text: >-
                helm-secrets uses Mozilla SOPS to encrypt values files. Encrypted files can be committed to git
                safely. Decryption happens transparently during helm install/upgrade.
        - id: v7
          title: helm secrets Decrypt for Review
          description: >-
            Write the command to decrypt <code>values-secret.yaml</code> for local viewing (if you have KMS access). Then
            show how to clean up the decrypted file and the <code>.gitignore</code> entry to prevent accidental commits.
          hints:
            - "<code>helm secrets dec</code> creates a <code>.dec</code> file with plaintext values."
            - "Always add <code>*.dec</code> to <code>.gitignore</code>."
          solution: |-
            # Decrypt for local viewing
            helm secrets dec values-secret.yaml
            # Creates values-secret.yaml.dec

            # View the plaintext
            cat values-secret.yaml.dec

            # Clean up
            rm values-secret.yaml.dec

            # .gitignore entry to prevent accidental commits
            # *.dec
            # values-secret.yaml.dec
          annotations:
            - type: gotcha
              label: Decrypted Files in Git
              text: >-
                Always add *.dec to .gitignore. If a decrypted file gets committed, the secrets are in git history
                forever. Also add pre-commit hooks to block .dec files.
        - id: v8
          title: External Secrets Operator
          description: >-
            Write an <code>ExternalSecret</code> resource that syncs the keys <code>db-password</code> and
            <code>api-key</code> from a Vault backend (ClusterSecretStore named <code>vault-backend</code>) into a
            Kubernetes Secret named <code>api-secrets</code> in namespace <code>app</code>.
          hints:
            - "Use <code>apiVersion: external-secrets.io/v1beta1</code> with <code>kind: ExternalSecret</code>."
            - "The <code>secretStoreRef</code> references the ClusterSecretStore."
            - "The <code>target.name</code> is the Kubernetes Secret that gets created."
          solution: |-
            apiVersion: external-secrets.io/v1beta1
            kind: ExternalSecret
            metadata:
              name: api-secrets
              namespace: app
            spec:
              refreshInterval: 1h
              secretStoreRef:
                name: vault-backend
                kind: ClusterSecretStore
              target:
                name: api-secrets
              data:
                - secretKey: db-password
                  remoteRef:
                    key: production/api
                    property: db-password
                - secretKey: api-key
                  remoteRef:
                    key: production/api
                    property: api-key
          annotations:
            - type: pattern
              label: External Secrets Operator
              text: >-
                External Secrets Operator syncs secrets from Vault, AWS Secrets Manager, or GCP Secret Manager
                into Kubernetes Secrets. No secrets in git at all — the gold standard for production.
        - id: v9
          title: Namespace Strategy Choice
          description: >-
            Your company has three teams (frontend, backend, platform) deploying to dev, staging, and prod. List the
            pros and cons of (a) namespace per environment, (b) namespace per team, and (c) cluster per environment.
          hints:
            - "Think about isolation, cost, and operational complexity."
            - "The answer depends on team size and security requirements."
          solution: |-
            # (a) Namespace per environment: app-dev, app-staging, app-prod
            # Pros: Simple isolation, easy RBAC per environment
            # Cons: All environments in one cluster, blast radius if cluster fails

            # (b) Namespace per team: team-frontend, team-backend, team-platform
            # Pros: Team autonomy, resource quotas per team
            # Cons: Cross-team dependencies complex, env isolation weaker

            # (c) Cluster per environment: dev-cluster, staging-cluster, prod-cluster
            # Pros: Strongest isolation, prod cluster can't be affected by dev
            # Cons: Higher infrastructure cost, more clusters to manage
          annotations:
            - type: pattern
              label: Namespace Strategy
              text: >-
                Most teams start with namespace per environment, then move to cluster per environment as they scale.
                The choice depends on isolation requirements and infrastructure budget.
        - id: v10
          title: List and Get Release Info
          description: >-
            Write the commands to (1) list all releases in the <code>app</code> namespace, (2) get the current values
            for the <code>api</code> release, and (3) get the deployed manifests for <code>api</code>.
          hints:
            - "<code>helm list</code> shows releases. <code>helm get values</code> shows values. <code>helm get manifest</code> shows rendered templates."
          solution: |-
            # List all releases in namespace
            helm list -n app

            # Get current values for a release
            helm get values api -n app

            # Get deployed manifests
            helm get manifest api -n app
          annotations:
            - type: idiom
              label: helm get
              text: >-
                helm get has subcommands: values (applied values), manifest (rendered templates), notes (release notes),
                hooks (lifecycle hooks), and all (everything). Essential for debugging.
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 3
      concept: Helmfile
      variants:
        - id: v1
          title: Multi-Service Helmfile for E-Commerce
          description: >-
            Design a <code>helmfile.yaml</code> for an e-commerce platform with four services: <code>frontend</code>
            (local chart <code>./charts/frontend</code> v1.2.0), <code>api</code> (local chart <code>./charts/api</code>
            v2.5.0), <code>redis</code> (bitnami/redis 18.6.1), and <code>postgresql</code> (bitnami/postgresql 14.0.5).
            Support <code>dev</code>, <code>staging</code>, and <code>prod</code> environments with appropriate
            <code>helmDefaults</code>. Dev should use 1 replica, prod should use 3 replicas for the frontend and api
            services.
          functionSignature: "helmfile.yaml"
          testCases:
            - input: "helmfile -e dev apply"
              output: "All 4 releases deployed to dev namespaces with 1 replica"
            - input: "helmfile -e prod apply"
              output: "All 4 releases deployed to prod namespaces with 3 replicas"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you structure environments so that replica counts differ between dev and prod without
                duplicating the release definitions?
            - title: "\U0001F4A1 Hint"
              content: >-
                Use the environments block to define per-environment values. Reference them with
                {{ .Environment.Values.replicas }} in the set field of each release.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Define repositories (bitnami)
                2. Set helmDefaults (wait, timeout, createNamespace, historyMax)
                3. Define environments with values files
                4. Define 4 releases using environment-templated namespaces
                5. Use set overrides for replicaCount from environment values</pre>
          solution: |-
            repositories:
              - name: bitnami
                url: https://charts.bitnami.com/bitnami

            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true
              historyMax: 10

            environments:
              dev:
                values:
                  - environments/dev.yaml
              staging:
                values:
                  - environments/staging.yaml
              prod:
                values:
                  - environments/prod.yaml

            releases:
              - name: frontend
                namespace: ecommerce-{{ .Environment.Name }}
                chart: ./charts/frontend
                version: 1.2.0
                values:
                  - values/frontend-common.yaml
                  - values/frontend-{{ .Environment.Name }}.yaml
                set:
                  - name: replicaCount
                    value: {{ .Environment.Values.replicas }}

              - name: api
                namespace: ecommerce-{{ .Environment.Name }}
                chart: ./charts/api
                version: 2.5.0
                values:
                  - values/api-common.yaml
                  - values/api-{{ .Environment.Name }}.yaml
                set:
                  - name: replicaCount
                    value: {{ .Environment.Values.replicas }}

              - name: redis
                namespace: ecommerce-{{ .Environment.Name }}
                chart: bitnami/redis
                version: 18.6.1
                values:
                  - values/redis-{{ .Environment.Name }}.yaml

              - name: postgresql
                namespace: ecommerce-{{ .Environment.Name }}
                chart: bitnami/postgresql
                version: 14.0.5
                values:
                  - values/postgresql-{{ .Environment.Name }}.yaml

            # environments/dev.yaml:   replicas: 1
            # environments/staging.yaml: replicas: 2
            # environments/prod.yaml:  replicas: 3
          difficulty: 2
          annotations:
            - type: pattern
              label: Multi-Service Helmfile
              text: >-
                Group related services into one helmfile with shared environment configuration. Use environment-templated
                namespaces and values files for per-environment overrides.
        - id: v2
          title: Helmfile for Shared Infrastructure Stack
          description: >-
            Design a <code>helmfile.yaml</code> for a shared infrastructure stack that includes: ingress-nginx controller,
            cert-manager, kube-prometheus-stack, and Loki for log aggregation. Each component should be in its own
            namespace. Configure <code>helmDefaults</code> with a 10-minute timeout (monitoring charts are slow to deploy).
            Pin all chart versions.
          functionSignature: "helmfile.yaml"
          testCases:
            - input: "helmfile sync"
              output: "4 releases deployed in separate namespaces with pinned versions"
            - input: "helmfile -l name=cert-manager apply"
              output: "Only cert-manager is upgraded"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Infrastructure charts like cert-manager and prometheus have long startup times. How do you ensure
                the timeout is long enough without setting it per-release?
            - title: "\U0001F4A1 Hint"
              content: >-
                Use helmDefaults for the shared timeout. Each chart comes from a different repository — you need
                four repository definitions.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Define 4 repositories (ingress-nginx, jetstack, prometheus-community, grafana)
                2. Set helmDefaults with 600-second timeout
                3. Define 4 releases in separate namespaces:
                   - ingress-nginx in ingress-system
                   - cert-manager in cert-manager
                   - kube-prometheus-stack in monitoring
                   - loki in logging</pre>
          solution: |-
            repositories:
              - name: ingress-nginx
                url: https://kubernetes.github.io/ingress-nginx
              - name: jetstack
                url: https://charts.jetstack.io
              - name: prometheus-community
                url: https://prometheus-community.github.io/helm-charts
              - name: grafana
                url: https://grafana.github.io/helm-charts

            helmDefaults:
              wait: true
              timeout: 600
              createNamespace: true
              historyMax: 10

            releases:
              - name: ingress-nginx
                namespace: ingress-system
                chart: ingress-nginx/ingress-nginx
                version: 4.9.1
                values:
                  - values/ingress-nginx.yaml

              - name: cert-manager
                namespace: cert-manager
                chart: jetstack/cert-manager
                version: 1.14.2
                values:
                  - values/cert-manager.yaml

              - name: monitoring
                namespace: monitoring
                chart: prometheus-community/kube-prometheus-stack
                version: 56.6.2
                values:
                  - values/monitoring.yaml

              - name: loki
                namespace: logging
                chart: grafana/loki
                version: 5.42.0
                values:
                  - values/loki.yaml
          difficulty: 2
          annotations:
            - type: pattern
              label: Infrastructure Helmfile
              text: >-
                Separate infrastructure components from application releases. Each infrastructure chart gets its own
                namespace for isolation and clean RBAC boundaries.
        - id: v3
          title: Multi-Cluster Helmfile with kubeContext
          description: >-
            Design a <code>helmfile.yaml</code> that deploys the same <code>api</code> application (local chart
            <code>./charts/api</code> v2.5.0) to three clusters: <code>us-east-prod</code>, <code>eu-west-prod</code>,
            and <code>ap-southeast-prod</code>. Each cluster has a different kubeContext and different values file.
            Use helmfile environments to target each cluster.
          functionSignature: "helmfile.yaml"
          testCases:
            - input: "helmfile -e us-east apply"
              output: "api deployed to us-east-prod cluster context"
            - input: "helmfile -e eu-west apply"
              output: "api deployed to eu-west-prod cluster context"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Each environment maps to a cluster. The kubeContext field in the environment definition tells helmfile
                which kubectl context to use.
            - title: "\U0001F4A1 Hint"
              content: >-
                Define each cluster as an environment with its own kubeContext and values file. The release definition
                uses template variables to select the right values.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>environments:
                  us-east:
                    kubeContext: us-east-prod
                    values: [env/us-east.yaml]
                  eu-west:
                    kubeContext: eu-west-prod
                    values: [env/eu-west.yaml]
                releases:
                  - name: api
                    values: [values/{{ .Environment.Name }}.yaml]</pre>
          solution: |-
            environments:
              us-east:
                values:
                  - env/us-east.yaml
                kubeContext: us-east-prod
              eu-west:
                values:
                  - env/eu-west.yaml
                kubeContext: eu-west-prod
              ap-southeast:
                values:
                  - env/ap-southeast.yaml
                kubeContext: ap-southeast-prod

            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true
              historyMax: 10

            releases:
              - name: api
                namespace: app
                chart: ./charts/api
                version: 2.5.0
                values:
                  - values/api-common.yaml
                  - values/api-{{ .Environment.Name }}.yaml
                set:
                  - name: region
                    value: {{ .Environment.Values.region }}
          difficulty: 3
          annotations:
            - type: pattern
              label: Multi-Cluster Helmfile
              text: >-
                Use helmfile environments with kubeContext to target different clusters. One helmfile, multiple clusters,
                per-cluster configuration through environment values.
        - id: v4
          title: Helmfile with Conditional Releases
          description: >-
            Design a <code>helmfile.yaml</code> where the <code>debug-tools</code> release (a chart with kubectl, curl,
            and debug utilities) is only deployed in <code>dev</code> and <code>staging</code> environments, not in
            <code>prod</code>. The <code>api</code> and <code>redis</code> releases should deploy in all environments.
            Use helmfile's <code>condition</code> field to control this.
          functionSignature: "helmfile.yaml"
          testCases:
            - input: "helmfile -e dev apply"
              output: "api, redis, and debug-tools deployed"
            - input: "helmfile -e prod apply"
              output: "Only api and redis deployed, debug-tools skipped"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you skip a release based on environment? The helmfile condition field evaluates a values path
                to determine if a release should be deployed.
            - title: "\U0001F4A1 Hint"
              content: >-
                Set a boolean value like debugToolsEnabled in each environment's values file. Reference it in the
                release's condition field.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>environments:
                  dev:   values: [{debugToolsEnabled: true}]
                  prod:  values: [{debugToolsEnabled: false}]
                releases:
                  - name: debug-tools
                    condition: debugToolsEnabled</pre>
          solution: |-
            environments:
              dev:
                values:
                  - environments/dev.yaml
                  - debugToolsEnabled: true
              staging:
                values:
                  - environments/staging.yaml
                  - debugToolsEnabled: true
              prod:
                values:
                  - environments/prod.yaml
                  - debugToolsEnabled: false

            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true

            releases:
              - name: api
                namespace: app-{{ .Environment.Name }}
                chart: ./charts/api
                version: 2.5.0
                values:
                  - values/api-{{ .Environment.Name }}.yaml

              - name: redis
                namespace: app-{{ .Environment.Name }}
                chart: bitnami/redis
                version: 18.6.1

              - name: debug-tools
                namespace: app-{{ .Environment.Name }}
                chart: ./charts/debug-tools
                version: 0.1.0
                condition: debugToolsEnabled
          difficulty: 3
          annotations:
            - type: pattern
              label: Conditional Releases
              text: >-
                Use the condition field to enable/disable releases based on environment values. This is cleaner than
                maintaining separate helmfiles per environment.
        - id: v5
          title: Helmfile with Hooks and Dependencies
          description: >-
            Design a <code>helmfile.yaml</code> where the database (<code>postgresql</code>) must be deployed before
            the <code>api</code> service, and the <code>api</code> must be deployed before the <code>frontend</code>.
            Use helmfile's <code>needs</code> field to enforce deployment order. Include all three services with
            appropriate versions and namespaces.
          functionSignature: "helmfile.yaml"
          testCases:
            - input: "helmfile apply"
              output: "postgresql deployed first, then api, then frontend"
            - input: "helmfile -l name=frontend apply"
              output: "frontend deployed (with needs satisfied by existing releases)"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Some services depend on others being ready first. Databases must exist before apps connect to them.
                How do you express these dependencies in helmfile?
            - title: "\U0001F4A1 Hint"
              content: >-
                The needs field takes a list of release references in the format namespace/name. Helmfile deploys
                needed releases first.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>releases:
                  - name: postgresql
                    namespace: db
                  - name: api
                    namespace: app
                    needs:
                      - db/postgresql
                  - name: frontend
                    namespace: app
                    needs:
                      - app/api</pre>
          solution: |-
            repositories:
              - name: bitnami
                url: https://charts.bitnami.com/bitnami

            helmDefaults:
              wait: true
              timeout: 300
              createNamespace: true
              historyMax: 10

            releases:
              - name: postgresql
                namespace: database
                chart: bitnami/postgresql
                version: 14.0.5
                values:
                  - values/postgresql.yaml

              - name: api
                namespace: app
                chart: ./charts/api
                version: 2.5.0
                needs:
                  - database/postgresql
                values:
                  - values/api.yaml

              - name: frontend
                namespace: app
                chart: ./charts/frontend
                version: 1.2.0
                needs:
                  - app/api
                values:
                  - values/frontend.yaml
          difficulty: 4
          annotations:
            - type: pattern
              label: Release Dependencies
              text: >-
                The needs field enforces deployment order. Combined with helmDefaults.wait=true, this ensures each
                dependency is fully ready before dependent releases start deploying.
        - id: v6
          title: Helmfile for Microservices Platform
          description: >-
            Design a comprehensive <code>helmfile.yaml</code> for a microservices platform with: (1) infrastructure
            layer (ingress-nginx, cert-manager), (2) data layer (postgresql, redis, rabbitmq), and (3) application layer
            (user-service, order-service, notification-service). Use <code>needs</code> to enforce that infrastructure
            deploys before data, and data deploys before applications. Support <code>dev</code> and <code>prod</code>
            environments.
          functionSignature: "helmfile.yaml"
          testCases:
            - input: "helmfile -e prod apply"
              output: "Infrastructure first, then data, then applications — all in prod namespaces"
            - input: "helmfile -e dev apply"
              output: "Same order with dev configuration"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                With 8 releases across 3 layers, you need clear dependency ordering. How do you ensure each layer
                completes before the next begins?
            - title: "\U0001F4A1 Hint"
              content: >-
                Use needs chains: applications need data layer releases, data layer releases need infrastructure.
                Group releases logically by namespace.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>Layer 1 (infra): ingress-nginx, cert-manager -> no needs
                Layer 2 (data): postgresql, redis, rabbitmq -> needs infra
                Layer 3 (apps): user-svc, order-svc, notif-svc -> needs data</pre>
          solution: |-
            repositories:
              - name: bitnami
                url: https://charts.bitnami.com/bitnami
              - name: ingress-nginx
                url: https://kubernetes.github.io/ingress-nginx
              - name: jetstack
                url: https://charts.jetstack.io

            helmDefaults:
              wait: true
              timeout: 600
              createNamespace: true
              historyMax: 10

            environments:
              dev:
                values:
                  - environments/dev.yaml
              prod:
                values:
                  - environments/prod.yaml

            releases:
              # Infrastructure layer
              - name: ingress-nginx
                namespace: ingress-system
                chart: ingress-nginx/ingress-nginx
                version: 4.9.1

              - name: cert-manager
                namespace: cert-manager
                chart: jetstack/cert-manager
                version: 1.14.2

              # Data layer
              - name: postgresql
                namespace: data-{{ .Environment.Name }}
                chart: bitnami/postgresql
                version: 14.0.5
                needs:
                  - ingress-system/ingress-nginx
                  - cert-manager/cert-manager
                values:
                  - values/postgresql-{{ .Environment.Name }}.yaml

              - name: redis
                namespace: data-{{ .Environment.Name }}
                chart: bitnami/redis
                version: 18.6.1
                needs:
                  - ingress-system/ingress-nginx
                values:
                  - values/redis-{{ .Environment.Name }}.yaml

              - name: rabbitmq
                namespace: data-{{ .Environment.Name }}
                chart: bitnami/rabbitmq
                version: 12.5.6
                needs:
                  - ingress-system/ingress-nginx
                values:
                  - values/rabbitmq-{{ .Environment.Name }}.yaml

              # Application layer
              - name: user-service
                namespace: app-{{ .Environment.Name }}
                chart: ./charts/user-service
                version: 1.0.0
                needs:
                  - data-{{ .Environment.Name }}/postgresql
                  - data-{{ .Environment.Name }}/redis
                values:
                  - values/user-service-{{ .Environment.Name }}.yaml

              - name: order-service
                namespace: app-{{ .Environment.Name }}
                chart: ./charts/order-service
                version: 1.0.0
                needs:
                  - data-{{ .Environment.Name }}/postgresql
                  - data-{{ .Environment.Name }}/rabbitmq
                values:
                  - values/order-service-{{ .Environment.Name }}.yaml

              - name: notification-service
                namespace: app-{{ .Environment.Name }}
                chart: ./charts/notification-service
                version: 1.0.0
                needs:
                  - data-{{ .Environment.Name }}/rabbitmq
                  - data-{{ .Environment.Name }}/redis
                values:
                  - values/notification-service-{{ .Environment.Name }}.yaml
          difficulty: 4
          annotations:
            - type: pattern
              label: Layered Architecture
              text: >-
                Organize releases into infrastructure, data, and application layers. Use needs to enforce deployment
                order. This mirrors how dependencies flow in a microservices architecture.
    - id: challenge_2
      block: 2
      difficulty: 3
      concept: CI/CD with Helm
      variants:
        - id: v1
          title: GitHub Actions Helm Pipeline
          description: >-
            Write a complete GitHub Actions workflow (<code>.github/workflows/deploy.yaml</code>) that: (1) lints the
            chart on every PR, (2) templates and validates with dry-run on every PR, (3) runs helm diff on pushes to
            main, and (4) deploys with <code>--atomic</code> on pushes to main. The chart is at <code>./charts/api</code>,
            values at <code>values/prod.yaml</code>, namespace <code>app</code>. Use kubeconfig from GitHub secrets.
          functionSignature: ".github/workflows/deploy.yaml"
          testCases:
            - input: "Pull request opened with chart changes"
              output: "Lint and template validation run, deployment is skipped"
            - input: "Push to main branch with chart changes"
              output: "Lint, template, diff, and deploy all run in sequence"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you split CI (validation on PRs) from CD (deployment on merge)? Use separate jobs with
                different triggers.
            - title: "\U0001F4A1 Hint"
              content: >-
                Use on.pull_request for validation jobs and on.push to main for deployment. The deploy job should
                use needs to depend on the validation job. Store kubeconfig as a GitHub secret.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>on:
                  pull_request: (lint + template)
                  push to main: (lint + template + diff + deploy)
                jobs:
                  validate: helm lint, helm template | kubectl dry-run
                  deploy: needs validate, helm diff, helm upgrade --install --atomic</pre>
          solution: |-
            name: Deploy Helm Chart
            on:
              pull_request:
                paths:
                  - 'charts/**'
                  - 'values/**'
              push:
                branches: [main]
                paths:
                  - 'charts/**'
                  - 'values/**'

            jobs:
              validate:
                runs-on: ubuntu-latest
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4
                  - uses: azure/setup-kubectl@v4

                  - name: Lint chart
                    run: helm lint ./charts/api --values values/prod.yaml

                  - name: Template and validate
                    run: |
                      helm template api ./charts/api \
                        --values values/prod.yaml \
                        | kubectl apply --dry-run=client -f -

              deploy:
                if: github.ref == 'refs/heads/main' && github.event_name == 'push'
                needs: validate
                runs-on: ubuntu-latest
                environment: production
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4
                  - uses: azure/setup-kubectl@v4

                  - name: Install helm-diff
                    run: helm plugin install https://github.com/databus23/helm-diff

                  - name: Configure kubeconfig
                    run: echo "${{ secrets.KUBECONFIG }}" | base64 -d > kubeconfig.yaml

                  - name: Diff changes
                    run: |
                      helm diff upgrade api ./charts/api \
                        --namespace app \
                        --values values/prod.yaml \
                        --kubeconfig kubeconfig.yaml

                  - name: Deploy
                    run: |
                      helm upgrade --install api ./charts/api \
                        --namespace app \
                        --create-namespace \
                        --values values/prod.yaml \
                        --wait \
                        --timeout 5m \
                        --atomic \
                        --history-max 10 \
                        --kubeconfig kubeconfig.yaml

                  - name: Run tests
                    run: |
                      helm test api -n app \
                        --kubeconfig kubeconfig.yaml \
                        --logs
          difficulty: 3
          annotations:
            - type: pattern
              label: CI/CD Pipeline
              text: >-
                Split validation (PRs) from deployment (merge). The deploy job gates behind the validate job.
                Using --atomic ensures failed deploys auto-rollback.
        - id: v2
          title: Multi-Environment CI/CD Pipeline
          description: >-
            Write a GitHub Actions workflow that deploys to <code>staging</code> automatically on push to main, then
            requires manual approval to deploy to <code>production</code>. Use helmfile with environments. The staging
            deploy should run helm tests after deploying.
          functionSignature: ".github/workflows/deploy.yaml"
          testCases:
            - input: "Push to main"
              output: "Staging deploys automatically, production waits for approval"
            - input: "Approval granted"
              output: "Production deploys with same chart versions as staging"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you gate production deployments behind manual approval in GitHub Actions? Use the environment
                field with required reviewers.
            - title: "\U0001F4A1 Hint"
              content: >-
                Define two deploy jobs: staging (automatic) and production (requires environment approval). Use
                helmfile -e staging apply and helmfile -e prod apply respectively.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>jobs:
                  validate: lint + template
                  deploy-staging: needs validate, helmfile -e staging apply, helm test
                  deploy-prod: needs deploy-staging, environment: production (manual approval)</pre>
          solution: |-
            name: Deploy Pipeline
            on:
              push:
                branches: [main]
                paths:
                  - 'charts/**'
                  - 'values/**'
                  - 'helmfile.yaml'

            jobs:
              validate:
                runs-on: ubuntu-latest
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4
                  - name: Lint all charts
                    run: |
                      helm lint ./charts/api --values values/api-staging.yaml
                      helm lint ./charts/frontend --values values/frontend-staging.yaml

              deploy-staging:
                needs: validate
                runs-on: ubuntu-latest
                environment: staging
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4
                  - name: Install helmfile and plugins
                    run: |
                      brew install helmfile
                      helm plugin install https://github.com/databus23/helm-diff
                  - name: Configure kubeconfig
                    run: echo "${{ secrets.STAGING_KUBECONFIG }}" | base64 -d > kubeconfig.yaml
                  - name: Deploy to staging
                    run: KUBECONFIG=kubeconfig.yaml helmfile -e staging apply
                  - name: Run tests
                    run: |
                      helm test api -n app-staging --kubeconfig kubeconfig.yaml --logs
                      helm test frontend -n app-staging --kubeconfig kubeconfig.yaml --logs

              deploy-prod:
                needs: deploy-staging
                runs-on: ubuntu-latest
                environment: production
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4
                  - name: Install helmfile and plugins
                    run: |
                      brew install helmfile
                      helm plugin install https://github.com/databus23/helm-diff
                  - name: Configure kubeconfig
                    run: echo "${{ secrets.PROD_KUBECONFIG }}" | base64 -d > kubeconfig.yaml
                  - name: Diff against production
                    run: KUBECONFIG=kubeconfig.yaml helmfile -e prod diff
                  - name: Deploy to production
                    run: KUBECONFIG=kubeconfig.yaml helmfile -e prod apply
          difficulty: 3
          annotations:
            - type: pattern
              label: Staged Deployment
              text: >-
                Deploy to staging first, run tests, then gate production behind manual approval. This catch issues
                before they reach production. GitHub environments with required reviewers enforce the approval gate.
        - id: v3
          title: Chart Publishing Pipeline
          description: >-
            Write a GitHub Actions workflow that, when chart files change and are merged to main: (1) lints the chart,
            (2) runs helm-unittest, (3) packages the chart, (4) pushes it to an OCI registry at
            <code>ghcr.io/myorg/charts</code>. The chart version should be extracted from <code>Chart.yaml</code>.
          functionSignature: ".github/workflows/publish-chart.yaml"
          testCases:
            - input: "Chart.yaml version bumped to 2.6.0 and merged to main"
              output: "Chart published to ghcr.io/myorg/charts/api:2.6.0"
            - input: "Only values/ files changed"
              output: "Pipeline does not run (chart source unchanged)"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you extract the chart version programmatically and use it in the push command? How do you
                authenticate with GHCR?
            - title: "\U0001F4A1 Hint"
              content: >-
                Use grep/awk to extract the version from Chart.yaml. GHCR uses the GITHUB_TOKEN for authentication.
                Use helm registry login with the token.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Trigger on push to main with charts/** path filter
                2. Lint the chart
                3. Run helm unittest
                4. Extract version from Chart.yaml
                5. helm package
                6. helm registry login ghcr.io
                7. helm push to oci://ghcr.io/myorg/charts</pre>
          solution: |-
            name: Publish Chart
            on:
              push:
                branches: [main]
                paths:
                  - 'charts/api/**'

            jobs:
              publish:
                runs-on: ubuntu-latest
                permissions:
                  packages: write
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4

                  - name: Lint chart
                    run: helm lint ./charts/api

                  - name: Install helm-unittest
                    run: helm plugin install https://github.com/helm-unittest/helm-unittest

                  - name: Run unit tests
                    run: helm unittest ./charts/api

                  - name: Extract chart version
                    id: version
                    run: |
                      VERSION=$(grep '^version:' charts/api/Chart.yaml | awk '{print $2}')
                      echo "version=${VERSION}" >> $GITHUB_OUTPUT

                  - name: Package chart
                    run: helm package ./charts/api

                  - name: Login to GHCR
                    run: |
                      echo "${{ secrets.GITHUB_TOKEN }}" | \
                        helm registry login ghcr.io --username ${{ github.actor }} --password-stdin

                  - name: Push chart
                    run: |
                      helm push \
                        "api-${{ steps.version.outputs.version }}.tgz" \
                        oci://ghcr.io/myorg/charts

                  - name: Summary
                    run: |
                      echo "Published api chart version ${{ steps.version.outputs.version }}"
          difficulty: 3
          annotations:
            - type: pattern
              label: Chart Publishing
              text: >-
                Automate chart publishing to OCI registries in CI. Extract the version from Chart.yaml to build the
                correct filename. GHCR uses GITHUB_TOKEN for authentication.
        - id: v4
          title: Canary Deploy Pipeline
          description: >-
            Write a CI/CD pipeline that implements a canary deployment: (1) deploy the new version with only 1 replica as
            <code>api-canary</code>, (2) run helm tests, (3) if tests pass, upgrade the main <code>api</code> release
            to the new version, (4) delete the canary. Use helm commands, not helmfile.
          functionSignature: "deploy-canary.sh"
          testCases:
            - input: "New chart version ready"
              output: "Canary deploys with 1 replica, tests run, main upgrades, canary deleted"
            - input: "Canary tests fail"
              output: "Main release untouched, canary uninstalled"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                A canary deployment runs a small replica of the new version alongside the old version. If the canary
                is healthy, promote the change to the main release.
            - title: "\U0001F4A1 Hint"
              content: >-
                Deploy the canary as a separate Helm release with overridden replica count and release name.
                Use helm test to verify the canary. On success, upgrade the main release.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. helm upgrade --install api-canary with replicaCount=1
                2. helm test api-canary
                3. If tests pass: helm upgrade --install api with full replicas
                4. helm uninstall api-canary
                5. If tests fail: helm uninstall api-canary (main untouched)</pre>
          solution: |-
            #!/bin/bash
            set -euo pipefail

            NAMESPACE="app"
            CHART="./charts/api"
            VALUES="values/prod.yaml"
            TIMEOUT="5m"

            echo "Step 1: Deploy canary (1 replica)"
            helm upgrade --install api-canary "$CHART" \
              --namespace "$NAMESPACE" \
              --values "$VALUES" \
              --set replicaCount=1 \
              --set nameOverride=api-canary \
              --wait \
              --timeout "$TIMEOUT" \
              --atomic

            echo "Step 2: Run tests on canary"
            if helm test api-canary -n "$NAMESPACE" --logs; then
              echo "Step 3: Canary passed — promote to main release"
              helm upgrade --install api "$CHART" \
                --namespace "$NAMESPACE" \
                --values "$VALUES" \
                --wait \
                --timeout "$TIMEOUT" \
                --atomic \
                --history-max 10

              echo "Step 4: Remove canary"
              helm uninstall api-canary -n "$NAMESPACE"

              echo "Deployment complete"
            else
              echo "Canary tests failed — rolling back canary"
              helm uninstall api-canary -n "$NAMESPACE"
              echo "Main release unchanged"
              exit 1
            fi
          difficulty: 4
          annotations:
            - type: pattern
              label: Canary Deploy
              text: >-
                Deploy a canary as a separate Helm release. Test it independently. On success, promote. On failure,
                remove the canary without touching the main release.
        - id: v5
          title: Pipeline with helm-secrets Integration
          description: >-
            Write a GitHub Actions deploy workflow that uses <code>helm-secrets</code> to decrypt secrets during
            deployment. The workflow should install sops and helm-secrets, configure an AWS KMS key for decryption,
            and deploy with both regular and encrypted values files.
          functionSignature: ".github/workflows/deploy-secrets.yaml"
          testCases:
            - input: "Push to main with encrypted values-secret.yaml"
              output: "Secrets decrypted via KMS at deploy time, release upgraded"
            - input: "Developer without KMS access tries to decrypt"
              output: "Decryption fails, secrets remain protected"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How does the CI runner get access to decrypt secrets? It needs KMS credentials. How do you pass
                multiple values files including encrypted ones?
            - title: "\U0001F4A1 Hint"
              content: >-
                Configure AWS credentials for KMS access. Use helm secrets upgrade with both --values for regular
                files and --values for encrypted files.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Configure AWS credentials (for KMS access)
                2. Install sops and helm-secrets
                3. helm secrets upgrade --install api ./charts/api
                     --values values/prod.yaml
                     --values values-secret.yaml</pre>
          solution: |-
            name: Deploy with Secrets
            on:
              push:
                branches: [main]

            jobs:
              deploy:
                runs-on: ubuntu-latest
                environment: production
                steps:
                  - uses: actions/checkout@v4
                  - uses: azure/setup-helm@v4
                  - uses: azure/setup-kubectl@v4

                  - name: Configure AWS credentials
                    uses: aws-actions/configure-aws-credentials@v4
                    with:
                      aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
                      aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
                      aws-region: us-east-1

                  - name: Install sops
                    run: |
                      curl -LO https://github.com/getsops/sops/releases/latest/download/sops-v3.8.1.linux.amd64
                      chmod +x sops-v3.8.1.linux.amd64
                      sudo mv sops-v3.8.1.linux.amd64 /usr/local/bin/sops

                  - name: Install helm-secrets
                    run: helm plugin install https://github.com/jkroepke/helm-secrets

                  - name: Configure kubeconfig
                    run: echo "${{ secrets.KUBECONFIG }}" | base64 -d > kubeconfig.yaml

                  - name: Deploy with encrypted secrets
                    run: |
                      helm secrets upgrade --install api ./charts/api \
                        --namespace app \
                        --create-namespace \
                        --values values/prod.yaml \
                        --values values-secret.yaml \
                        --wait \
                        --timeout 5m \
                        --atomic \
                        --kubeconfig kubeconfig.yaml
          difficulty: 4
          annotations:
            - type: pattern
              label: Secrets in CI/CD
              text: >-
                The CI runner needs KMS access to decrypt secrets. helm-secrets decrypts transparently during
                install/upgrade. AWS credentials are stored as GitHub secrets.
        - id: v6
          title: Full CT Pipeline for Chart Monorepo
          description: >-
            Write a GitHub Actions workflow for a chart monorepo (multiple charts under <code>charts/</code>) that:
            (1) uses <code>ct lint</code> to lint only changed charts, (2) uses <code>ct install</code> to install and
            test changed charts in a Kind cluster, and (3) publishes changed charts to an OCI registry. The workflow
            should spin up a Kind cluster for testing.
          functionSignature: ".github/workflows/chart-ci.yaml"
          testCases:
            - input: "PR modifying charts/api"
              output: "Only api chart linted, installed in Kind, and tested"
            - input: "PR modifying charts/api and charts/frontend"
              output: "Both charts linted, installed, and tested independently"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How does ct know which charts changed? It compares against the target branch. How do you get a
                temporary cluster for testing?
            - title: "\U0001F4A1 Hint"
              content: >-
                Use the helm/kind-action to create a Kind cluster. Use ct lint --target-branch main and ct install
                --target-branch main. Use the chart-testing-action for setup.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Checkout code
                2. Setup Helm and chart-testing
                3. ct lint --target-branch main
                4. Create Kind cluster
                5. ct install --target-branch main
                6. On merge: publish changed charts to OCI</pre>
          solution: |-
            name: Chart CI
            on:
              pull_request:
                paths:
                  - 'charts/**'
              push:
                branches: [main]
                paths:
                  - 'charts/**'

            jobs:
              lint:
                runs-on: ubuntu-latest
                steps:
                  - uses: actions/checkout@v4
                    with:
                      fetch-depth: 0
                  - uses: azure/setup-helm@v4
                  - uses: helm/chart-testing-action@v2

                  - name: Lint changed charts
                    run: ct lint --target-branch main

              test:
                needs: lint
                runs-on: ubuntu-latest
                steps:
                  - uses: actions/checkout@v4
                    with:
                      fetch-depth: 0
                  - uses: azure/setup-helm@v4
                  - uses: helm/chart-testing-action@v2
                  - uses: helm/kind-action@v1

                  - name: Install and test changed charts
                    run: ct install --target-branch main

              publish:
                if: github.ref == 'refs/heads/main' && github.event_name == 'push'
                needs: test
                runs-on: ubuntu-latest
                permissions:
                  packages: write
                steps:
                  - uses: actions/checkout@v4
                    with:
                      fetch-depth: 0
                  - uses: azure/setup-helm@v4

                  - name: Login to GHCR
                    run: |
                      echo "${{ secrets.GITHUB_TOKEN }}" | \
                        helm registry login ghcr.io --username ${{ github.actor }} --password-stdin

                  - name: Publish changed charts
                    run: |
                      CHANGED=$(ct list-changed --target-branch main)
                      for chart_path in $CHANGED; do
                        chart_name=$(basename "$chart_path")
                        version=$(grep '^version:' "$chart_path/Chart.yaml" | awk '{print $2}')
                        helm package "$chart_path"
                        helm push "${chart_name}-${version}.tgz" oci://ghcr.io/myorg/charts
                        echo "Published ${chart_name}:${version}"
                      done
          difficulty: 4
          annotations:
            - type: pattern
              label: Chart Monorepo CI
              text: >-
                Use ct (chart-testing) to detect and test only changed charts. Kind provides ephemeral clusters
                for testing. Only publish charts after they pass linting and testing.
    - id: challenge_3
      block: 1
      difficulty: 2
      concept: Upgrading and Rollback Strategies
      variants:
        - id: v1
          title: Safe Upgrade with Diff and Rollback Plan
          description: >-
            Write the sequence of helm commands to safely upgrade the <code>api</code> release in namespace
            <code>app</code> to chart version <code>2.6.0</code>: (1) check current release status, (2) view release
            history, (3) diff the changes, (4) upgrade with safety flags, (5) verify, and (6) prepare a rollback command
            in case something goes wrong.
          functionSignature: "helm commands"
          testCases:
            - input: "Upgrade api from 2.5.0 to 2.6.0"
              output: "Diff shown, upgrade with --atomic, rollback command ready"
            - input: "Upgrade fails (Pods don't become ready)"
              output: "Automatic rollback via --atomic, previous version restored"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                What information do you need before upgrading? Current status, history (what to rollback to),
                and a preview of changes.
            - title: "\U0001F4A1 Hint"
              content: >-
                Use helm list to check status, helm history for revisions, helm diff for preview, then upgrade
                with --atomic. Note the current revision number for manual rollback.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. helm list -n app (check current state)
                2. helm history api -n app (note current revision)
                3. helm diff upgrade (preview changes)
                4. helm upgrade --install --atomic (deploy)
                5. helm list -n app (verify)
                6. helm rollback api REVISION -n app (if needed)</pre>
          solution: |-
            # Step 1: Check current release status
            helm list -n app
            # NAME  NAMESPACE  REVISION  STATUS    CHART       APP VERSION
            # api   app        5         deployed  api-2.5.0   1.5.0

            # Step 2: View history (note current revision for rollback)
            helm history api -n app
            # REVISION  STATUS      CHART       DESCRIPTION
            # 4         superseded  api-2.4.0   Upgrade complete
            # 5         deployed    api-2.5.0   Upgrade complete

            # Step 3: Preview what will change
            helm diff upgrade api ./charts/api \
              --namespace app \
              --values values/prod.yaml

            # Step 4: Upgrade with safety flags
            helm upgrade --install api ./charts/api \
              --namespace app \
              --values values/prod.yaml \
              --version 2.6.0 \
              --wait \
              --timeout 5m \
              --atomic \
              --history-max 10

            # Step 5: Verify the upgrade
            helm list -n app
            helm get values api -n app

            # Step 6: If something is wrong after deploy, manual rollback
            helm rollback api 5 -n app
          difficulty: 2
          annotations:
            - type: pattern
              label: Safe Upgrade Workflow
              text: >-
                Always diff before upgrading and note the current revision. With --atomic, failed upgrades
                auto-rollback. Keep a manual rollback command ready for post-deploy issues.
        - id: v2
          title: CRD Upgrade Procedure
          description: >-
            The <code>kube-prometheus-stack</code> chart has a new version that includes CRD changes. Write the commands
            to safely upgrade: (1) extract and apply the new CRDs first, (2) then upgrade the Helm release. Explain
            why you cannot just run <code>helm upgrade</code>.
          functionSignature: "helm and kubectl commands"
          testCases:
            - input: "kube-prometheus-stack upgrade with CRD changes"
              output: "CRDs applied with kubectl first, then helm upgrade"
            - input: "Only helm upgrade run (no CRD update)"
              output: "CRDs unchanged — new CRD fields not available to the cluster"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Helm installs CRDs on first install but never updates them on upgrade. This is intentional because
                CRDs are cluster-scoped and affect all namespaces.
            - title: "\U0001F4A1 Hint"
              content: >-
                Use helm template with --include-crds to extract CRDs, then apply with kubectl apply --server-side.
                After CRDs are updated, run helm upgrade normally.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. helm template with --include-crds | kubectl apply --server-side
                   (or kubectl apply -f charts/kube-prometheus-stack/crds/)
                2. Wait for CRDs to be established
                3. helm upgrade as normal</pre>
          solution: |-
            # Why: Helm does NOT upgrade CRDs on helm upgrade.
            # CRDs are cluster-scoped and Helm intentionally skips them
            # to prevent accidental cluster-wide breakage.

            # Step 1: Extract and apply CRDs from the new chart version
            helm template prometheus \
              prometheus-community/kube-prometheus-stack \
              --version 57.0.0 \
              --include-crds \
              | kubectl apply --server-side -f -

            # Alternative: apply CRDs from the chart directory
            # kubectl apply --server-side -f charts/kube-prometheus-stack/crds/

            # Step 2: Verify CRDs are established
            kubectl get crds | grep monitoring.coreos.com

            # Step 3: Now upgrade the Helm release
            helm upgrade prometheus \
              prometheus-community/kube-prometheus-stack \
              --version 57.0.0 \
              --namespace monitoring \
              --values values/monitoring.yaml \
              --wait \
              --timeout 10m \
              --atomic
          difficulty: 3
          annotations:
            - type: gotcha
              label: CRD Upgrades
              text: >-
                Helm's CRD limitation is the most common surprise in production. Always check chart release notes
                for CRD changes and apply them manually before running helm upgrade.
        - id: v3
          title: Rollback After Failed Upgrade
          description: >-
            A <code>helm upgrade</code> was run without <code>--atomic</code> and the new Pods are crash-looping. Write
            the commands to: (1) identify the problem, (2) check which revision was the last working one, (3) rollback
            to that revision, and (4) verify the rollback succeeded.
          functionSignature: "helm and kubectl commands"
          testCases:
            - input: "api release revision 6 is crash-looping"
              output: "Rollback to revision 5, new revision 7 created, Pods healthy"
            - input: "Check revision 7 status"
              output: "Status: deployed, chart matches revision 5's chart"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you find the last working revision? helm history shows the status of each revision.
                Look for the most recent 'deployed' or 'superseded' revision before the failed one.
            - title: "\U0001F4A1 Hint"
              content: >-
                Use helm history to see revisions. The failed revision will show 'deployed' but Pods are unhealthy.
                The previous revision with status 'superseded' was the last working state.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. kubectl get pods -n app (see crash-looping Pods)
                2. helm history api -n app (find last good revision)
                3. helm rollback api REVISION -n app
                4. kubectl get pods -n app (verify healthy)
                5. helm history api -n app (confirm new rollback revision)</pre>
          solution: |-
            # Step 1: Identify the problem
            kubectl get pods -n app
            # NAME                   READY   STATUS             RESTARTS
            # api-7b9c8d6e5-abc12    0/1     CrashLoopBackOff   5

            kubectl logs api-7b9c8d6e5-abc12 -n app
            # Error: missing required config /etc/api/config.yaml

            # Step 2: Check revision history
            helm history api -n app
            # REVISION  STATUS      CHART       DESCRIPTION
            # 4         superseded  api-2.4.0   Upgrade complete
            # 5         superseded  api-2.5.0   Upgrade complete
            # 6         deployed    api-2.6.0   Upgrade complete  <- broken

            # Step 3: Rollback to revision 5 (last known good)
            helm rollback api 5 -n app
            # Rollback was a success! Happy Helming!

            # Step 4: Verify the rollback
            kubectl get pods -n app
            # NAME                   READY   STATUS    RESTARTS
            # api-5d4f7b8c9-xyz99    1/1     Running   0

            helm history api -n app
            # REVISION  STATUS      CHART       DESCRIPTION
            # 5         superseded  api-2.5.0   Upgrade complete
            # 6         superseded  api-2.6.0   Upgrade complete
            # 7         deployed    api-2.5.0   Rollback to 5
          difficulty: 2
          annotations:
            - type: gotcha
              label: Rollback Creates New Revision
              text: >-
                helm rollback does not delete the failed revision. It creates a new revision with the old config.
                The history keeps growing, which is why --history-max matters.
        - id: v4
          title: Blue-Green with Helm Releases
          description: >-
            Implement a blue-green deployment strategy using two separate Helm releases: <code>api-blue</code> (current)
            and <code>api-green</code> (new). Write the commands to: (1) deploy the green version, (2) verify green is
            healthy, (3) switch traffic by updating the ingress, and (4) clean up the old blue release.
          functionSignature: "helm commands"
          testCases:
            - input: "New version ready for blue-green deploy"
              output: "Green deployed alongside blue, traffic switched, blue removed"
            - input: "Green is unhealthy after deploy"
              output: "Traffic stays on blue, green is removed"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Blue-green runs two full copies. Traffic switches all at once (unlike canary which is gradual).
                How do you switch traffic between two Helm releases?
            - title: "\U0001F4A1 Hint"
              content: >-
                Deploy green as a separate release. Use helm test to verify. Update the ingress or service to point
                to the green Pods. Then uninstall blue.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Deploy api-green (new version)
                2. helm test api-green (verify health)
                3. Update ingress to point to api-green service
                4. Verify traffic flows to green
                5. helm uninstall api-blue</pre>
          solution: |-
            #!/bin/bash
            set -euo pipefail

            NAMESPACE="app"
            CHART="./charts/api"
            VALUES="values/prod.yaml"

            # Step 1: Deploy green (new version)
            helm upgrade --install api-green "$CHART" \
              --namespace "$NAMESPACE" \
              --values "$VALUES" \
              --set nameOverride=api-green \
              --set service.name=api-green \
              --wait \
              --timeout 5m \
              --atomic

            # Step 2: Verify green is healthy
            if ! helm test api-green -n "$NAMESPACE" --logs; then
              echo "Green failed health checks — aborting"
              helm uninstall api-green -n "$NAMESPACE"
              exit 1
            fi

            # Step 3: Switch traffic — update ingress to point to green
            kubectl patch ingress api-ingress -n "$NAMESPACE" \
              --type=json \
              -p='[{"op":"replace","path":"/spec/rules/0/http/paths/0/backend/service/name","value":"api-green"}]'

            # Step 4: Verify traffic is flowing to green
            sleep 10
            kubectl get ingress api-ingress -n "$NAMESPACE" -o jsonpath='{.spec.rules[0].http.paths[0].backend.service.name}'
            # Should output: api-green

            # Step 5: Remove old blue release
            helm uninstall api-blue -n "$NAMESPACE"

            # Step 6: Rename green to blue for next cycle (optional)
            echo "Blue-green deployment complete. Green is now active."
          difficulty: 3
          annotations:
            - type: pattern
              label: Blue-Green with Helm
              text: >-
                Use separate Helm releases for blue and green. Switch traffic at the ingress/service level.
                This gives instant rollback by re-pointing traffic back to the old release.
        - id: v5
          title: Handling ConfigMap/Secret Changes
          description: >-
            Your chart deploys a ConfigMap that is mounted into Pods. When the ConfigMap values change via
            <code>helm upgrade</code>, the Pods don't automatically restart. Write the chart template pattern that
            forces a Pod restart when ConfigMap content changes, and show the upgrade command.
          functionSignature: "deployment.yaml template snippet + helm command"
          testCases:
            - input: "ConfigMap values changed in values.yaml"
              output: "Pods restart automatically after helm upgrade"
            - input: "ConfigMap unchanged, other values changed"
              output: "Pods restart only if their own spec changed"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Kubernetes does not restart Pods when a mounted ConfigMap changes. How do you force a restart when
                the config changes during a Helm upgrade?
            - title: "\U0001F4A1 Hint"
              content: >-
                Add an annotation to the Pod template that contains a hash of the ConfigMap data. When the ConfigMap
                changes, the hash changes, which changes the Pod spec, triggering a rollout.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>In deployment.yaml template:
                  annotations:
                    checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
                This annotation changes when the ConfigMap content changes,
                forcing Kubernetes to roll out new Pods.</pre>
          solution: |-
            # In charts/api/templates/deployment.yaml:
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: {{ include "api.fullname" . }}
            spec:
              template:
                metadata:
                  annotations:
                    # Force restart when ConfigMap changes
                    checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
                spec:
                  containers:
                    - name: api
                      image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
                      volumeMounts:
                        - name: config
                          mountPath: /etc/api
                  volumes:
                    - name: config
                      configMap:
                        name: {{ include "api.fullname" . }}-config

            # Upgrade command (ConfigMap changes trigger Pod restart)
            helm upgrade --install api ./charts/api \
              --namespace app \
              --values values/prod.yaml \
              --wait \
              --timeout 5m \
              --atomic
          difficulty: 3
          annotations:
            - type: pattern
              label: ConfigMap Checksum Annotation
              text: >-
                The sha256sum checksum annotation is the standard Helm pattern for triggering Pod restarts on
                ConfigMap changes. It works because changing the annotation changes the Pod template spec.
        - id: v6
          title: Staged Rollout with Pause
          description: >-
            Write the helm upgrade and kubectl commands to perform a staged rollout: (1) upgrade the release, (2) pause
            the rollout after the first batch of Pods, (3) verify the new Pods are healthy, and (4) resume the rollout.
            Include the rollback command if the new Pods are unhealthy.
          functionSignature: "helm and kubectl commands"
          testCases:
            - input: "Upgrade with maxSurge=1, then pause"
              output: "One new Pod deployed, rollout paused for verification"
            - input: "New Pod is healthy, resume rollout"
              output: "Remaining Pods updated, rollout complete"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                How do you pause a Kubernetes rollout mid-way? kubectl rollout pause stops the rollout controller
                from creating more new Pods.
            - title: "\U0001F4A1 Hint"
              content: >-
                Run helm upgrade without --wait (so it returns immediately), then kubectl rollout pause.
                After verification, kubectl rollout resume.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. helm upgrade (no --wait, returns immediately)
                2. Wait for first new Pod
                3. kubectl rollout pause deployment/api
                4. Verify new Pod health
                5. kubectl rollout resume deployment/api
                6. Or: kubectl rollout undo if unhealthy</pre>
          solution: |-
            # Step 1: Upgrade without --wait (returns immediately)
            helm upgrade --install api ./charts/api \
              --namespace app \
              --values values/prod.yaml \
              --history-max 10

            # Step 2: Wait for first new Pod to start
            kubectl rollout status deployment/api -n app --timeout=60s --watch=false

            # Step 3: Pause the rollout
            kubectl rollout pause deployment/api -n app

            # Step 4: Verify the new Pod is healthy
            kubectl get pods -n app -l app.kubernetes.io/name=api
            kubectl logs -n app -l app.kubernetes.io/name=api --tail=20

            # Step 5a: If healthy — resume rollout
            kubectl rollout resume deployment/api -n app
            kubectl rollout status deployment/api -n app

            # Step 5b: If unhealthy — undo the rollout
            # kubectl rollout undo deployment/api -n app
            # helm rollback api PREVIOUS_REVISION -n app
          difficulty: 3
          annotations:
            - type: pattern
              label: Staged Rollout
              text: >-
                Pausing a rollout mid-way lets you verify new Pods before rolling out to all replicas. This is
                a manual version of a canary strategy using native Kubernetes rollout controls.
            - type: gotcha
              label: Helm and Rollout Pause
              text: >-
                If you use --wait with helm upgrade, the command will hang while the rollout is paused. Omit --wait
                when you plan to pause the rollout manually.
