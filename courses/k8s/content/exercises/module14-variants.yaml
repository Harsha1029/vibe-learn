conceptLinks:
  Debugging Commands: "#lesson-debugging-commands"
  Pod Status Diagnosis: "#lesson-pod-status-diagnosis"
  Service Debugging: "#lesson-service-debugging"
  Pod Troubleshooting: "#lesson-pod-troubleshooting"
  Service Connectivity: "#lesson-service-connectivity"
  Multi-Layer Diagnosis: "#lesson-multi-layer-diagnosis"
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: Debugging Commands
      variants:
        - id: v1
          title: Describe a Failing Pod
          description: >-
            Write the <code>kubectl</code> command to get detailed information about a Pod named
            <code>web-frontend-7d9f8b6c5-abc12</code> in the <code>production</code> namespace, including events and
            conditions.
          hints:
            - Use <code>kubectl describe</code> to get detailed Pod info including events.
            - "Specify the namespace with <code>-n production</code>."
          solution: |-
            kubectl describe pod web-frontend-7d9f8b6c5-abc12 -n production
        - id: v2
          title: View Container Logs
          description: >-
            Write the <code>kubectl</code> command to view the last 100 lines of logs from a container named
            <code>nginx</code> inside the Pod <code>web-server-5c8d7b9f4-xyz99</code> in the <code>staging</code>
            namespace.
          hints:
            - Use <code>kubectl logs</code> with <code>-c</code> to specify the container.
            - Use <code>--tail=100</code> to limit output to the last 100 lines.
          solution: |-
            kubectl logs web-server-5c8d7b9f4-xyz99 -c nginx -n staging --tail=100
        - id: v3
          title: Get Cluster Events
          description: >-
            Write the <code>kubectl</code> command to list all events in the <code>default</code> namespace, sorted by
            the time they last occurred.
          hints:
            - Use <code>kubectl get events</code> with a sort option.
            - "The field to sort by is <code>.metadata.creationTimestamp</code> or <code>.lastTimestamp</code>."
          solution: |-
            kubectl get events -n default --sort-by='.lastTimestamp'
        - id: v4
          title: Exec Into a Running Container
          description: >-
            Write the <code>kubectl</code> command to open an interactive shell (<code>/bin/sh</code>) inside the
            container <code>app</code> of Pod <code>api-server-6f8c9d7e2-def34</code> in the <code>backend</code>
            namespace.
          hints:
            - Use <code>kubectl exec</code> with <code>-it</code> for interactive mode.
            - Specify the container with <code>-c app</code>.
          solution: |-
            kubectl exec -it api-server-6f8c9d7e2-def34 -c app -n backend -- /bin/sh
        - id: v5
          title: Check Resource Usage
          description: >-
            Write the <code>kubectl</code> command to view CPU and memory usage for all Pods in the
            <code>monitoring</code> namespace, sorted by CPU usage.
          hints:
            - Use <code>kubectl top pods</code> to view resource usage.
            - Use <code>--sort-by=cpu</code> to sort the output.
          solution: |-
            kubectl top pods -n monitoring --sort-by=cpu
        - id: v6
          title: Check Node Conditions
          description: >-
            Write the <code>kubectl</code> command to show the conditions (Ready, MemoryPressure, DiskPressure, etc.)
            for a node named <code>worker-node-03</code>.
          hints:
            - Use <code>kubectl describe node</code> to see conditions.
            - "Alternatively, use <code>kubectl get node</code> with a JSONPath to extract just conditions."
          solution: |-
            kubectl describe node worker-node-03
          annotations:
            - type: tip
              label: JSONPath Alternative
              text: >-
                For scripting, extract conditions directly:
                <code>kubectl get node worker-node-03 -o jsonpath='{.status.conditions[*].type}'</code>
        - id: v7
          title: View Previous Container Logs
          description: >-
            Write the <code>kubectl</code> command to view logs from the <em>previous</em> (crashed) instance of a
            container in Pod <code>worker-job-abc12</code> in the <code>batch</code> namespace.
          hints:
            - Use the <code>--previous</code> flag with <code>kubectl logs</code>.
            - This is essential for debugging CrashLoopBackOff pods.
          solution: |-
            kubectl logs worker-job-abc12 -n batch --previous
        - id: v8
          title: Get Pod Status with Wide Output
          description: >-
            Write the <code>kubectl</code> command to list all Pods in the <code>kube-system</code> namespace showing
            IP addresses, node assignments, and any nominated/readiness gates.
          hints:
            - Use <code>kubectl get pods</code> with <code>-o wide</code>.
            - This reveals which node each Pod runs on and its IP.
          solution: |-
            kubectl get pods -n kube-system -o wide
        - id: v9
          title: Debug DNS Resolution
          description: >-
            Write the <code>kubectl</code> command to run a temporary debug Pod using the <code>busybox</code> image
            to test DNS resolution of the service <code>my-service.default.svc.cluster.local</code>.
          hints:
            - Use <code>kubectl run</code> with <code>--rm -it</code> for a temporary interactive Pod.
            - Run <code>nslookup</code> inside the container to test DNS.
          solution: |-
            kubectl run dns-debug --rm -it --image=busybox --restart=Never -- nslookup my-service.default.svc.cluster.local
        - id: v10
          title: Check Pod Resource Requests and Limits
          description: >-
            Write the <code>kubectl</code> command to display the resource requests and limits for all containers in
            Pod <code>memory-hog-5c7d8e9f1-ghi56</code> in the <code>default</code> namespace using a custom output
            format.
          hints:
            - Use <code>kubectl get pod</code> with <code>-o jsonpath</code> to extract container resources.
            - "Alternatively, <code>kubectl describe pod</code> shows resources in the Containers section."
          solution: |-
            kubectl get pod memory-hog-5c7d8e9f1-ghi56 -o jsonpath='{range .spec.containers[*]}{.name}{"\t"}Requests: {.resources.requests}{"\t"}Limits: {.resources.limits}{"\n"}{end}'
          annotations:
            - type: tip
              label: Simpler Alternative
              text: >-
                <code>kubectl describe pod memory-hog-5c7d8e9f1-ghi56</code> is simpler for interactive debugging and
                shows the same resource information in a readable format.
        - id: v11
          title: Stream Logs in Real Time
          description: >-
            Write the <code>kubectl</code> command to follow (stream) the logs in real time from all containers in Pod
            <code>api-gateway-4b6c8d9e3-jkl78</code> in the <code>ingress</code> namespace.
          hints:
            - Use <code>-f</code> or <code>--follow</code> to stream logs.
            - Use <code>--all-containers</code> to include all containers in the Pod.
          solution: |-
            kubectl logs -f --all-containers api-gateway-4b6c8d9e3-jkl78 -n ingress
        - id: v12
          title: Get Pod YAML for Inspection
          description: >-
            Write the <code>kubectl</code> command to export the full YAML specification of Pod
            <code>broken-deploy-7f8e9d0c1-mno90</code> in the <code>qa</code> namespace for offline inspection.
          hints:
            - Use <code>kubectl get pod</code> with <code>-o yaml</code>.
            - You can redirect to a file for easier reading.
          solution: |-
            kubectl get pod broken-deploy-7f8e9d0c1-mno90 -n qa -o yaml
        - id: v13
          title: Check Cluster Component Health
          description: >-
            Write the <code>kubectl</code> command to check the health status of all control plane components
            (scheduler, controller-manager, etcd).
          hints:
            - Use <code>kubectl get componentstatuses</code> or its abbreviation.
            - Note that this command is deprecated in newer versions; check Pod health in kube-system instead.
          solution: |-
            kubectl get componentstatuses
          annotations:
            - type: tip
              label: Modern Alternative
              text: >-
                In Kubernetes 1.19+, <code>componentstatuses</code> is deprecated. Instead, check control plane Pod
                health with <code>kubectl get pods -n kube-system</code> or query the <code>/healthz</code> endpoint.
    - id: warmup_2
      concept: Pod Status Diagnosis
      variants:
        - id: v1
          title: Diagnose Pending Pod
          description: >-
            A Pod has been in <code>Pending</code> status for 10 minutes. List at least three likely root causes for
            why a Pod can get stuck in <code>Pending</code>.
          hints:
            - Think about what needs to happen before a Pod is scheduled to a node.
            - Consider resource availability, node selectors, and taints/tolerations.
          solution: |-
            Likely causes for a Pending Pod:
            1. Insufficient resources — no node has enough CPU or memory to satisfy the Pod's requests.
            2. Node selector or affinity mismatch — the Pod requires a specific node label that no node has.
            3. Taints and tolerations — all eligible nodes have taints the Pod does not tolerate.
            4. PersistentVolumeClaim not bound — the Pod references a PVC that has no matching PV.
            5. ResourceQuota exceeded — the namespace quota has been reached.
            6. Pod scheduling is blocked by a PodDisruptionBudget or priority preemption issue.
        - id: v2
          title: Diagnose ImagePullBackOff
          description: >-
            A Pod is in <code>ImagePullBackOff</code> status. List at least three likely root causes and the
            <code>kubectl</code> command you would use to confirm each cause.
          hints:
            - Check the Events section from <code>kubectl describe pod</code>.
            - Think about image name, registry authentication, and network.
          solution: |-
            Likely causes for ImagePullBackOff:
            1. Wrong image name or tag — typo in the image reference. Check: kubectl describe pod <name> and look at the Events for "repository does not exist" or "manifest unknown".
            2. Missing imagePullSecret — private registry requires credentials. Check: kubectl get pod <name> -o jsonpath='{.spec.imagePullSecrets}'.
            3. Registry unreachable — network policy or firewall blocks access. Check: kubectl exec into a debug pod and try curl <registry-url>.
            4. Image tag does not exist — the specific tag was deleted or never pushed. Check the Events for "not found".
            5. Rate limiting — Docker Hub or other registry rate-limited the pull. Check Events for "429 Too Many Requests".
        - id: v3
          title: Diagnose CrashLoopBackOff
          description: >-
            A Pod is in <code>CrashLoopBackOff</code> status. List at least three likely root causes and the debugging
            steps you would take to investigate.
          hints:
            - The container starts but exits immediately or shortly after.
            - Check both current and previous logs.
          solution: |-
            Likely causes for CrashLoopBackOff:
            1. Application error — the entrypoint crashes on startup. Debug: kubectl logs <pod> --previous to see crash output.
            2. Missing configuration — required environment variable or ConfigMap/Secret not set. Debug: kubectl describe pod <pod> to check env and volume mounts.
            3. Wrong command or args — the container command is misconfigured. Debug: kubectl get pod <pod> -o yaml and check spec.containers[].command and args.
            4. Liveness probe failing too aggressively — the probe kills the container before it is ready. Debug: check livenessProbe config in the Pod spec.
            5. Dependency not available — app tries to connect to a database or service that is down. Debug: kubectl logs <pod> --previous to see connection errors.
        - id: v4
          title: Diagnose OOMKilled
          description: >-
            A Pod shows status <code>OOMKilled</code> (exit code 137). List likely root causes and the steps to
            diagnose and resolve the issue.
          hints:
            - OOMKilled means the container exceeded its memory limit.
            - Check the container's memory limit versus actual memory usage.
          solution: |-
            Likely causes for OOMKilled (exit code 137):
            1. Memory limit too low — the application legitimately needs more memory than the limit allows. Fix: increase spec.containers[].resources.limits.memory.
            2. Memory leak — the application allocates memory without releasing it. Debug: kubectl top pod <pod> over time to see growing memory usage.
            3. JVM/runtime heap not aligned — for Java apps, -Xmx is set higher than the container limit. Fix: set -Xmx to ~75% of the container memory limit.
            4. Large data processing — the container loads large files or datasets into memory. Fix: use streaming or pagination instead of loading all data.
            Debug steps:
            - kubectl describe pod <pod> — check Last State for OOMKilled reason and exit code 137
            - kubectl top pod <pod> — check current memory usage
            - kubectl get pod <pod> -o jsonpath='{.spec.containers[*].resources}' — check configured limits
        - id: v5
          title: Diagnose ErrImageNeverPull
          description: >-
            A Pod shows status <code>ErrImageNeverPull</code>. What does this status mean and what causes it?
          hints:
            - This is related to the <code>imagePullPolicy</code> field.
            - Consider what happens when the image is not already present on the node.
          solution: |-
            ErrImageNeverPull means:
            - The Pod spec has imagePullPolicy: Never, but the required image is not present on the node.
            - This policy tells Kubernetes to NEVER pull the image from a registry and only use locally available images.

            Common causes:
            1. Image was built locally on a different node — the image exists on the build machine but not on the scheduled node.
            2. Minikube or kind usage — image was built on the host but not loaded into the cluster.
            3. Wrong imagePullPolicy — should be IfNotPresent or Always instead of Never.

            Fix: Change imagePullPolicy to IfNotPresent or Always, or ensure the image is available locally on every node.
        - id: v6
          title: Diagnose CreateContainerConfigError
          description: >-
            A Pod shows status <code>CreateContainerConfigError</code>. List likely root causes and how to diagnose
            them.
          hints:
            - This error occurs before the container starts.
            - It is related to the container configuration, not the application.
          solution: |-
            Likely causes for CreateContainerConfigError:
            1. Missing ConfigMap — the Pod references a ConfigMap that does not exist. Debug: kubectl describe pod <pod> and look for "configmap not found" in Events.
            2. Missing Secret — the Pod references a Secret that does not exist. Debug: kubectl get secret <name> -n <namespace> to verify it exists.
            3. Missing key in ConfigMap/Secret — the Pod references a specific key that does not exist in the ConfigMap or Secret.
            4. Invalid volume mount — the volume configuration references a non-existent resource.

            Debug: kubectl describe pod <pod> will show the exact missing resource in the Events section.
        - id: v7
          title: Diagnose RunContainerError
          description: >-
            A Pod shows status <code>RunContainerError</code>. List likely root causes and the steps to investigate.
          hints:
            - This happens when the container runtime fails to start the container.
            - Think about volume mounts, security contexts, and capabilities.
          solution: |-
            Likely causes for RunContainerError:
            1. Volume mount failure — a hostPath volume references a path that does not exist on the node. Debug: kubectl describe pod <pod> to see mount errors.
            2. Security context issues — the container requests a user ID that is not allowed. Debug: check securityContext settings in the Pod spec.
            3. Invalid device or capability — the Pod requests a GPU or device that is not available. Debug: check the Events and node resources.
            4. Read-only filesystem conflict — the container tries to write to a read-only mount.

            Debug steps:
            - kubectl describe pod <pod> — check Events for specific error messages
            - kubectl get pod <pod> -o yaml — inspect volume mounts, security context, and capabilities
        - id: v8
          title: Diagnose Pod Eviction
          description: >-
            Pods on a node are being evicted. What conditions cause Kubernetes to evict Pods and how do you investigate?
          hints:
            - Node pressure conditions trigger eviction.
            - Check node status and resource thresholds.
          solution: |-
            Pod eviction causes:
            1. DiskPressure — node disk usage exceeds the eviction threshold (default 85%). Pods using ephemeral storage are evicted first.
            2. MemoryPressure — node memory is critically low. Pods exceeding their memory requests are evicted.
            3. PID pressure — too many processes on the node.
            4. Node NotReady — kubelet cannot communicate with the API server.

            Investigation steps:
            - kubectl describe node <node> — check Conditions section for pressure flags
            - kubectl get events --field-selector reason=Evicted — list eviction events
            - kubectl top node <node> — check current resource usage
            - Check kubelet logs on the node for eviction threshold details
        - id: v9
          title: Diagnose Pod Stuck in Terminating
          description: >-
            A Pod has been in <code>Terminating</code> status for over 10 minutes. List likely causes and how to
            resolve the issue.
          hints:
            - The Pod is not shutting down gracefully within the termination grace period.
            - Consider finalizers and node issues.
          solution: |-
            Likely causes for a Pod stuck in Terminating:
            1. Finalizers blocking deletion — a finalizer is set on the Pod and the controller responsible has not removed it. Debug: kubectl get pod <pod> -o jsonpath='{.metadata.finalizers}'.
            2. Node is down — the kubelet on the node is unreachable so it cannot confirm deletion. Debug: kubectl get nodes and check the node status.
            3. Process ignoring SIGTERM — the application does not handle graceful shutdown. The Pod waits for terminationGracePeriodSeconds (default 30s).
            4. Persistent volume detach stuck — the volume cannot be unmounted.

            Resolution:
            - Wait for the grace period to expire (kubelet sends SIGKILL after)
            - If node is down: kubectl delete pod <pod> --grace-period=0 --force
            - Remove finalizers: kubectl patch pod <pod> -p '{"metadata":{"finalizers":null}}'
        - id: v10
          title: Diagnose Init Container Failure
          description: >-
            A Pod is stuck in <code>Init:0/2</code> status. What does this mean and how do you debug it?
          hints:
            - Init containers run before the main containers.
            - The <code>0/2</code> means zero of two init containers have completed.
          solution: |-
            Init:0/2 means:
            - The Pod has 2 init containers defined and none have completed yet.
            - The first init container is either still running or has failed.
            - Init containers run sequentially — the second will not start until the first succeeds.

            Debug steps:
            1. kubectl describe pod <pod> — check the Init Containers section for status and events
            2. kubectl logs <pod> -c <init-container-name> — view the first init container's logs
            3. Common causes:
               - Init container waiting for a dependency (database, service) to become available
               - Init container command has an error
               - Init container image cannot be pulled
               - Volume mount fails for the init container
    - id: warmup_3
      concept: Service Debugging
      variants:
        - id: v1
          title: Check Service Endpoints
          description: >-
            Write the <code>kubectl</code> command to check whether a Service named <code>backend-svc</code> in the
            <code>app</code> namespace has any endpoints (backing Pods).
          hints:
            - Use <code>kubectl get endpoints</code> to see which Pod IPs back a Service.
            - No endpoints means no Pods match the Service selector.
          solution: |-
            kubectl get endpoints backend-svc -n app
        - id: v2
          title: Compare Service Selector to Pod Labels
          description: >-
            A Service named <code>web-svc</code> has no endpoints. Write the commands to compare the Service selector
            with the labels on the Pods to find the mismatch.
          hints:
            - Get the Service selector with <code>kubectl get svc</code> and a JSONPath.
            - Get Pod labels with <code>kubectl get pods --show-labels</code>.
          solution: |-
            # Step 1: Get the Service selector
            kubectl get svc web-svc -o jsonpath='{.spec.selector}'

            # Step 2: List Pods with their labels
            kubectl get pods --show-labels

            # Step 3: Try selecting Pods using the Service's selector
            kubectl get pods -l app=web
          annotations:
            - type: tip
              label: Quick Check
              text: >-
                The fastest way to check is to copy the selector from the Service and use it with
                <code>kubectl get pods -l key=value</code>. If no Pods are returned, the labels do not match.
        - id: v3
          title: Test Service Connectivity from a Pod
          description: >-
            Write the <code>kubectl</code> command to test connectivity to Service <code>api-svc</code> on port
            <code>8080</code> from inside the cluster using a temporary debug Pod.
          hints:
            - Use <code>kubectl run</code> with <code>--rm -it</code> and a networking-capable image.
            - Use <code>wget</code> or <code>curl</code> to test the connection.
          solution: |-
            kubectl run net-debug --rm -it --image=busybox --restart=Never -- wget -qO- http://api-svc:8080
        - id: v4
          title: Check Service Port Configuration
          description: >-
            A Service is reachable but returns connection refused. Write the commands to verify the Service port
            configuration matches the container's listening port.
          hints:
            - Check the Service's <code>port</code> and <code>targetPort</code>.
            - Compare with the container's <code>containerPort</code>.
          solution: |-
            # Check the Service port mapping
            kubectl get svc <service-name> -o jsonpath='{.spec.ports[*]}'

            # Check what port the container is configured to listen on
            kubectl get pod <pod-name> -o jsonpath='{.spec.containers[*].ports[*]}'

            # Verify the process is actually listening inside the container
            kubectl exec <pod-name> -- netstat -tlnp
          annotations:
            - type: tip
              label: Port Fields
              text: >-
                Service <code>port</code> is what clients connect to. <code>targetPort</code> is forwarded to the Pod.
                The container must actually listen on <code>targetPort</code>. If <code>targetPort</code> is omitted,
                it defaults to the same value as <code>port</code>.
        - id: v5
          title: Debug ClusterIP Service
          description: >-
            Write the commands to verify that a <code>ClusterIP</code> Service named <code>redis-svc</code> in
            namespace <code>cache</code> is functioning correctly, including DNS resolution and connectivity.
          hints:
            - Test DNS resolution first, then try connecting to the Service.
            - Use both the short and fully qualified DNS names.
          solution: |-
            # Check Service exists and has a ClusterIP
            kubectl get svc redis-svc -n cache

            # Check endpoints exist
            kubectl get endpoints redis-svc -n cache

            # Test DNS resolution from within the cluster
            kubectl run dns-test --rm -it --image=busybox --restart=Never -- nslookup redis-svc.cache.svc.cluster.local

            # Test connectivity
            kubectl run conn-test --rm -it --image=busybox --restart=Never -n cache -- nc -zv redis-svc 6379
        - id: v6
          title: Debug NodePort Not Reachable
          description: >-
            A <code>NodePort</code> Service is configured but external clients cannot reach it. List the debugging
            steps and the commands to investigate.
          hints:
            - Check the NodePort allocation, firewall rules, and node network.
            - Verify the Service has endpoints.
          solution: |-
            Debug steps for unreachable NodePort:
            # 1. Verify Service exists and has NodePort assigned
            kubectl get svc <service-name> -o wide

            # 2. Check endpoints exist
            kubectl get endpoints <service-name>

            # 3. Verify connectivity from the node itself
            curl http://localhost:<nodeport>

            # 4. Check kube-proxy is running
            kubectl get pods -n kube-system -l k8s-app=kube-proxy

            # 5. Check firewall rules allow the NodePort range (default 30000-32767)
            # On cloud providers, check security group / firewall rules

            # 6. Check if the node's external IP is correct
            kubectl get nodes -o wide
        - id: v7
          title: Service with Multiple Ports
          description: >-
            A Service exposes both HTTP (port 80) and HTTPS (port 443) but only HTTP works. Write the commands to
            debug why HTTPS is not routing correctly.
          hints:
            - Each port in the Service must have a matching <code>targetPort</code>.
            - Check that the container listens on both target ports.
          solution: |-
            # Check Service port configuration
            kubectl get svc <service-name> -o yaml | grep -A5 ports

            # Verify both targetPorts match container ports
            kubectl get pod <pod-name> -o jsonpath='{.spec.containers[*].ports}'

            # Test connectivity to each port individually
            kubectl run port-test --rm -it --image=busybox --restart=Never -- sh -c 'nc -zv <service-name> 80 && nc -zv <service-name> 443'

            # Check container is listening on both ports
            kubectl exec <pod-name> -- netstat -tlnp
        - id: v8
          title: Headless Service No DNS Records
          description: >-
            A headless Service (<code>clusterIP: None</code>) is not returning DNS A records for individual Pods.
            What are the likely causes?
          hints:
            - Headless Services return Pod IPs directly via DNS.
            - Pods need to be Ready and have the correct labels.
          solution: |-
            Likely causes for headless Service DNS failure:
            1. No Pods match the selector — check labels match: kubectl get pods --show-labels
            2. Pods are not Ready — only Ready Pods are included in DNS by default. Check: kubectl get pods and look for non-Ready Pods.
            3. publishNotReadyAddresses not set — if Pods need to be discoverable before Ready, set spec.publishNotReadyAddresses: true.
            4. Missing subdomain/hostname — for StatefulSet Pods to get individual DNS records (pod-0.svc), the StatefulSet must reference the Service via spec.serviceName.

            Debug:
            kubectl get endpoints <service-name> -o yaml
            kubectl run dns-test --rm -it --image=busybox --restart=Never -- nslookup <service-name>
        - id: v9
          title: Verify kube-proxy Mode
          description: >-
            Write the commands to check what mode <code>kube-proxy</code> is running in (iptables, IPVS, or
            userspace) and verify that proxy rules exist for a given Service.
          hints:
            - Check kube-proxy logs or configmap.
            - Use iptables or ipvsadm on the node to verify rules.
          solution: |-
            # Check kube-proxy configuration
            kubectl get configmap kube-proxy -n kube-system -o yaml | grep mode

            # Check kube-proxy logs for mode information
            kubectl logs -n kube-system -l k8s-app=kube-proxy --tail=20

            # On a node, verify iptables rules for a Service (iptables mode)
            iptables -t nat -L KUBE-SERVICES | grep <service-name>

            # Or for IPVS mode
            ipvsadm -Ln | grep <cluster-ip>
        - id: v10
          title: Debug ExternalName Service
          description: >-
            An <code>ExternalName</code> Service is returning <code>NXDOMAIN</code> when accessed from within the
            cluster. List the debugging steps.
          hints:
            - ExternalName Services create a CNAME record.
            - Check that the external hostname is valid and resolvable.
          solution: |-
            Debug steps for ExternalName NXDOMAIN:
            # 1. Check Service configuration
            kubectl get svc <service-name> -o yaml

            # 2. Verify the externalName value is a valid DNS name
            kubectl get svc <service-name> -o jsonpath='{.spec.externalName}'

            # 3. Test DNS resolution from within the cluster
            kubectl run dns-test --rm -it --image=busybox --restart=Never -- nslookup <service-name>

            # 4. Test direct resolution of the external name
            kubectl run dns-test2 --rm -it --image=busybox --restart=Never -- nslookup <external-hostname>

            Common causes:
            - externalName has a typo
            - External DNS name does not exist
            - Cluster DNS cannot resolve external names (CoreDNS upstream config)
            - externalName includes a protocol prefix (should be hostname only, not http://...)
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 1
      concept: Pod Troubleshooting
      variants:
        - id: v1
          title: Fix Wrong Image Name
          description: >-
            A Deployment's Pods are in <code>ImagePullBackOff</code>. The <code>kubectl describe pod</code> output
            shows:<br><br>
            <pre>Events:
              Warning  Failed   pull image "ngix:latest": rpc error: code = NotFound
              Warning  Failed   Error: ErrImagePull
              Warning  BackOff  Back-off pulling image "ngix:latest"</pre><br>
            Identify the root cause and write the <code>kubectl</code> command to fix it.
          functionSignature: "Diagnosis and kubectl fix command"
          testCases:
            - input: 'Pod status: ImagePullBackOff, image: "ngix:latest"'
              output: 'Root cause: typo in image name (ngix instead of nginx). Fix: kubectl set image deployment/<name> <container>=nginx:latest'
          hints:
            - title: "\U0001F914 Think about it"
              content: Look at the image name carefully. Does it match a valid image on Docker Hub?
            - title: "\U0001F4A1 Hint"
              content: >-
                The image name is <code>ngix:latest</code> but the correct image is <code>nginx:latest</code>. The
                letter 'n' is missing.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Read the event: "pull image ngix:latest"
                2. Identify typo: ngix -> nginx
                3. Fix with kubectl set image</pre>
          solution: |-
            # Root cause: image name typo — "ngix" should be "nginx"

            # Fix the image in the Deployment
            kubectl set image deployment/<deployment-name> <container-name>=nginx:latest
          difficulty: 1
          annotations:
            - type: tip
              label: Image Names
              text: >-
                Always double-check image names and tags. Common mistakes include typos, missing registry prefixes, and
                using tags that do not exist. Use <code>docker pull</code> locally to verify an image exists.
        - id: v2
          title: Fix Missing ConfigMap
          description: >-
            A Pod is in <code>CreateContainerConfigError</code>. The <code>kubectl describe pod</code> output
            shows:<br><br>
            <pre>Events:
              Warning  Failed  Error: configmap "app-config" not found</pre><br>
            The Pod spec references:<br>
            <pre>envFrom:
            - configMapRef:
                name: app-config</pre><br>
            Identify the root cause and write the commands to fix it.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Pod status: CreateContainerConfigError, configmap 'app-config' not found"
              output: "Root cause: referenced ConfigMap does not exist. Fix: create the missing ConfigMap."
          hints:
            - title: "\U0001F914 Think about it"
              content: The Pod expects a ConfigMap that does not exist. You need to create it before the Pod can start.
            - title: "\U0001F4A1 Hint"
              content: >-
                Create the ConfigMap with the expected name. You need to know what keys and values the application
                expects, or create it with placeholder values.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Confirm ConfigMap is missing: kubectl get configmap app-config
                2. Create ConfigMap with required data
                3. Pod will restart automatically</pre>
          solution: |-
            # Root cause: ConfigMap "app-config" does not exist in the namespace

            # Verify it is missing
            kubectl get configmap app-config

            # Create the ConfigMap with required keys
            kubectl create configmap app-config \
              --from-literal=DATABASE_URL=postgres://db:5432/app \
              --from-literal=LOG_LEVEL=info

            # The Pod will be restarted automatically by the kubelet
          difficulty: 1
          annotations:
            - type: tip
              label: ConfigMap Dependencies
              text: >-
                Always deploy ConfigMaps and Secrets before the Deployments that reference them. Use Helm or Kustomize
                to manage deployment ordering.
        - id: v3
          title: Fix OOMKilled Container
          description: >-
            A Pod keeps restarting with <code>OOMKilled</code> status. The <code>kubectl describe pod</code> output
            shows:<br><br>
            <pre>Last State:  Terminated
              Reason:    OOMKilled
              Exit Code: 137
            Containers:
              app:
                Limits:
                  memory: 64Mi
                Requests:
                  memory: 64Mi</pre><br>
            The application is a Java service that requires at least 256Mi of memory. Write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Pod OOMKilled with memory limit 64Mi, app needs 256Mi"
              output: "Root cause: memory limit too low. Fix: increase memory limit to at least 256Mi."
          hints:
            - title: "\U0001F914 Think about it"
              content: The container is killed because it exceeded its 64Mi memory limit. The application needs 256Mi.
            - title: "\U0001F4A1 Hint"
              content: >-
                Patch the Deployment to increase the memory limit. For Java apps, also ensure the JVM heap is set
                appropriately relative to the container limit.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Identify OOMKilled reason and current limit (64Mi)
                2. Application requires 256Mi minimum
                3. Set limit to 512Mi (headroom) and request to 256Mi
                4. For Java: set -Xmx to ~75% of limit</pre>
          solution: |-
            # Root cause: memory limit (64Mi) is far below what the app requires (256Mi)

            # Fix: patch the Deployment to increase memory limits
            kubectl patch deployment <deployment-name> --type='json' -p='[
              {"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": "512Mi"},
              {"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/memory", "value": "256Mi"}
            ]'

            # For Java applications, also set JVM heap:
            # Add env var: JAVA_OPTS="-Xmx384m -Xms256m"
          difficulty: 2
          annotations:
            - type: tip
              label: Memory Sizing
              text: >-
                Set the memory limit higher than the request to allow for spikes. For Java, set <code>-Xmx</code> to
                about 75% of the container memory limit to leave room for non-heap memory (metaspace, threads, etc.).
        - id: v4
          title: Fix CrashLoopBackOff from Bad Command
          description: >-
            A Pod is in <code>CrashLoopBackOff</code>. The <code>kubectl logs --previous</code> output
            shows:<br><br>
            <pre>/bin/sh: /app/startserver.sh: not found</pre><br>
            The Pod spec shows:<br>
            <pre>command: ["/app/startserver.sh"]</pre><br>
            The correct entrypoint is <code>/app/start-server.sh</code>. Write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "CrashLoopBackOff, command /app/startserver.sh not found"
              output: "Root cause: wrong command path. Fix: correct to /app/start-server.sh"
          hints:
            - title: "\U0001F914 Think about it"
              content: The container starts but the entrypoint script does not exist at the specified path.
            - title: "\U0001F4A1 Hint"
              content: >-
                The command path has a typo — missing the hyphen. The correct path is
                <code>/app/start-server.sh</code>.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Check logs --previous: "not found"
                2. Compare command in spec with actual file path
                3. Fix the command path in the Deployment</pre>
          solution: |-
            # Root cause: wrong command path — "startserver.sh" should be "start-server.sh"

            # Fix: edit the Deployment to correct the command
            kubectl edit deployment <deployment-name>
            # Change: command: ["/app/startserver.sh"]
            # To:     command: ["/app/start-server.sh"]

            # Or use patch:
            kubectl patch deployment <deployment-name> --type='json' -p='[
              {"op": "replace", "path": "/spec/template/spec/containers/0/command", "value": ["/app/start-server.sh"]}
            ]'
          difficulty: 1
        - id: v5
          title: Fix Pending Pod with Insufficient CPU
          description: >-
            A Pod has been <code>Pending</code> for 20 minutes. The <code>kubectl describe pod</code> output
            shows:<br><br>
            <pre>Events:
              Warning  FailedScheduling  0/3 nodes are available: 3 Insufficient cpu.
            Containers:
              app:
                Requests:
                  cpu: 8
                  memory: 1Gi</pre><br>
            The cluster has 3 nodes, each with 4 CPUs. Write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Pending Pod requesting 8 CPUs, nodes have 4 CPUs each"
              output: "Root cause: CPU request exceeds node capacity. Fix: reduce CPU request."
          hints:
            - title: "\U0001F914 Think about it"
              content: No single node has 8 CPUs available. The Pod's request cannot be satisfied.
            - title: "\U0001F4A1 Hint"
              content: >-
                Either reduce the CPU request to fit on a node (e.g., 2 or 4 CPUs) or add a node with more CPUs to
                the cluster.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Read event: "3 Insufficient cpu"
                2. Pod requests 8 CPU, nodes have 4 CPU each
                3. Reduce CPU request to <= 4 (minus system overhead)
                4. Or scale up nodes</pre>
          solution: |-
            # Root cause: Pod requests 8 CPUs but no node has that many available (max 4 per node)

            # Fix: reduce the CPU request to a value that fits
            kubectl patch deployment <deployment-name> --type='json' -p='[
              {"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/cpu", "value": "2"}
            ]'

            # Alternative: add a larger node to the cluster with >= 8 CPUs
          difficulty: 1
          annotations:
            - type: tip
              label: Resource Requests
              text: >-
                CPU requests must be satisfiable by a single node. Unlike memory, CPU cannot be combined across nodes.
                Always check node capacity with <code>kubectl describe node</code> before setting large requests.
        - id: v6
          title: Fix Missing Secret Volume
          description: >-
            A Pod is in <code>CreateContainerConfigError</code>. The <code>kubectl describe pod</code> output
            shows:<br><br>
            <pre>Events:
              Warning  Failed  Error: secret "tls-cert" not found
            Volumes:
              tls-volume:
                Type:   Secret (a volume populated by a Secret)
                SecretName: tls-cert</pre><br>
            Write the commands to create the missing Secret and fix the Pod.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "CreateContainerConfigError, secret 'tls-cert' not found"
              output: "Root cause: referenced Secret does not exist. Fix: create the TLS Secret."
          hints:
            - title: "\U0001F914 Think about it"
              content: The Pod expects a Secret named tls-cert to be mounted as a volume.
            - title: "\U0001F4A1 Hint"
              content: >-
                Create the missing TLS Secret using <code>kubectl create secret tls</code> with the certificate and
                key files.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Confirm Secret is missing
                2. Create TLS Secret with cert and key
                3. Pod restarts automatically</pre>
          solution: |-
            # Root cause: Secret "tls-cert" does not exist

            # Verify it is missing
            kubectl get secret tls-cert

            # Create the TLS Secret
            kubectl create secret tls tls-cert \
              --cert=path/to/tls.crt \
              --key=path/to/tls.key

            # The Pod will restart automatically and mount the Secret volume
          difficulty: 2
        - id: v7
          title: Fix Liveness Probe CrashLoop
          description: >-
            A Pod is in <code>CrashLoopBackOff</code>. The <code>kubectl describe pod</code> output
            shows:<br><br>
            <pre>Events:
              Warning  Unhealthy  Liveness probe failed: Get "http://10.1.0.15:8080/healthz": dial tcp 10.1.0.15:8080: connect: connection refused
              Normal   Killing    Container app failed liveness probe, will be restarted
            Containers:
              app:
                Liveness:  http-get http://:8080/healthz delay=0s timeout=1s period=10s #failure=3</pre><br>
            The application takes 30 seconds to start. Write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "CrashLoopBackOff, liveness probe failing during startup, app needs 30s to start"
              output: "Root cause: no initial delay on liveness probe. Fix: add initialDelaySeconds or startupProbe."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                The liveness probe starts checking immediately (delay=0s), but the app takes 30 seconds to start.
                The probe fails 3 times and kills the container before it can become ready.
            - title: "\U0001F4A1 Hint"
              content: >-
                Add <code>initialDelaySeconds: 45</code> to the liveness probe, or add a separate
                <code>startupProbe</code> that allows time for the application to initialize.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Liveness probe has no startup delay
                2. App takes 30s to start
                3. Probe kills container before it is ready
                4. Fix: add initialDelaySeconds or startupProbe</pre>
          solution: |-
            # Root cause: liveness probe has no initialDelaySeconds and the app needs 30s to start
            # The probe kills the container before it can finish starting up

            # Fix option 1: Add initialDelaySeconds to the liveness probe
            kubectl patch deployment <deployment-name> --type='json' -p='[
              {"op": "add", "path": "/spec/template/spec/containers/0/livenessProbe/initialDelaySeconds", "value": 45}
            ]'

            # Fix option 2 (preferred): Add a startupProbe
            kubectl edit deployment <deployment-name>
            # Add under the container spec:
            #   startupProbe:
            #     httpGet:
            #       path: /healthz
            #       port: 8080
            #     failureThreshold: 10
            #     periodSeconds: 5
          difficulty: 2
          annotations:
            - type: tip
              label: Startup vs Liveness
              text: >-
                Use <code>startupProbe</code> for slow-starting apps instead of a large
                <code>initialDelaySeconds</code> on the liveness probe. The startup probe runs first and disables the
                liveness probe until it succeeds.
        - id: v8
          title: Fix Pod with Unbound PVC
          description: >-
            A Pod is <code>Pending</code> with the following events:<br><br>
            <pre>Events:
              Warning  FailedScheduling  0/3 nodes are available: 3 pod has unbound immediate PersistentVolumeClaims.
            Volumes:
              data-volume:
                Type:       PersistentVolumeClaim
                ClaimName:  data-pvc</pre><br>
            The PVC <code>data-pvc</code> shows status <code>Pending</code>. The cluster has no dynamic provisioner
            configured. Write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Pending Pod, PVC unbound, no dynamic provisioner"
              output: "Root cause: PVC has no matching PV. Fix: create a PV or configure a StorageClass."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                The PVC is Pending because no PersistentVolume matches its request and no StorageClass can dynamically
                provision one.
            - title: "\U0001F4A1 Hint"
              content: >-
                Either create a PersistentVolume that matches the PVC's requirements (size, access modes,
                storageClassName) or set up a dynamic provisioner.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Check PVC status: kubectl get pvc data-pvc
                2. Check if any PVs exist: kubectl get pv
                3. Create matching PV or configure StorageClass
                4. PVC binds, Pod schedules</pre>
          solution: |-
            # Root cause: PVC "data-pvc" is unbound — no PV matches and no dynamic provisioner exists

            # Check PVC requirements
            kubectl get pvc data-pvc -o yaml

            # Fix: create a PersistentVolume that matches
            cat <<EOF | kubectl apply -f -
            apiVersion: v1
            kind: PersistentVolume
            metadata:
              name: data-pv
            spec:
              capacity:
                storage: 10Gi
              accessModes:
                - ReadWriteOnce
              hostPath:
                path: /mnt/data
            EOF

            # The PVC will bind to the PV and the Pod will be scheduled
          difficulty: 2
    - id: challenge_2
      block: 2
      difficulty: 2
      concept: Service Connectivity
      variants:
        - id: v1
          title: Fix Label Mismatch
          description: >-
            A Service named <code>frontend-svc</code> has zero endpoints. Investigation
            shows:<br><br>
            <pre># kubectl get svc frontend-svc -o jsonpath='{.spec.selector}'
            {"app":"frontend"}

            # kubectl get pods --show-labels
            NAME                       LABELS
            frontend-7d9f8b-abc12      app=front-end,tier=web
            frontend-7d9f8b-def34      app=front-end,tier=web</pre><br>
            Identify the root cause and write the fix.
          functionSignature: "Diagnosis and kubectl fix"
          testCases:
            - input: "Service selector: app=frontend, Pod labels: app=front-end"
              output: "Root cause: label mismatch (frontend vs front-end). Fix: update either the Service selector or Pod labels."
          hints:
            - title: "\U0001F914 Think about it"
              content: Compare the Service selector labels with the Pod labels. Do they match exactly?
            - title: "\U0001F4A1 Hint"
              content: >-
                The Service selects <code>app=frontend</code> but the Pods have
                <code>app=front-end</code>. The hyphen makes the difference.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Service selector: app=frontend
                2. Pod labels: app=front-end
                3. "frontend" != "front-end"
                4. Fix the selector OR the labels to match</pre>
          solution: |-
            # Root cause: Service selector "app=frontend" does not match Pod label "app=front-end"

            # Fix option 1: Update the Service selector to match the Pods
            kubectl patch svc frontend-svc --type='json' -p='[
              {"op": "replace", "path": "/spec/selector/app", "value": "front-end"}
            ]'

            # Fix option 2: Update the Deployment labels to match the Service
            kubectl patch deployment frontend --type='json' -p='[
              {"op": "replace", "path": "/spec/template/metadata/labels/app", "value": "frontend"},
              {"op": "replace", "path": "/spec/selector/matchLabels/app", "value": "frontend"}
            ]'

            # Verify endpoints are now populated
            kubectl get endpoints frontend-svc
          difficulty: 2
          annotations:
            - type: tip
              label: Label Matching
              text: >-
                Service selectors use exact string matching. <code>frontend</code> and <code>front-end</code> are
                different labels. Always verify with <code>kubectl get endpoints</code> after creating a Service.
        - id: v2
          title: Fix Wrong Target Port
          description: >-
            A Service is reachable but returns <code>Connection refused</code>. Investigation
            shows:<br><br>
            <pre># kubectl get svc api-svc -o yaml (ports section)
            ports:
            - port: 80
              targetPort: 3000
              protocol: TCP

            # kubectl exec api-pod -- netstat -tlnp
            tcp  0  0  0.0.0.0:8080  0.0.0.0:*  LISTEN  1/node</pre><br>
            Identify the root cause and write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Service targetPort=3000, container listening on 8080"
              output: "Root cause: targetPort mismatch. Fix: change targetPort to 8080."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                The Service forwards traffic to port 3000 on the Pod, but what port is the application actually
                listening on?
            - title: "\U0001F4A1 Hint"
              content: >-
                The container listens on port 8080 but the Service targetPort is 3000. Traffic is forwarded to a port
                where nothing is listening.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Service forwards to targetPort 3000
                2. Container listens on 8080
                3. Fix: change targetPort to 8080</pre>
          solution: |-
            # Root cause: Service targetPort (3000) does not match the container's listening port (8080)

            # Fix: update the Service targetPort
            kubectl patch svc api-svc --type='json' -p='[
              {"op": "replace", "path": "/spec/ports/0/targetPort", "value": 8080}
            ]'

            # Verify connectivity
            kubectl run test --rm -it --image=busybox --restart=Never -- wget -qO- http://api-svc
          difficulty: 2
        - id: v3
          title: Fix Cross-Namespace Service Access
          description: >-
            A Pod in the <code>frontend</code> namespace is trying to reach a Service in the <code>backend</code>
            namespace using <code>http://api-svc:8080</code> but gets <code>NXDOMAIN</code>.<br><br>
            <pre># From a Pod in frontend namespace:
            $ wget http://api-svc:8080
            wget: bad address 'api-svc:8080'</pre><br>
            The Service <code>api-svc</code> exists in the <code>backend</code> namespace. Write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Frontend Pod cannot reach api-svc in backend namespace using short name"
              output: "Root cause: cross-namespace DNS requires FQDN. Fix: use api-svc.backend.svc.cluster.local"
          hints:
            - title: "\U0001F914 Think about it"
              content: Short Service names only resolve within the same namespace. How do you reference a Service in a different namespace?
            - title: "\U0001F4A1 Hint"
              content: >-
                Use the fully qualified DNS name: <code>api-svc.backend.svc.cluster.local</code> or the shorter form
                <code>api-svc.backend</code>.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Short name "api-svc" only resolves in same namespace
                2. Service is in "backend" namespace, Pod is in "frontend"
                3. Fix: use "api-svc.backend" or full FQDN</pre>
          solution: |-
            # Root cause: short Service name only resolves within the same namespace
            # "api-svc" resolves to "api-svc.frontend.svc.cluster.local" from the frontend namespace

            # Fix: use the cross-namespace DNS name in the application configuration
            # Change URL from: http://api-svc:8080
            # To: http://api-svc.backend.svc.cluster.local:8080
            # Or shorter: http://api-svc.backend:8080

            # If the URL is configured via a ConfigMap:
            kubectl patch configmap app-config -n frontend --type='json' -p='[
              {"op": "replace", "path": "/data/API_URL", "value": "http://api-svc.backend.svc.cluster.local:8080"}
            ]'

            # Restart Pods to pick up the config change
            kubectl rollout restart deployment frontend -n frontend
          difficulty: 3
          annotations:
            - type: tip
              label: Service DNS
              text: >-
                Kubernetes DNS follows the pattern: <code>&lt;service&gt;.&lt;namespace&gt;.svc.cluster.local</code>.
                Within the same namespace, just the service name works. Across namespaces, you must include at least
                <code>&lt;service&gt;.&lt;namespace&gt;</code>.
        - id: v4
          title: Fix Service Protocol Mismatch
          description: >-
            A gRPC application cannot connect through a Service. Investigation shows:<br><br>
            <pre># kubectl get svc grpc-svc -o yaml (ports section)
            ports:
            - name: grpc
              port: 50051
              targetPort: 50051
              protocol: TCP

            # Application logs:
            ERROR: connection reset, received HTTP/1.1 response</pre><br>
            The Service is behind an Ingress. Identify the issue and write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "gRPC through Ingress failing with HTTP/1.1 response"
              output: "Root cause: Ingress not configured for gRPC/HTTP2. Fix: add gRPC annotation to Ingress."
          hints:
            - title: "\U0001F914 Think about it"
              content: gRPC requires HTTP/2. Is the Ingress controller configured to use HTTP/2 for backend connections?
            - title: "\U0001F4A1 Hint"
              content: >-
                The Ingress controller defaults to HTTP/1.1 for backend connections. gRPC needs HTTP/2. Add the
                appropriate annotation for your Ingress controller.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. gRPC requires HTTP/2
                2. Ingress defaults to HTTP/1.1 backends
                3. Add annotation for gRPC/HTTP2 backend protocol
                4. For nginx-ingress: nginx.ingress.kubernetes.io/backend-protocol: "GRPC"</pre>
          solution: |-
            # Root cause: Ingress is proxying with HTTP/1.1 but gRPC requires HTTP/2

            # Fix: add the gRPC backend protocol annotation to the Ingress
            kubectl annotate ingress <ingress-name> \
              nginx.ingress.kubernetes.io/backend-protocol="GRPC" --overwrite

            # Full Ingress fix if editing YAML:
            # metadata:
            #   annotations:
            #     nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
            # spec:
            #   rules:
            #   - host: grpc.example.com
            #     http:
            #       paths:
            #       - path: /
            #         pathType: Prefix
            #         backend:
            #           service:
            #             name: grpc-svc
            #             port:
            #               number: 50051
          difficulty: 3
        - id: v5
          title: Fix Endpoints Not Updating
          description: >-
            After scaling a Deployment from 1 to 5 replicas, the Service still only routes to 1 Pod. Investigation
            shows:<br><br>
            <pre># kubectl get endpoints my-svc
            NAME     ENDPOINTS
            my-svc   10.1.0.5:8080

            # kubectl get pods -o wide
            NAME                    IP          STATUS
            app-6f8c9-abc12         10.1.0.5    Running (Ready)
            app-6f8c9-def34         10.1.0.6    Running (Not Ready)
            app-6f8c9-ghi56         10.1.0.7    Running (Not Ready)
            app-6f8c9-jkl78         10.1.0.8    Running (Not Ready)
            app-6f8c9-mno90         10.1.0.9    Running (Not Ready)</pre><br>
            Identify the root cause and write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "5 Pods running but only 1 endpoint, 4 Pods not Ready"
              output: "Root cause: readiness probe failing on new Pods. Fix: investigate and fix the readiness probe."
          hints:
            - title: "\U0001F914 Think about it"
              content: Only Ready Pods are included in Service endpoints. Why are 4 Pods not Ready?
            - title: "\U0001F4A1 Hint"
              content: >-
                The new Pods are Running but not Ready, meaning the readiness probe is failing. Check the readiness
                probe configuration and why it fails on the new Pods.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. 4 of 5 Pods are Not Ready
                2. Only Ready Pods appear in endpoints
                3. Check readiness probe: kubectl describe pod <not-ready-pod>
                4. Fix the readiness probe or the condition it checks</pre>
          solution: |-
            # Root cause: new Pods are not passing the readiness probe, so they are excluded from endpoints

            # Step 1: Check why Pods are not Ready
            kubectl describe pod app-6f8c9-def34

            # Look for readiness probe failures in Events:
            # "Readiness probe failed: ..."

            # Common fixes:
            # - If probe path is wrong: fix the httpGet path
            # - If probe port is wrong: fix the port
            # - If app needs time: increase initialDelaySeconds
            # - If dependency is missing: fix the dependency

            # Example fix for a readiness probe with wrong path:
            kubectl patch deployment app --type='json' -p='[
              {"op": "replace", "path": "/spec/template/spec/containers/0/readinessProbe/httpGet/path", "value": "/ready"}
            ]'
          difficulty: 3
        - id: v6
          title: Fix Service Routing to Wrong Pods
          description: >-
            Users report that <code>frontend-svc</code> is sometimes returning responses from the admin panel instead
            of the user-facing app. Investigation shows:<br><br>
            <pre># kubectl get svc frontend-svc -o jsonpath='{.spec.selector}'
            {"tier":"frontend"}

            # kubectl get pods --show-labels -l tier=frontend
            NAME                      LABELS
            webapp-6f8c9-abc12        app=webapp,tier=frontend
            admin-panel-5d7e8-xyz99   app=admin,tier=frontend</pre><br>
            Identify the root cause and write the fix.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Service selecting by tier=frontend, matches both webapp and admin Pods"
              output: "Root cause: selector too broad. Fix: add app=webapp to the Service selector."
          hints:
            - title: "\U0001F914 Think about it"
              content: The Service selector only uses one label. Does it uniquely identify the intended Pods?
            - title: "\U0001F4A1 Hint"
              content: >-
                The selector <code>tier=frontend</code> matches both webapp and admin-panel Pods. The selector needs to
                be more specific.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Service selector: tier=frontend
                2. This matches BOTH webapp and admin-panel Pods
                3. Fix: add "app=webapp" to the selector
                4. Service will only route to webapp Pods</pre>
          solution: |-
            # Root cause: Service selector "tier=frontend" is too broad — it matches both webapp and admin Pods

            # Fix: add the "app" label to the Service selector for more specific targeting
            kubectl patch svc frontend-svc --type='merge' -p='{"spec":{"selector":{"app":"webapp","tier":"frontend"}}}'

            # Verify only webapp Pods are in the endpoints
            kubectl get endpoints frontend-svc
          difficulty: 2
        - id: v7
          title: Fix Service Session Affinity
          description: >-
            A stateful web application behind a Service loses user sessions on every request because traffic is
            load-balanced across different Pods. The application stores sessions in memory. Write the fix to enable
            session stickiness.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Stateful app losing sessions due to round-robin load balancing"
              output: "Root cause: no session affinity. Fix: enable sessionAffinity: ClientIP on the Service."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                By default, Services use round-robin. For session-based apps, you need requests from the same client to
                go to the same Pod.
            - title: "\U0001F4A1 Hint"
              content: >-
                Use <code>sessionAffinity: ClientIP</code> to route requests from the same IP to the same Pod. Or
                better yet, externalize sessions.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Service default: no session affinity (round-robin)
                2. App stores sessions in memory
                3. Fix: set sessionAffinity to ClientIP
                4. Long-term: externalize sessions to Redis</pre>
          solution: |-
            # Root cause: Service has no session affinity; each request may hit a different Pod

            # Fix: enable ClientIP session affinity
            kubectl patch svc <service-name> -p '{"spec":{"sessionAffinity":"ClientIP","sessionAffinityConfig":{"clientIP":{"timeoutSeconds":3600}}}}'

            # Verify
            kubectl get svc <service-name> -o yaml | grep -A3 sessionAffinity

            # Note: the better long-term fix is to externalize session storage (Redis, database)
            # so the app is stateless and works with any load-balancing strategy
          difficulty: 3
          annotations:
            - type: tip
              label: Session Management
              text: >-
                <code>sessionAffinity: ClientIP</code> is a quick fix but has limitations (NAT, shared IPs). For
                production, externalize sessions to Redis or a database so any Pod can serve any request.
    - id: challenge_3
      block: 2
      difficulty: 3
      concept: Multi-Layer Diagnosis
      variants:
        - id: v1
          title: Debug End-to-End Request Failure
          description: >-
            Users report a 502 Bad Gateway when accessing <code>https://app.example.com</code>. The stack includes
            an Ingress, a Service, and a Deployment. Walk through the full debugging process from Ingress to
            Pod.<br><br>
            <pre># kubectl get ingress app-ingress -o yaml (rules)
            rules:
            - host: app.example.com
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: app-svc
                      port:
                        number: 80

            # kubectl get svc app-svc
            NAME      TYPE        CLUSTER-IP     PORT(S)
            app-svc   ClusterIP   10.96.45.123   80/TCP

            # kubectl get endpoints app-svc
            NAME      ENDPOINTS
            app-svc   &lt;none&gt;</pre><br>
            The Service has no endpoints. Continue debugging to find and fix the root cause.
          functionSignature: "Full diagnosis and fix"
          testCases:
            - input: "502 Bad Gateway, Ingress -> Service -> no endpoints"
              output: "Trace: Ingress OK -> Service has no endpoints -> check selector -> label mismatch -> fix labels"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                A 502 means the Ingress controller could not get a response from the backend. Work backwards from the
                Ingress to find where the chain breaks.
            - title: "\U0001F4A1 Hint"
              content: >-
                The Service has no endpoints, meaning no Pods match its selector. Check the Service selector versus
                the Deployment Pod labels.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Ingress routes to app-svc:80 — OK
                2. Service app-svc has no endpoints — PROBLEM
                3. Check Service selector vs Pod labels
                4. Fix the mismatch
                5. Verify end-to-end</pre>
          solution: |-
            # Debugging chain: Ingress -> Service -> Endpoints -> Pods

            # Step 1: Ingress points to app-svc:80 — configuration looks correct
            kubectl get ingress app-ingress -o yaml

            # Step 2: Service has NO endpoints — this is why we get 502
            kubectl get endpoints app-svc

            # Step 3: Check the Service selector
            kubectl get svc app-svc -o jsonpath='{.spec.selector}'
            # Output: {"app":"webapp"}

            # Step 4: Check Pod labels
            kubectl get pods --show-labels
            # Output shows Pods have label "app=web-app" (not "webapp")

            # Step 5: Fix the label mismatch
            kubectl patch svc app-svc --type='merge' -p='{"spec":{"selector":{"app":"web-app"}}}'

            # Step 6: Verify endpoints are populated
            kubectl get endpoints app-svc

            # Step 7: Test end-to-end
            curl -H "Host: app.example.com" https://app.example.com
          difficulty: 3
          annotations:
            - type: tip
              label: Debug Methodology
              text: >-
                Always debug layer by layer from the external-facing component inward: Ingress -> Service -> Endpoints
                -> Pods -> Containers. At each layer, verify the connection to the next layer works.
        - id: v2
          title: Debug Partial Outage
          description: >-
            Some requests to <code>https://api.example.com/v2</code> return 200 OK, but others return 500 Internal
            Server Error. The Deployment has 3 replicas.<br><br>
            <pre># kubectl get pods
            NAME                   READY   STATUS    RESTARTS
            api-v2-6f8c9-abc12     1/1     Running   0
            api-v2-6f8c9-def34     1/1     Running   12
            api-v2-6f8c9-ghi56     1/1     Running   0

            # kubectl logs api-v2-6f8c9-def34
            ERROR: Cannot connect to database at db-svc:5432
            FATAL: connection refused</pre><br>
            All Pods are Running and Ready, but one Pod is constantly crashing and restarting. Diagnose the full issue.
          functionSignature: "Multi-layer diagnosis and fix"
          testCases:
            - input: "Intermittent 500s, 1 of 3 Pods has database connection errors and high restart count"
              output: "Root cause: one Pod cannot reach database. Investigate node networking, DNS, or NetworkPolicy."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                Two Pods work fine, but one does not. What could be different about that one Pod? Consider which node
                it runs on and network-level issues.
            - title: "\U0001F4A1 Hint"
              content: >-
                Check which node the failing Pod is on. The issue may be node-specific — a NetworkPolicy, a DNS
                problem on that node, or a node-level network issue.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Identify the failing Pod: def34 (12 restarts, DB connection error)
                2. Check which node it runs on: kubectl get pod -o wide
                3. Compare with working Pods' nodes
                4. Check node networking / DNS / NetworkPolicy
                5. Fix node issue or reschedule Pod</pre>
          solution: |-
            # Step 1: Identify the problematic Pod
            # api-v2-6f8c9-def34 has 12 restarts and DB connection errors

            # Step 2: Check which nodes each Pod is running on
            kubectl get pods -o wide
            # abc12 -> worker-1, def34 -> worker-3, ghi56 -> worker-2

            # Step 3: Check if worker-3 has issues
            kubectl describe node worker-3
            # Look for Conditions, network problems, taints

            # Step 4: Test DNS from the failing Pod
            kubectl exec api-v2-6f8c9-def34 -- nslookup db-svc
            # If DNS fails, check CoreDNS and node's DNS config

            # Step 5: Check if a NetworkPolicy is blocking egress from that node/namespace
            kubectl get networkpolicy -A

            # Step 6: If node is the issue, drain and fix it
            kubectl drain worker-3 --ignore-daemonsets --delete-emptydir-data
            # Fix the node's networking, then uncordon
            kubectl uncordon worker-3

            # Step 7: If NetworkPolicy is the issue, update it to allow DB access
            # kubectl edit networkpolicy <policy-name>
          difficulty: 3
        - id: v3
          title: Debug Deployment Stuck Rollout
          description: >-
            A Deployment rollout is stuck. The old Pods are still running and the new Pods are not becoming
            Ready.<br><br>
            <pre># kubectl rollout status deployment/webapp
            Waiting for deployment "webapp" rollout to finish: 1 out of 3 new replicas have been updated...

            # kubectl get pods
            NAME                      READY   STATUS             RESTARTS
            webapp-old-abc12          1/1     Running            0
            webapp-old-def34          1/1     Running            0
            webapp-old-ghi56          1/1     Running            0
            webapp-new-jkl78          0/1     ImagePullBackOff   0

            # kubectl describe pod webapp-new-jkl78
            Events:
              Warning  Failed   pull image "myregistry.io/webapp:v2.0": unauthorized</pre><br>
            Diagnose and fix the stuck rollout.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "Stuck rollout, new Pod in ImagePullBackOff, unauthorized registry"
              output: "Root cause: missing imagePullSecret for private registry. Fix: add Secret and reference it."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                The new Pod cannot pull the image because the registry requires authentication. The Deployment needs an
                imagePullSecret.
            - title: "\U0001F4A1 Hint"
              content: >-
                Create a Docker registry Secret and add it to the Deployment spec as an imagePullSecret. Then the
                rollout will continue.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. New Pod: ImagePullBackOff, "unauthorized"
                2. Private registry requires credentials
                3. Create imagePullSecret
                4. Add to Deployment spec
                5. Rollout resumes automatically</pre>
          solution: |-
            # Root cause: private registry requires authentication but no imagePullSecret is configured

            # Step 1: Create the registry Secret
            kubectl create secret docker-registry regcred \
              --docker-server=myregistry.io \
              --docker-username=<username> \
              --docker-password=<password>

            # Step 2: Add imagePullSecrets to the Deployment
            kubectl patch deployment webapp --type='json' -p='[
              {"op": "add", "path": "/spec/template/spec/imagePullSecrets", "value": [{"name": "regcred"}]}
            ]'

            # Step 3: The Deployment controller will create new Pods with the Secret
            # Monitor the rollout
            kubectl rollout status deployment/webapp

            # If rollout is stuck and you need to abort:
            # kubectl rollout undo deployment/webapp
          difficulty: 3
          annotations:
            - type: tip
              label: Registry Auth
              text: >-
                For production, attach imagePullSecrets to a ServiceAccount so all Pods in the namespace automatically
                have registry credentials: <code>kubectl patch serviceaccount default -p '{"imagePullSecrets":
                [{"name": "regcred"}]}'</code>
        - id: v4
          title: Debug Ingress TLS Misconfiguration
          description: >-
            Users see a TLS certificate error when accessing <code>https://secure.example.com</code>. The browser
            shows the certificate is for <code>*.default.svc.cluster.local</code> instead of
            <code>secure.example.com</code>.<br><br>
            <pre># kubectl get ingress secure-ingress -o yaml
            spec:
              tls:
              - hosts:
                - secure.example.com
                secretName: tls-secret
              rules:
              - host: secure.example.com
                http:
                  paths:
                  - path: /
                    pathType: Prefix
                    backend:
                      service:
                        name: secure-svc
                        port:
                          number: 443

            # kubectl get secret tls-secret -o jsonpath='{.data.tls\.crt}' | base64 -d | openssl x509 -text -noout
            Subject: CN = *.default.svc.cluster.local</pre><br>
            Diagnose and fix the issue.
          functionSignature: "Diagnosis and fix"
          testCases:
            - input: "TLS cert for wrong domain, Secret contains cluster-internal certificate"
              output: "Root cause: wrong certificate in Secret. Fix: replace with certificate for secure.example.com."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                The Ingress configuration is correct, but the TLS Secret contains the wrong certificate. The cert is
                for the internal cluster domain, not the external domain.
            - title: "\U0001F4A1 Hint"
              content: >-
                The TLS Secret needs to be replaced with a certificate that matches
                <code>secure.example.com</code>. Delete the old Secret and create a new one.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Ingress TLS config references tls-secret — correct
                2. tls-secret contains cert for *.default.svc.cluster.local — WRONG
                3. Need cert for secure.example.com
                4. Replace the Secret with the correct certificate</pre>
          solution: |-
            # Root cause: TLS Secret contains a certificate for the wrong domain
            # Certificate is for *.default.svc.cluster.local instead of secure.example.com

            # Step 1: Delete the incorrect Secret
            kubectl delete secret tls-secret

            # Step 2: Create a new TLS Secret with the correct certificate
            kubectl create secret tls tls-secret \
              --cert=path/to/secure.example.com.crt \
              --key=path/to/secure.example.com.key

            # Step 3: Verify the certificate
            kubectl get secret tls-secret -o jsonpath='{.data.tls\.crt}' | base64 -d | openssl x509 -subject -noout
            # Should show: subject=CN = secure.example.com

            # Step 4: Restart the Ingress controller to pick up the new cert (if needed)
            kubectl rollout restart deployment -n ingress-nginx ingress-nginx-controller

            # For automated cert management, consider using cert-manager with Let's Encrypt
          difficulty: 4
          annotations:
            - type: tip
              label: Cert Management
              text: >-
                Use cert-manager to automate TLS certificate provisioning and renewal. It integrates with Let's
                Encrypt and other CAs, and automatically creates and updates TLS Secrets for Ingress resources.
        - id: v5
          title: Debug Full Stack with NetworkPolicy
          description: >-
            After enabling NetworkPolicies in a namespace, the application stops working. The architecture is:
            Ingress -> frontend-svc -> frontend Pods -> api-svc -> api Pods -> db-svc -> db
            Pod.<br><br>
            <pre># kubectl get networkpolicy -n app
            NAME             POD-SELECTOR     AGE
            default-deny     &lt;none&gt;            5m

            # The default-deny policy:
            spec:
              podSelector: {}
              policyTypes:
              - Ingress
              - Egress</pre><br>
            The default-deny policy blocks all traffic. Write the NetworkPolicies needed to restore connectivity for
            the full request chain.
          functionSignature: "Full NetworkPolicy solution"
          testCases:
            - input: "Default-deny NetworkPolicy blocking all traffic in multi-tier app"
              output: "Create allow policies for each tier: ingress->frontend, frontend->api, api->db, and DNS egress"
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                With default-deny, you need explicit allow rules for every connection. Map out the full traffic flow
                and create a policy for each hop.
            - title: "\U0001F4A1 Hint"
              content: >-
                You need: (1) allow ingress to frontend from Ingress controller, (2) allow frontend to api, (3) allow
                api to db, (4) allow DNS egress for all Pods.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Map traffic: Ingress -> frontend -> api -> db
                2. Each hop needs an ingress AND egress rule
                3. Do not forget DNS (port 53) egress to kube-system
                4. Create a NetworkPolicy for each tier</pre>
          solution: |-
            # Allow DNS egress for all Pods (required for Service discovery)
            cat <<EOF | kubectl apply -f -
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-dns
              namespace: app
            spec:
              podSelector: {}
              policyTypes:
              - Egress
              egress:
              - to:
                - namespaceSelector: {}
                ports:
                - protocol: UDP
                  port: 53
                - protocol: TCP
                  port: 53
            EOF

            # Allow Ingress controller -> frontend Pods
            cat <<EOF | kubectl apply -f -
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-ingress-to-frontend
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: frontend
              policyTypes:
              - Ingress
              ingress:
              - from:
                - namespaceSelector:
                    matchLabels:
                      kubernetes.io/metadata.name: ingress-nginx
                ports:
                - port: 8080
            EOF

            # Allow frontend -> api
            cat <<EOF | kubectl apply -f -
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-frontend-to-api
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: api
              policyTypes:
              - Ingress
              ingress:
              - from:
                - podSelector:
                    matchLabels:
                      app: frontend
                ports:
                - port: 8080
            ---
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-frontend-egress-to-api
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: frontend
              policyTypes:
              - Egress
              egress:
              - to:
                - podSelector:
                    matchLabels:
                      app: api
                ports:
                - port: 8080
            EOF

            # Allow api -> db
            cat <<EOF | kubectl apply -f -
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-api-to-db
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: db
              policyTypes:
              - Ingress
              ingress:
              - from:
                - podSelector:
                    matchLabels:
                      app: api
                ports:
                - port: 5432
            ---
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-api-egress-to-db
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: api
              policyTypes:
              - Egress
              egress:
              - to:
                - podSelector:
                    matchLabels:
                      app: db
                ports:
                - port: 5432
            EOF
          difficulty: 4
          annotations:
            - type: tip
              label: NetworkPolicy Tips
              text: >-
                Always start with DNS egress when adding default-deny policies. Without DNS, Pods cannot resolve
                Service names. Test each policy incrementally rather than applying all at once.
        - id: v6
          title: Debug HPA Not Scaling
          description: >-
            A HorizontalPodAutoscaler is not scaling up despite high traffic. Investigation
            shows:<br><br>
            <pre># kubectl get hpa webapp-hpa
            NAME         REFERENCE           TARGETS         MINPODS  MAXPODS  REPLICAS
            webapp-hpa   Deployment/webapp    &lt;unknown&gt;/80%   2        10       2

            # kubectl describe hpa webapp-hpa
            Events:
              Warning  FailedGetResourceMetric  missing request for cpu</pre><br>
            The Deployment Pods do not have CPU resource requests set. Diagnose and fix the complete issue.
          functionSignature: "Multi-resource diagnosis and fix"
          testCases:
            - input: "HPA shows unknown/80% for CPU, Pods missing CPU requests"
              output: "Root cause: HPA needs CPU requests to calculate utilization percentage. Fix: add CPU requests to Deployment."
          hints:
            - title: "\U0001F914 Think about it"
              content: >-
                HPA calculates CPU utilization as a percentage of the Pod's CPU request. Without requests, it cannot
                compute the percentage.
            - title: "\U0001F4A1 Hint"
              content: >-
                Add CPU resource requests to the Deployment's container spec. The HPA will then be able to compare
                actual usage against the request to determine scaling.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. HPA shows <unknown>/80% — cannot read CPU metrics
                2. "missing request for cpu" — Pods have no CPU requests
                3. HPA needs requests to calculate percentage
                4. Fix: add CPU requests to the Deployment
                5. Verify HPA picks up metrics</pre>
          solution: |-
            # Root cause: HPA cannot calculate CPU utilization percentage because Pods have no CPU requests
            # HPA formula: utilization = (current usage / request) * 100%
            # Without requests, the denominator is undefined

            # Step 1: Also verify metrics-server is running
            kubectl get pods -n kube-system -l k8s-app=metrics-server

            # Step 2: Add CPU requests to the Deployment
            kubectl patch deployment webapp --type='json' -p='[
              {"op": "add", "path": "/spec/template/spec/containers/0/resources", "value": {
                "requests": {"cpu": "200m", "memory": "256Mi"},
                "limits": {"cpu": "1", "memory": "512Mi"}
              }}
            ]'

            # Step 3: Wait for Pods to restart with new resource specs
            kubectl rollout status deployment/webapp

            # Step 4: Verify HPA now shows metrics
            kubectl get hpa webapp-hpa
            # Should show actual percentage like "45%/80%" instead of "<unknown>/80%"
          difficulty: 3
          annotations:
            - type: tip
              label: HPA Requirements
              text: >-
                HPA requires: (1) metrics-server installed and running, (2) resource requests set on target Pods, (3)
                correct scaleTargetRef in the HPA spec. Without all three, autoscaling will not function.
        - id: v7
          title: Debug CronJob Never Running
          description: >-
            A CronJob is configured but has never created a Job. The cluster has been running for
            hours.<br><br>
            <pre># kubectl get cronjob cleanup
            NAME      SCHEDULE       SUSPEND   ACTIVE   LAST SCHEDULE   AGE
            cleanup   */5 * * *      True      0        &lt;none&gt;          3h

            # kubectl get jobs
            No resources found</pre><br>
            Additionally, when the CronJob is unsuspended, the Jobs it creates fail immediately:<br>
            <pre># kubectl get pods -l job-name
            NAME                   STATUS
            cleanup-28391-abc12    CreateContainerConfigError

            # kubectl describe pod cleanup-28391-abc12
            Events:
              Warning  Failed  secret "db-credentials" not found</pre><br>
            Diagnose and fix both issues.
          functionSignature: "Multi-issue diagnosis and fix"
          testCases:
            - input: "CronJob suspended and Jobs fail due to missing Secret"
              output: "Root cause: (1) CronJob is suspended, (2) missing Secret. Fix: create Secret and unsuspend."
          hints:
            - title: "\U0001F914 Think about it"
              content: There are two problems here. The CronJob does not run, AND when it does, the Pods fail.
            - title: "\U0001F4A1 Hint"
              content: >-
                First, the CronJob SUSPEND field is True — it will never create Jobs while suspended. Second, the Pods
                need a Secret that does not exist.
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. SUSPEND: True — CronJob is paused
                2. When unsuspended, Pods fail: missing Secret
                3. Fix both: create Secret, then unsuspend
                4. Verify next scheduled run works</pre>
          solution: |-
            # Two root causes:
            # 1. CronJob is suspended (SUSPEND: True)
            # 2. Jobs fail because Secret "db-credentials" is missing

            # Step 1: Create the missing Secret
            kubectl create secret generic db-credentials \
              --from-literal=DB_USER=cleanup_user \
              --from-literal=DB_PASS=secure_password \
              --from-literal=DB_HOST=db-svc.database.svc.cluster.local

            # Step 2: Unsuspend the CronJob
            kubectl patch cronjob cleanup -p '{"spec":{"suspend":false}}'

            # Step 3: Optionally trigger an immediate run to verify
            kubectl create job --from=cronjob/cleanup cleanup-test

            # Step 4: Verify the Job completes successfully
            kubectl get jobs
            kubectl logs job/cleanup-test
          difficulty: 4
