conceptLinks:
  ServiceAccounts: "#lesson-serviceaccounts"
  Roles & ClusterRoles: "#lesson-roles-and-clusterroles"
  RoleBindings: "#lesson-rolebindings-and-clusterrolebindings"
  Permission Testing: "#lesson-testing-permissions"
  Security Contexts: "#lesson-security-contexts"
  Pod Security Standards: "#lesson-pod-security-standards-pss"
  Network Policies: "#lesson-network-policies"
sharedContent: {}
variants:
  warmups:
    # ── Warmup 1: ServiceAccounts ──────────────────────────────────────────────
    - id: warmup_1
      concept: ServiceAccounts
      variants:
        - id: v1
          title: Create a ServiceAccount
          description: >-
            Write the YAML manifest to create a ServiceAccount named <code>app-sa</code> in the
            <code>default</code> namespace.
          hints:
            - "The apiVersion is <code>v1</code> and the kind is <code>ServiceAccount</code>."
            - "You only need <code>apiVersion</code>, <code>kind</code>, and <code>metadata</code> with <code>name</code> and <code>namespace</code>."
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: app-sa
              namespace: default
        - id: v2
          title: ServiceAccount in a Custom Namespace
          description: >-
            Write the YAML to create a ServiceAccount named <code>deploy-bot</code> in the
            <code>staging</code> namespace.
          hints:
            - "Set <code>namespace: staging</code> in the metadata."
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: deploy-bot
              namespace: staging
        - id: v3
          title: Assign a ServiceAccount to a Pod
          description: >-
            Write a Pod YAML named <code>worker</code> using the image <code>busybox:1.36</code> that
            runs as the <code>task-runner</code> ServiceAccount. The container should run
            <code>sleep 3600</code>.
          hints:
            - "Use <code>serviceAccountName</code> under <code>spec</code> (not inside the container)."
            - "The <code>command</code> field takes a list: <code>[\"sleep\", \"3600\"]</code>."
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: worker
            spec:
              serviceAccountName: task-runner
              containers:
              - name: worker
                image: busybox:1.36
                command: ["sleep", "3600"]
        - id: v4
          title: Disable Token Auto-Mounting on a Pod
          description: >-
            Write a Pod YAML named <code>no-api-pod</code> using image <code>nginx:1.25</code> and
            ServiceAccount <code>web-sa</code>. Disable the automatic mounting of the ServiceAccount token.
          hints:
            - "Set <code>automountServiceAccountToken: false</code> in the Pod spec."
            - "This prevents the token from being mounted at <code>/var/run/secrets/kubernetes.io/serviceaccount/</code>."
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: no-api-pod
            spec:
              serviceAccountName: web-sa
              automountServiceAccountToken: false
              containers:
              - name: web
                image: nginx:1.25
        - id: v5
          title: Disable Token Auto-Mounting on the ServiceAccount
          description: >-
            Write a ServiceAccount YAML named <code>batch-sa</code> in the <code>jobs</code> namespace
            that disables automatic token mounting for <strong>all Pods</strong> using it.
          hints:
            - "You can set <code>automountServiceAccountToken: false</code> directly on the ServiceAccount resource."
            - "When set on the ServiceAccount, it applies to every Pod using it unless the Pod overrides it."
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: batch-sa
              namespace: jobs
            automountServiceAccountToken: false
        - id: v6
          title: Pod with ServiceAccount and Labels
          description: >-
            Write a Pod YAML named <code>api-consumer</code> with label <code>app: consumer</code>, using
            image <code>curlimages/curl:8.5.0</code> and ServiceAccount <code>api-reader</code>. The
            container should run <code>sleep 3600</code>.
          hints:
            - "Labels go under <code>metadata.labels</code>."
            - "<code>serviceAccountName</code> goes under <code>spec</code>."
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: api-consumer
              labels:
                app: consumer
            spec:
              serviceAccountName: api-reader
              containers:
              - name: api-consumer
                image: curlimages/curl:8.5.0
                command: ["sleep", "3600"]
        - id: v7
          title: Create ServiceAccount Imperatively
          description: >-
            Write the <code>kubectl</code> command to create a ServiceAccount named
            <code>monitoring-sa</code> in the <code>observability</code> namespace.
          hints:
            - "Use <code>kubectl create serviceaccount</code>."
            - "Specify the namespace with <code>-n</code> or <code>--namespace</code>."
          solution: |-
            kubectl create serviceaccount monitoring-sa -n observability
        - id: v8
          title: Multiple ServiceAccounts per Namespace
          description: >-
            Write the YAML to create two ServiceAccounts in the <code>production</code> namespace:
            <code>frontend-sa</code> and <code>backend-sa</code>. Use a single YAML file with
            <code>---</code> separator.
          hints:
            - "Separate multiple resources in a single file with <code>---</code> on its own line."
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: frontend-sa
              namespace: production
            ---
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: backend-sa
              namespace: production
        - id: v9
          title: Verify Pod ServiceAccount
          description: >-
            Write the <code>kubectl</code> command to check which ServiceAccount the Pod named
            <code>my-app</code> is running as, using JSONPath output.
          hints:
            - "Use <code>kubectl get pod</code> with <code>-o jsonpath</code>."
            - "The ServiceAccount name is at <code>.spec.serviceAccountName</code>."
          solution: |-
            kubectl get pod my-app -o jsonpath='{.spec.serviceAccountName}'
        - id: v10
          title: Create a Short-Lived Token
          description: >-
            Write the <code>kubectl</code> command to create a token for ServiceAccount
            <code>ci-sa</code> in the <code>ci-cd</code> namespace that expires in 15 minutes.
          hints:
            - "Use <code>kubectl create token</code>."
            - "The <code>--duration</code> flag sets the expiration time."
          solution: |-
            kubectl create token ci-sa -n ci-cd --duration=15m
        - id: v11
          title: ServiceAccount with Image Pull Secret
          description: >-
            Write a ServiceAccount YAML named <code>registry-sa</code> in the <code>default</code>
            namespace that references an image pull secret named <code>my-registry-creds</code>.
          hints:
            - "Use the <code>imagePullSecrets</code> field on the ServiceAccount."
            - "This automatically adds the image pull secret to any Pod using this ServiceAccount."
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: registry-sa
              namespace: default
            imagePullSecrets:
            - name: my-registry-creds

    # ── Warmup 2: Roles & ClusterRoles ─────────────────────────────────────────
    - id: warmup_2
      concept: Roles & ClusterRoles
      variants:
        - id: v1
          title: Read-Only Pod Role
          description: >-
            Write a Role YAML named <code>pod-reader</code> in the <code>default</code> namespace that
            allows <code>get</code>, <code>list</code>, and <code>watch</code> on Pods.
          hints:
            - "Pods are in the core API group, which is represented as an empty string <code>\"\"</code>."
            - "The resource name is <code>pods</code> (lowercase, plural)."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: pod-reader
              namespace: default
            rules:
            - apiGroups: [""]
              resources: ["pods"]
              verbs: ["get", "list", "watch"]
        - id: v2
          title: Deployment Manager Role
          description: >-
            Write a Role YAML named <code>deployment-manager</code> in the <code>dev</code> namespace
            that allows full CRUD operations on Deployments.
          hints:
            - "Deployments are in the <code>apps</code> API group."
            - "Full CRUD verbs are: <code>get</code>, <code>list</code>, <code>watch</code>, <code>create</code>, <code>update</code>, <code>patch</code>, <code>delete</code>."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: deployment-manager
              namespace: dev
            rules:
            - apiGroups: ["apps"]
              resources: ["deployments"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        - id: v3
          title: Secret Reader Role
          description: >-
            Write a Role YAML named <code>secret-reader</code> in the <code>default</code> namespace
            that grants read-only access to Secrets.
          hints:
            - "Secrets are in the core API group (<code>\"\"</code>)."
            - "Read-only means <code>get</code> and <code>list</code> only."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: secret-reader
              namespace: default
            rules:
            - apiGroups: [""]
              resources: ["secrets"]
              verbs: ["get", "list"]
        - id: v4
          title: Multi-Resource Role
          description: >-
            Write a Role YAML named <code>app-operator</code> in the <code>production</code> namespace
            that allows reading Pods and ConfigMaps (core group), and managing Deployments (apps group).
          hints:
            - "You need two separate rules: one for the core API group and one for the <code>apps</code> group."
            - "You can list multiple resources in a single rule if they share the same API group."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: app-operator
              namespace: production
            rules:
            - apiGroups: [""]
              resources: ["pods", "configmaps"]
              verbs: ["get", "list", "watch"]
            - apiGroups: ["apps"]
              resources: ["deployments"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        - id: v5
          title: Pod Logs and Exec Role
          description: >-
            Write a Role YAML named <code>pod-debugger</code> in the <code>dev</code> namespace that
            allows reading Pods, viewing Pod logs, and exec-ing into Pods.
          hints:
            - "Pod logs are the sub-resource <code>pods/log</code>."
            - "Pod exec is the sub-resource <code>pods/exec</code>."
            - "Sub-resources use the <code>create</code> verb for exec."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: pod-debugger
              namespace: dev
            rules:
            - apiGroups: [""]
              resources: ["pods"]
              verbs: ["get", "list", "watch"]
            - apiGroups: [""]
              resources: ["pods/log"]
              verbs: ["get"]
            - apiGroups: [""]
              resources: ["pods/exec"]
              verbs: ["create"]
        - id: v6
          title: ClusterRole for Nodes
          description: >-
            Write a ClusterRole YAML named <code>node-viewer</code> that allows reading Nodes
            across the entire cluster.
          hints:
            - "ClusterRoles have no <code>namespace</code> field in metadata."
            - "Nodes are cluster-scoped resources in the core API group."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: node-viewer
            rules:
            - apiGroups: [""]
              resources: ["nodes"]
              verbs: ["get", "list", "watch"]
        - id: v7
          title: ClusterRole for Namespaces and PVs
          description: >-
            Write a ClusterRole YAML named <code>cluster-viewer</code> that allows reading Namespaces,
            Nodes, and PersistentVolumes.
          hints:
            - "All three are cluster-scoped resources in the core API group."
            - "List them all in a single rule under <code>resources</code>."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: cluster-viewer
            rules:
            - apiGroups: [""]
              resources: ["namespaces", "nodes", "persistentvolumes"]
              verbs: ["get", "list", "watch"]
        - id: v8
          title: Job Manager Role
          description: >-
            Write a Role YAML named <code>job-manager</code> in the <code>batch-jobs</code> namespace
            that allows full management of Jobs and CronJobs.
          hints:
            - "Jobs and CronJobs are in the <code>batch</code> API group."
            - "Use <code>resources: [\"jobs\", \"cronjobs\"]</code> in the same rule."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: job-manager
              namespace: batch-jobs
            rules:
            - apiGroups: ["batch"]
              resources: ["jobs", "cronjobs"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        - id: v9
          title: Service and Ingress Role
          description: >-
            Write a Role YAML named <code>network-manager</code> in the <code>web</code> namespace that
            allows managing Services (core group) and Ingresses (networking.k8s.io group).
          hints:
            - "Services are in the core API group (<code>\"\"</code>)."
            - "Ingresses are in <code>networking.k8s.io</code>."
            - "You need two separate rules for the different API groups."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: network-manager
              namespace: web
            rules:
            - apiGroups: [""]
              resources: ["services"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
            - apiGroups: ["networking.k8s.io"]
              resources: ["ingresses"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        - id: v10
          title: ConfigMap and Secret Manager Role
          description: >-
            Write a Role YAML named <code>config-manager</code> in the <code>default</code> namespace
            that allows full management of ConfigMaps and read-only access to Secrets.
          hints:
            - "Both ConfigMaps and Secrets are in the core API group."
            - "Use two separate rules since the verb sets differ."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: config-manager
              namespace: default
            rules:
            - apiGroups: [""]
              resources: ["configmaps"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
            - apiGroups: [""]
              resources: ["secrets"]
              verbs: ["get", "list"]
        - id: v11
          title: Role for Specific Resource Names
          description: >-
            Write a Role YAML named <code>release-config-reader</code> in the <code>production</code>
            namespace that allows reading only the ConfigMap named <code>release-config</code>.
          hints:
            - "Use the <code>resourceNames</code> field to restrict access to specific named resources."
            - "The <code>resourceNames</code> field is a list of resource names."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: release-config-reader
              namespace: production
            rules:
            - apiGroups: [""]
              resources: ["configmaps"]
              resourceNames: ["release-config"]
              verbs: ["get"]
        - id: v12
          title: ClusterRole for CRDs
          description: >-
            Write a ClusterRole YAML named <code>crd-viewer</code> that allows reading
            CustomResourceDefinitions.
          hints:
            - "CRDs are in the <code>apiextensions.k8s.io</code> API group."
            - "The resource name is <code>customresourcedefinitions</code>."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: crd-viewer
            rules:
            - apiGroups: ["apiextensions.k8s.io"]
              resources: ["customresourcedefinitions"]
              verbs: ["get", "list", "watch"]

    # ── Warmup 3: RoleBindings ─────────────────────────────────────────────────
    - id: warmup_3
      concept: RoleBindings
      variants:
        - id: v1
          title: Bind Role to a ServiceAccount
          description: >-
            Write a RoleBinding YAML named <code>read-pods-binding</code> in the <code>default</code>
            namespace that binds the Role <code>pod-reader</code> to the ServiceAccount
            <code>app-sa</code> in the <code>default</code> namespace.
          hints:
            - "The <code>roleRef</code> must specify <code>kind: Role</code>, <code>name</code>, and <code>apiGroup: rbac.authorization.k8s.io</code>."
            - "For ServiceAccount subjects, you must include the <code>namespace</code> field."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: read-pods-binding
              namespace: default
            subjects:
            - kind: ServiceAccount
              name: app-sa
              namespace: default
            roleRef:
              kind: Role
              name: pod-reader
              apiGroup: rbac.authorization.k8s.io
        - id: v2
          title: Bind Role to a User
          description: >-
            Write a RoleBinding YAML named <code>dev-deploy-binding</code> in the <code>dev</code>
            namespace that binds the Role <code>deployment-manager</code> to the user
            <code>alice</code>.
          hints:
            - "For User subjects, use <code>kind: User</code> and <code>apiGroup: rbac.authorization.k8s.io</code>."
            - "Users do not have a <code>namespace</code> field in the subject."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: dev-deploy-binding
              namespace: dev
            subjects:
            - kind: User
              name: alice
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: Role
              name: deployment-manager
              apiGroup: rbac.authorization.k8s.io
        - id: v3
          title: Bind Role to a Group
          description: >-
            Write a RoleBinding YAML named <code>team-view-binding</code> in the <code>staging</code>
            namespace that binds the ClusterRole <code>view</code> to the group
            <code>qa-team</code>.
          hints:
            - "A RoleBinding can reference a ClusterRole -- this scopes the ClusterRole's permissions to the binding's namespace."
            - "For Group subjects, use <code>kind: Group</code> and <code>apiGroup: rbac.authorization.k8s.io</code>."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: team-view-binding
              namespace: staging
            subjects:
            - kind: Group
              name: qa-team
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: ClusterRole
              name: view
              apiGroup: rbac.authorization.k8s.io
        - id: v4
          title: ClusterRoleBinding to a User
          description: >-
            Write a ClusterRoleBinding YAML named <code>admin-binding</code> that grants the
            <code>cluster-admin</code> ClusterRole to the user <code>jane</code>.
          hints:
            - "ClusterRoleBindings have no <code>namespace</code> in metadata."
            - "The <code>roleRef</code> must reference <code>kind: ClusterRole</code>."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: admin-binding
            subjects:
            - kind: User
              name: jane
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: ClusterRole
              name: cluster-admin
              apiGroup: rbac.authorization.k8s.io
        - id: v5
          title: ClusterRoleBinding to a ServiceAccount
          description: >-
            Write a ClusterRoleBinding YAML named <code>monitoring-binding</code> that grants the
            ClusterRole <code>cluster-viewer</code> to the ServiceAccount <code>prometheus-sa</code>
            in the <code>monitoring</code> namespace.
          hints:
            - "ServiceAccount subjects in a ClusterRoleBinding still need the <code>namespace</code> field."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: monitoring-binding
            subjects:
            - kind: ServiceAccount
              name: prometheus-sa
              namespace: monitoring
            roleRef:
              kind: ClusterRole
              name: cluster-viewer
              apiGroup: rbac.authorization.k8s.io
        - id: v6
          title: Bind ClusterRole via RoleBinding (Namespace Scoping)
          description: >-
            Write a RoleBinding YAML named <code>staging-edit</code> in the <code>staging</code>
            namespace that grants the built-in <code>edit</code> ClusterRole to the ServiceAccount
            <code>deploy-bot</code> in the <code>staging</code> namespace.
          hints:
            - "This is the ClusterRole + RoleBinding pattern -- it scopes cluster-wide permissions to a single namespace."
            - "The <code>roleRef.kind</code> should be <code>ClusterRole</code>, not <code>Role</code>."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: staging-edit
              namespace: staging
            subjects:
            - kind: ServiceAccount
              name: deploy-bot
              namespace: staging
            roleRef:
              kind: ClusterRole
              name: edit
              apiGroup: rbac.authorization.k8s.io
        - id: v7
          title: Multiple Subjects in a RoleBinding
          description: >-
            Write a RoleBinding YAML named <code>team-access</code> in the <code>dev</code> namespace
            that binds the Role <code>app-operator</code> to both the user <code>bob</code> and the
            ServiceAccount <code>ci-sa</code> in namespace <code>dev</code>.
          hints:
            - "The <code>subjects</code> field is a list -- you can add multiple entries."
            - "Each subject has its own <code>kind</code> and appropriate fields."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: team-access
              namespace: dev
            subjects:
            - kind: User
              name: bob
              apiGroup: rbac.authorization.k8s.io
            - kind: ServiceAccount
              name: ci-sa
              namespace: dev
            roleRef:
              kind: Role
              name: app-operator
              apiGroup: rbac.authorization.k8s.io
        - id: v8
          title: Create RoleBinding Imperatively
          description: >-
            Write the <code>kubectl</code> command to create a RoleBinding named
            <code>view-pods</code> that binds the Role <code>pod-reader</code> to the ServiceAccount
            <code>default:app-sa</code> in the <code>default</code> namespace.
          hints:
            - "Use <code>kubectl create rolebinding</code>."
            - "ServiceAccount format is <code>--serviceaccount=namespace:name</code>."
          solution: |-
            kubectl create rolebinding view-pods --role=pod-reader --serviceaccount=default:app-sa --namespace=default
        - id: v9
          title: Create ClusterRoleBinding Imperatively
          description: >-
            Write the <code>kubectl</code> command to create a ClusterRoleBinding named
            <code>nodes-view</code> that binds the ClusterRole <code>node-viewer</code> to the group
            <code>ops-team</code>.
          hints:
            - "Use <code>kubectl create clusterrolebinding</code>."
            - "Use <code>--group</code> to specify a group subject."
          solution: |-
            kubectl create clusterrolebinding nodes-view --clusterrole=node-viewer --group=ops-team
        - id: v10
          title: RoleBinding with Cross-Namespace ServiceAccount
          description: >-
            Write a RoleBinding YAML named <code>cross-ns-read</code> in the <code>production</code>
            namespace that grants the Role <code>pod-reader</code> to the ServiceAccount
            <code>deploy-bot</code> from the <code>ci-cd</code> namespace.
          hints:
            - "The ServiceAccount subject's <code>namespace</code> can differ from the RoleBinding's namespace."
            - "This grants the <code>ci-cd</code> namespace's ServiceAccount access to <code>production</code> resources."
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: cross-ns-read
              namespace: production
            subjects:
            - kind: ServiceAccount
              name: deploy-bot
              namespace: ci-cd
            roleRef:
              kind: Role
              name: pod-reader
              apiGroup: rbac.authorization.k8s.io

    # ── Warmup 4: Permission Testing ──────────────────────────────────────────
    - id: warmup_4
      concept: Permission Testing
      variants:
        - id: v1
          title: Check Your Own Permission
          description: >-
            Write the <code>kubectl</code> command to check if you can create Deployments in the
            <code>default</code> namespace.
          hints:
            - "Use <code>kubectl auth can-i</code> followed by the verb and resource."
          solution: |-
            kubectl auth can-i create deployments
        - id: v2
          title: Check Permission in a Specific Namespace
          description: >-
            Write the <code>kubectl</code> command to check if you can delete Pods in the
            <code>production</code> namespace.
          hints:
            - "Add <code>--namespace=production</code> or <code>-n production</code> to target a specific namespace."
          solution: |-
            kubectl auth can-i delete pods --namespace=production
        - id: v3
          title: Impersonate a ServiceAccount
          description: >-
            Write the <code>kubectl</code> command to check if the ServiceAccount <code>app-sa</code>
            in the <code>default</code> namespace can list Pods.
          hints:
            - "Use <code>--as=system:serviceaccount:&lt;namespace&gt;:&lt;name&gt;</code> to impersonate a ServiceAccount."
            - "The prefix <code>system:serviceaccount:</code> is required."
          solution: |-
            kubectl auth can-i list pods --as=system:serviceaccount:default:app-sa
        - id: v4
          title: Impersonate a User
          description: >-
            Write the <code>kubectl</code> command to check if the user <code>alice</code> can create
            Deployments in the <code>dev</code> namespace.
          hints:
            - "Use <code>--as=alice</code> to impersonate a user (no prefix needed for users)."
          solution: |-
            kubectl auth can-i create deployments --as=alice --namespace=dev
        - id: v5
          title: Impersonate a Group
          description: >-
            Write the <code>kubectl</code> command to check if the group <code>dev-team</code> can
            get Secrets in the <code>staging</code> namespace.
          hints:
            - "Use <code>--as-group=dev-team</code> with a dummy <code>--as</code> value."
            - "You must provide <code>--as</code> when using <code>--as-group</code>."
          solution: |-
            kubectl auth can-i get secrets --as-group=dev-team --as=test-user --namespace=staging
        - id: v6
          title: List All Permissions
          description: >-
            Write the <code>kubectl</code> command to list all permissions that the ServiceAccount
            <code>deploy-bot</code> in the <code>staging</code> namespace has.
          hints:
            - "Use <code>kubectl auth can-i --list</code> combined with <code>--as</code>."
          solution: |-
            kubectl auth can-i --list --as=system:serviceaccount:staging:deploy-bot --namespace=staging
        - id: v7
          title: Check Permission on Cluster-Scoped Resource
          description: >-
            Write the <code>kubectl</code> command to check if the ServiceAccount
            <code>monitoring-sa</code> in the <code>monitoring</code> namespace can list Nodes.
          hints:
            - "Nodes are cluster-scoped, so no namespace is needed for the resource."
            - "You still need the full <code>system:serviceaccount:</code> prefix."
          solution: |-
            kubectl auth can-i list nodes --as=system:serviceaccount:monitoring:monitoring-sa
        - id: v8
          title: Check Sub-Resource Permission
          description: >-
            Write the <code>kubectl</code> command to check if the user <code>bob</code> can
            view Pod logs in the <code>dev</code> namespace.
          hints:
            - "Pod logs are accessed via the sub-resource <code>pods/log</code>."
            - "The verb for reading logs is <code>get</code>."
          solution: |-
            kubectl auth can-i get pods/log --as=bob --namespace=dev
        - id: v9
          title: Check Pod Exec Permission
          description: >-
            Write the <code>kubectl</code> command to check if the ServiceAccount
            <code>debug-sa</code> in the <code>dev</code> namespace can exec into Pods.
          hints:
            - "Pod exec uses the sub-resource <code>pods/exec</code> with the <code>create</code> verb."
          solution: |-
            kubectl auth can-i create pods/exec --as=system:serviceaccount:dev:debug-sa --namespace=dev
        - id: v10
          title: Check All Verbs on a Resource
          description: >-
            Write the <code>kubectl</code> command to check if you can perform <strong>any</strong>
            action (wildcard) on Deployments in the <code>production</code> namespace.
          hints:
            - "Use the wildcard verb <code>*</code> (with quotes) to check for all verbs."
          solution: |-
            kubectl auth can-i '*' deployments --namespace=production
        - id: v11
          title: Check Permission on Secrets as ServiceAccount
          description: >-
            Write the <code>kubectl</code> command to check if the ServiceAccount
            <code>backup-sa</code> in the <code>default</code> namespace can delete Secrets in the
            <code>production</code> namespace.
          hints:
            - "Combine <code>--as</code> for the ServiceAccount identity with <code>--namespace</code> for the target namespace."
          solution: |-
            kubectl auth can-i delete secrets --as=system:serviceaccount:default:backup-sa --namespace=production
        - id: v12
          title: List Permissions in All Namespaces
          description: >-
            Write the <code>kubectl</code> command to list all cluster-wide permissions for the user
            <code>jane</code>.
          hints:
            - "Use <code>kubectl auth can-i --list</code> with <code>--as</code> and no namespace flag to see cluster-scoped permissions."
          solution: |-
            kubectl auth can-i --list --as=jane

  challenges:
    # ── Challenge 1: RBAC Design ───────────────────────────────────────────────
    - id: challenge_1
      block: 1
      difficulty: 3
      concept: Roles & ClusterRoles
      variants:
        - id: v1
          title: "RBAC: Developer Read Access"
          description: >-
            A developer named <code>alice</code> needs to <strong>read Pods, Services, and
            Deployments</strong> in the <code>dev</code> namespace. Write the complete RBAC setup:
            a Role and a RoleBinding.
          functionSignature: "Role + RoleBinding"
          testCases:
            - input: "kubectl auth can-i get pods --as=alice -n dev"
              output: "yes"
            - input: "kubectl auth can-i list deployments --as=alice -n dev"
              output: "yes"
            - input: "kubectl auth can-i create pods --as=alice -n dev"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Which resources belong to which API groups? Pods and Services are core (\"\"), Deployments are in \"apps\"."
            - title: "\U0001F4A1 Hint"
              content: "You need two rules in the Role: one for the core API group (pods, services) and one for apps (deployments). Then a RoleBinding binding this Role to the User alice."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Role with two rules:
                   - apiGroups [""] -> pods, services -> get, list, watch
                   - apiGroups ["apps"] -> deployments -> get, list, watch
                2. RoleBinding: subject User alice, roleRef to the Role</pre>
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: dev-reader
              namespace: dev
            rules:
            - apiGroups: [""]
              resources: ["pods", "services"]
              verbs: ["get", "list", "watch"]
            - apiGroups: ["apps"]
              resources: ["deployments"]
              verbs: ["get", "list", "watch"]
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: alice-dev-reader
              namespace: dev
            subjects:
            - kind: User
              name: alice
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: Role
              name: dev-reader
              apiGroup: rbac.authorization.k8s.io
          difficulty: 2
        - id: v2
          title: "RBAC: CI/CD Pipeline ServiceAccount"
          description: >-
            A CI/CD pipeline ServiceAccount <code>ci-deployer</code> in the <code>ci-cd</code>
            namespace needs to <strong>create, update, and delete Deployments and Services</strong> in
            the <code>staging</code> namespace. It also needs to <strong>read Pods</strong> to verify
            rollouts. Write the complete RBAC setup.
          functionSignature: "ServiceAccount + Role + RoleBinding"
          testCases:
            - input: "kubectl auth can-i create deployments --as=system:serviceaccount:ci-cd:ci-deployer -n staging"
              output: "yes"
            - input: "kubectl auth can-i delete services --as=system:serviceaccount:ci-cd:ci-deployer -n staging"
              output: "yes"
            - input: "kubectl auth can-i delete pods --as=system:serviceaccount:ci-cd:ci-deployer -n staging"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "The ServiceAccount is in ci-cd but needs access in staging. The RoleBinding goes in the target namespace (staging) and the subject references the ServiceAccount from ci-cd."
            - title: "\U0001F4A1 Hint"
              content: "Create: 1) ServiceAccount in ci-cd, 2) Role in staging with deployment/service management + pod reading, 3) RoleBinding in staging with a cross-namespace subject."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. ServiceAccount in ci-cd namespace
                2. Role in staging:
                   - apps group: deployments -> full CRUD
                   - core group: services -> full CRUD
                   - core group: pods -> read only
                3. RoleBinding in staging:
                   - subject: SA ci-deployer from ci-cd namespace
                   - roleRef: the staging Role</pre>
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: ci-deployer
              namespace: ci-cd
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: deployer-role
              namespace: staging
            rules:
            - apiGroups: ["apps"]
              resources: ["deployments"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
            - apiGroups: [""]
              resources: ["services"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
            - apiGroups: [""]
              resources: ["pods"]
              verbs: ["get", "list", "watch"]
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: ci-deployer-binding
              namespace: staging
            subjects:
            - kind: ServiceAccount
              name: ci-deployer
              namespace: ci-cd
            roleRef:
              kind: Role
              name: deployer-role
              apiGroup: rbac.authorization.k8s.io
          difficulty: 3
        - id: v3
          title: "RBAC: Multi-Namespace Read with ClusterRole"
          description: >-
            The <code>ops-team</code> group needs <strong>read-only access to Pods, Deployments, and
            Services</strong> in both the <code>staging</code> and <code>production</code>
            namespaces. Use the ClusterRole + RoleBinding pattern to avoid duplicating the Role.
          functionSignature: "ClusterRole + 2 RoleBindings"
          testCases:
            - input: "kubectl auth can-i list pods --as-group=ops-team --as=user -n staging"
              output: "yes"
            - input: "kubectl auth can-i list pods --as-group=ops-team --as=user -n production"
              output: "yes"
            - input: "kubectl auth can-i create pods --as-group=ops-team --as=user -n staging"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Instead of creating the same Role in two namespaces, define permissions once as a ClusterRole and use RoleBindings to scope it per namespace."
            - title: "\U0001F4A1 Hint"
              content: "Create one ClusterRole with read rules, then two RoleBindings (one in staging, one in production) both referencing that ClusterRole with the Group subject."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. ClusterRole (no namespace):
                   - core: pods, services -> get, list, watch
                   - apps: deployments -> get, list, watch
                2. RoleBinding in staging -> ClusterRole, Group ops-team
                3. RoleBinding in production -> ClusterRole, Group ops-team</pre>
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: app-viewer
            rules:
            - apiGroups: [""]
              resources: ["pods", "services"]
              verbs: ["get", "list", "watch"]
            - apiGroups: ["apps"]
              resources: ["deployments"]
              verbs: ["get", "list", "watch"]
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: ops-staging-view
              namespace: staging
            subjects:
            - kind: Group
              name: ops-team
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: ClusterRole
              name: app-viewer
              apiGroup: rbac.authorization.k8s.io
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: ops-production-view
              namespace: production
            subjects:
            - kind: Group
              name: ops-team
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: ClusterRole
              name: app-viewer
              apiGroup: rbac.authorization.k8s.io
          difficulty: 3
        - id: v4
          title: "RBAC: Monitoring Stack Permissions"
          description: >-
            A monitoring ServiceAccount <code>prometheus-sa</code> in the <code>monitoring</code>
            namespace needs to <strong>read Pods, Endpoints, and Services across all
            namespaces</strong>, plus <strong>read Nodes</strong> (cluster-scoped). Write a ClusterRole
            and ClusterRoleBinding.
          functionSignature: "ServiceAccount + ClusterRole + ClusterRoleBinding"
          testCases:
            - input: "kubectl auth can-i list pods --as=system:serviceaccount:monitoring:prometheus-sa -n default"
              output: "yes"
            - input: "kubectl auth can-i list nodes --as=system:serviceaccount:monitoring:prometheus-sa"
              output: "yes"
            - input: "kubectl auth can-i delete pods --as=system:serviceaccount:monitoring:prometheus-sa -n default"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Since we need access across ALL namespaces plus cluster-scoped resources like Nodes, we need a ClusterRole with a ClusterRoleBinding (not a RoleBinding)."
            - title: "\U0001F4A1 Hint"
              content: "One ClusterRole with rules for pods, endpoints, services, and nodes. One ClusterRoleBinding granting it to the monitoring ServiceAccount."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. ServiceAccount in monitoring namespace
                2. ClusterRole:
                   - core: pods, endpoints, services -> get, list, watch
                   - core: nodes -> get, list, watch
                3. ClusterRoleBinding -> SA prometheus-sa from monitoring</pre>
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: prometheus-sa
              namespace: monitoring
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: prometheus-reader
            rules:
            - apiGroups: [""]
              resources: ["pods", "endpoints", "services"]
              verbs: ["get", "list", "watch"]
            - apiGroups: [""]
              resources: ["nodes"]
              verbs: ["get", "list", "watch"]
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: prometheus-reader-binding
            subjects:
            - kind: ServiceAccount
              name: prometheus-sa
              namespace: monitoring
            roleRef:
              kind: ClusterRole
              name: prometheus-reader
              apiGroup: rbac.authorization.k8s.io
          difficulty: 3
        - id: v5
          title: "RBAC: Namespace Admin"
          description: >-
            Create a complete RBAC setup where the user <code>team-lead</code> gets full admin access
            within the <code>team-alpha</code> namespace using the built-in <code>admin</code>
            ClusterRole. Also grant user <code>intern</code> read-only access using the built-in
            <code>view</code> ClusterRole in the same namespace.
          functionSignature: "2 RoleBindings"
          testCases:
            - input: "kubectl auth can-i '*' '*' --as=team-lead -n team-alpha"
              output: "yes (for namespaced resources)"
            - input: "kubectl auth can-i get pods --as=intern -n team-alpha"
              output: "yes"
            - input: "kubectl auth can-i create deployments --as=intern -n team-alpha"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "You can reuse the built-in ClusterRoles (admin, view) via RoleBindings. No need to create custom Roles."
            - title: "\U0001F4A1 Hint"
              content: "Two RoleBindings in team-alpha, each referencing a different built-in ClusterRole with different User subjects."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. RoleBinding: team-lead -> ClusterRole admin in team-alpha
                2. RoleBinding: intern -> ClusterRole view in team-alpha</pre>
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: team-lead-admin
              namespace: team-alpha
            subjects:
            - kind: User
              name: team-lead
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: ClusterRole
              name: admin
              apiGroup: rbac.authorization.k8s.io
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: intern-view
              namespace: team-alpha
            subjects:
            - kind: User
              name: intern
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: ClusterRole
              name: view
              apiGroup: rbac.authorization.k8s.io
          difficulty: 2
        - id: v6
          title: "RBAC: Debugging Role with Logs and Exec"
          description: >-
            A support engineer <code>charlie</code> needs to <strong>read Pods, view Pod logs, and
            exec into Pods</strong> in the <code>production</code> namespace -- but must NOT be able to
            create, update, or delete any resources. Write the Role and RoleBinding.
          functionSignature: "Role + RoleBinding"
          testCases:
            - input: "kubectl auth can-i get pods --as=charlie -n production"
              output: "yes"
            - input: "kubectl auth can-i get pods/log --as=charlie -n production"
              output: "yes"
            - input: "kubectl auth can-i create pods/exec --as=charlie -n production"
              output: "yes"
            - input: "kubectl auth can-i delete pods --as=charlie -n production"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Pod logs and exec are sub-resources. Logs use the verb \"get\" on \"pods/log\". Exec uses \"create\" on \"pods/exec\" (it creates an exec session)."
            - title: "\U0001F4A1 Hint"
              content: "Three rules in the Role: one for pods (get/list/watch), one for pods/log (get), one for pods/exec (create)."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Role with three rules:
                   - pods -> get, list, watch
                   - pods/log -> get
                   - pods/exec -> create
                2. RoleBinding: User charlie -> the Role</pre>
          solution: |-
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: pod-debugger
              namespace: production
            rules:
            - apiGroups: [""]
              resources: ["pods"]
              verbs: ["get", "list", "watch"]
            - apiGroups: [""]
              resources: ["pods/log"]
              verbs: ["get"]
            - apiGroups: [""]
              resources: ["pods/exec"]
              verbs: ["create"]
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: charlie-debugger
              namespace: production
            subjects:
            - kind: User
              name: charlie
              apiGroup: rbac.authorization.k8s.io
            roleRef:
              kind: Role
              name: pod-debugger
              apiGroup: rbac.authorization.k8s.io
          difficulty: 2
        - id: v7
          title: "RBAC: Full Application Stack"
          description: >-
            An application team needs a ServiceAccount <code>app-deployer</code> in the
            <code>app</code> namespace with the following permissions in that namespace:
            <strong>full management of Deployments and StatefulSets</strong> (apps group),
            <strong>full management of Services and ConfigMaps</strong> (core group),
            <strong>read-only access to Secrets</strong> (core group), and
            <strong>read-only access to Pods and Pod logs</strong>.
            Write the complete setup.
          functionSignature: "ServiceAccount + Role + RoleBinding"
          testCases:
            - input: "kubectl auth can-i create deployments --as=system:serviceaccount:app:app-deployer -n app"
              output: "yes"
            - input: "kubectl auth can-i get secrets --as=system:serviceaccount:app:app-deployer -n app"
              output: "yes"
            - input: "kubectl auth can-i delete secrets --as=system:serviceaccount:app:app-deployer -n app"
              output: "no"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Group resources by API group and verb set. Resources with the same verbs in the same API group can share a rule."
            - title: "\U0001F4A1 Hint"
              content: "You need rules for: apps group (deployments, statefulsets - full CRUD), core group (services, configmaps - full CRUD), core group (secrets - read only), core group (pods, pods/log - read only)."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. ServiceAccount in app namespace
                2. Role with rules:
                   - apps: deployments, statefulsets -> all verbs
                   - core: services, configmaps -> all verbs
                   - core: secrets -> get, list
                   - core: pods -> get, list, watch
                   - core: pods/log -> get
                3. RoleBinding tying them together</pre>
          solution: |-
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: app-deployer
              namespace: app
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: app-deployer-role
              namespace: app
            rules:
            - apiGroups: ["apps"]
              resources: ["deployments", "statefulsets"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
            - apiGroups: [""]
              resources: ["services", "configmaps"]
              verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
            - apiGroups: [""]
              resources: ["secrets"]
              verbs: ["get", "list"]
            - apiGroups: [""]
              resources: ["pods"]
              verbs: ["get", "list", "watch"]
            - apiGroups: [""]
              resources: ["pods/log"]
              verbs: ["get"]
            ---
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: app-deployer-binding
              namespace: app
            subjects:
            - kind: ServiceAccount
              name: app-deployer
              namespace: app
            roleRef:
              kind: Role
              name: app-deployer-role
              apiGroup: rbac.authorization.k8s.io
          difficulty: 4

    # ── Challenge 2: Security Context Hardening ────────────────────────────────
    - id: challenge_2
      block: 1
      difficulty: 2
      concept: Security Contexts
      variants:
        - id: v1
          title: "Basic Non-Root Pod"
          description: >-
            Write a Pod YAML named <code>secure-app</code> with image <code>nginx:1.25</code> that
            runs as a non-root user with UID <code>1000</code>.
          functionSignature: "Pod securityContext"
          testCases:
            - input: "kubectl exec secure-app -- id"
              output: "uid=1000"
            - input: "Container runs as root?"
              output: "no -- runAsNonRoot: true prevents it"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Which security context fields control the user a container runs as? Where do pod-level vs container-level settings go?"
            - title: "\U0001F4A1 Hint"
              content: "Set <code>runAsNonRoot: true</code> and <code>runAsUser: 1000</code> in the pod-level <code>securityContext</code>."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  securityContext:
                    runAsNonRoot: true
                    runAsUser: 1000</pre>
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: secure-app
            spec:
              securityContext:
                runAsNonRoot: true
                runAsUser: 1000
                runAsGroup: 1000
              containers:
              - name: app
                image: nginx:1.25
          difficulty: 1
        - id: v2
          title: "Read-Only Root Filesystem"
          description: >-
            Write a Pod YAML named <code>immutable-app</code> with image <code>python:3.12-slim</code>
            that has a read-only root filesystem. The container needs a writable <code>/tmp</code>
            directory. The container runs <code>sleep 3600</code>.
          functionSignature: "Pod securityContext + emptyDir"
          testCases:
            - input: "kubectl exec immutable-app -- touch /etc/test"
              output: "Read-only file system error"
            - input: "kubectl exec immutable-app -- touch /tmp/test"
              output: "succeeds (emptyDir is writable)"
          hints:
            - title: "\U0001F914 Think about it"
              content: "A read-only root filesystem blocks writes everywhere. How do you give the container a writable directory? Use a volume mount."
            - title: "\U0001F4A1 Hint"
              content: "Set <code>readOnlyRootFilesystem: true</code> in the container's securityContext. Mount an <code>emptyDir</code> volume at <code>/tmp</code>."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>containers:
                - securityContext:
                    readOnlyRootFilesystem: true
                  volumeMounts:
                  - name: tmp
                    mountPath: /tmp
                volumes:
                - name: tmp
                  emptyDir: {}</pre>
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: immutable-app
            spec:
              containers:
              - name: app
                image: python:3.12-slim
                command: ["sleep", "3600"]
                securityContext:
                  readOnlyRootFilesystem: true
                volumeMounts:
                - name: tmp
                  mountPath: /tmp
              volumes:
              - name: tmp
                emptyDir: {}
          difficulty: 1
        - id: v3
          title: "Drop All Capabilities"
          description: >-
            Write a Pod YAML named <code>minimal-app</code> with image <code>busybox:1.36</code> that
            drops all Linux capabilities and prevents privilege escalation. The container runs
            <code>sleep 3600</code>.
          functionSignature: "Pod securityContext with capabilities"
          testCases:
            - input: "Container has NET_RAW capability?"
              output: "no -- all capabilities are dropped"
            - input: "Container can escalate privileges?"
              output: "no -- allowPrivilegeEscalation is false"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Capabilities and privilege escalation are container-level settings, not pod-level."
            - title: "\U0001F4A1 Hint"
              content: "In the container's securityContext, set <code>capabilities.drop: [\"ALL\"]</code> and <code>allowPrivilegeEscalation: false</code>."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>containers:
                - securityContext:
                    allowPrivilegeEscalation: false
                    capabilities:
                      drop:
                      - ALL</pre>
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: minimal-app
            spec:
              containers:
              - name: app
                image: busybox:1.36
                command: ["sleep", "3600"]
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
          difficulty: 1
        - id: v4
          title: "Fully Hardened Production Pod"
          description: >-
            Write a fully hardened Pod YAML named <code>hardened-app</code> with image
            <code>myapp:v2</code> that satisfies the <strong>Restricted</strong> Pod Security Standard:
            non-root user (UID 10000, GID 10000), read-only root filesystem, all capabilities
            dropped, no privilege escalation, RuntimeDefault seccomp profile, writable
            <code>/tmp</code> and <code>/var/cache</code> directories.
          functionSignature: "Pod meeting Restricted PSS"
          testCases:
            - input: "Passes Restricted PSS enforcement?"
              output: "yes"
            - input: "kubectl exec hardened-app -- id"
              output: "uid=10000 gid=10000"
            - input: "kubectl exec hardened-app -- touch /etc/anything"
              output: "Read-only file system"
          hints:
            - title: "\U0001F914 Think about it"
              content: "The Restricted PSS requires: runAsNonRoot, drop ALL capabilities, no privilege escalation, and a seccomp profile. Read-only rootFS is best practice."
            - title: "\U0001F4A1 Hint"
              content: "Pod-level: runAsNonRoot, runAsUser, runAsGroup, fsGroup, seccompProfile. Container-level: readOnlyRootFilesystem, allowPrivilegeEscalation, capabilities.drop. Use emptyDir volumes for writable paths."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  securityContext: (pod-level settings)
                  containers:
                  - securityContext: (container-level settings)
                    volumeMounts: [/tmp, /var/cache]
                  volumes: [two emptyDir volumes]</pre>
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: hardened-app
            spec:
              securityContext:
                runAsNonRoot: true
                runAsUser: 10000
                runAsGroup: 10000
                fsGroup: 10000
                seccompProfile:
                  type: RuntimeDefault
              containers:
              - name: app
                image: myapp:v2
                securityContext:
                  allowPrivilegeEscalation: false
                  readOnlyRootFilesystem: true
                  capabilities:
                    drop:
                    - ALL
                volumeMounts:
                - name: tmp
                  mountPath: /tmp
                - name: cache
                  mountPath: /var/cache
              volumes:
              - name: tmp
                emptyDir: {}
              - name: cache
                emptyDir: {}
          difficulty: 3
        - id: v5
          title: "Security Context with Specific Capability"
          description: >-
            Write a Pod YAML named <code>web-server</code> with image <code>nginx:1.25</code> that
            drops all Linux capabilities but adds back <code>NET_BIND_SERVICE</code> (needed to
            bind to ports below 1024). Run as non-root user 101 (nginx user), with a read-only
            root filesystem and writable <code>/var/cache/nginx</code> and <code>/tmp</code>.
          functionSignature: "Pod with selective capabilities"
          testCases:
            - input: "Container can bind to port 80?"
              output: "yes -- NET_BIND_SERVICE is added"
            - input: "Container has SYS_ADMIN capability?"
              output: "no -- all dropped, only NET_BIND_SERVICE added back"
          hints:
            - title: "\U0001F914 Think about it"
              content: "The best practice is to drop ALL, then add back only what you need. The <code>capabilities.add</code> list works alongside <code>capabilities.drop</code>."
            - title: "\U0001F4A1 Hint"
              content: "In the container securityContext, use both <code>drop: [\"ALL\"]</code> and <code>add: [\"NET_BIND_SERVICE\"]</code> under capabilities."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>securityContext:
                  capabilities:
                    drop: ["ALL"]
                    add: ["NET_BIND_SERVICE"]</pre>
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: web-server
            spec:
              securityContext:
                runAsNonRoot: true
                runAsUser: 101
                runAsGroup: 101
                fsGroup: 101
              containers:
              - name: nginx
                image: nginx:1.25
                securityContext:
                  allowPrivilegeEscalation: false
                  readOnlyRootFilesystem: true
                  capabilities:
                    drop:
                    - ALL
                    add:
                    - NET_BIND_SERVICE
                volumeMounts:
                - name: cache
                  mountPath: /var/cache/nginx
                - name: tmp
                  mountPath: /tmp
              volumes:
              - name: cache
                emptyDir: {}
              - name: tmp
                emptyDir: {}
          difficulty: 2
        - id: v6
          title: "Restricted Namespace Setup"
          description: >-
            Write the YAML to create a Namespace named <code>secure-apps</code> with the
            <strong>Restricted</strong> Pod Security Standard enforced, audited, and warned. Then write
            a Pod named <code>compliant-pod</code> with image <code>myapp:v1</code> in that namespace
            that meets the Restricted standard.
          functionSignature: "Namespace labels + compliant Pod"
          testCases:
            - input: "Non-compliant pod deployed to secure-apps?"
              output: "rejected by admission controller"
            - input: "compliant-pod deployed successfully?"
              output: "yes -- meets all Restricted requirements"
          hints:
            - title: "\U0001F914 Think about it"
              content: "PSS enforcement is set via labels on the Namespace. The Pod must meet all Restricted requirements: non-root, drop ALL capabilities, no privilege escalation, seccomp profile."
            - title: "\U0001F4A1 Hint"
              content: "Namespace labels: <code>pod-security.kubernetes.io/enforce: restricted</code>, <code>pod-security.kubernetes.io/audit: restricted</code>, <code>pod-security.kubernetes.io/warn: restricted</code>."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>1. Namespace with PSS labels (enforce, audit, warn)
                2. Pod with:
                   - runAsNonRoot, runAsUser, seccompProfile (pod-level)
                   - allowPrivilegeEscalation: false, capabilities.drop: ALL (container-level)</pre>
          solution: |-
            apiVersion: v1
            kind: Namespace
            metadata:
              name: secure-apps
              labels:
                pod-security.kubernetes.io/enforce: restricted
                pod-security.kubernetes.io/enforce-version: latest
                pod-security.kubernetes.io/audit: restricted
                pod-security.kubernetes.io/warn: restricted
            ---
            apiVersion: v1
            kind: Pod
            metadata:
              name: compliant-pod
              namespace: secure-apps
            spec:
              securityContext:
                runAsNonRoot: true
                runAsUser: 1000
                runAsGroup: 1000
                seccompProfile:
                  type: RuntimeDefault
              containers:
              - name: app
                image: myapp:v1
                securityContext:
                  allowPrivilegeEscalation: false
                  capabilities:
                    drop:
                    - ALL
          difficulty: 3
        - id: v7
          title: "Multi-Container Hardened Pod"
          description: >-
            Write a Pod YAML named <code>app-with-sidecar</code> with two containers:
            <code>app</code> (image <code>myapp:v1</code>) and <code>log-shipper</code> (image
            <code>fluentbit:2.2</code>). Both must run as non-root (UID 1000), have read-only root
            filesystems, drop all capabilities, and prevent privilege escalation. The app needs
            a writable <code>/tmp</code>, and the log-shipper needs a writable <code>/var/log</code>.
            Both share a volume at <code>/var/log/app</code> (app writes, log-shipper reads).
          functionSignature: "Multi-container Pod with shared volume"
          testCases:
            - input: "Both containers run as non-root?"
              output: "yes -- pod-level runAsNonRoot: true"
            - input: "App can write to /var/log/app?"
              output: "yes -- shared emptyDir volume"
            - input: "Log-shipper can read /var/log/app?"
              output: "yes -- same shared volume"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Pod-level securityContext applies to all containers. Container-level settings handle readOnlyRootFilesystem and capabilities per container."
            - title: "\U0001F4A1 Hint"
              content: "Use three volumes: tmp (for app), var-log (for log-shipper), and shared-logs (mounted in both). Pod-level: runAsNonRoot, runAsUser, seccompProfile. Container-level: readOnly rootFS, drop ALL, no escalation."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  securityContext: (shared pod-level settings)
                  containers:
                  - name: app (volumeMounts: /tmp, /var/log/app)
                  - name: log-shipper (volumeMounts: /var/log, /var/log/app)
                  volumes: [tmp, var-log, shared-logs]</pre>
          solution: |-
            apiVersion: v1
            kind: Pod
            metadata:
              name: app-with-sidecar
            spec:
              securityContext:
                runAsNonRoot: true
                runAsUser: 1000
                runAsGroup: 1000
                fsGroup: 1000
                seccompProfile:
                  type: RuntimeDefault
              containers:
              - name: app
                image: myapp:v1
                securityContext:
                  allowPrivilegeEscalation: false
                  readOnlyRootFilesystem: true
                  capabilities:
                    drop:
                    - ALL
                volumeMounts:
                - name: tmp
                  mountPath: /tmp
                - name: shared-logs
                  mountPath: /var/log/app
              - name: log-shipper
                image: fluentbit:2.2
                securityContext:
                  allowPrivilegeEscalation: false
                  readOnlyRootFilesystem: true
                  capabilities:
                    drop:
                    - ALL
                volumeMounts:
                - name: var-log
                  mountPath: /var/log
                - name: shared-logs
                  mountPath: /var/log/app
                  readOnly: true
              volumes:
              - name: tmp
                emptyDir: {}
              - name: var-log
                emptyDir: {}
              - name: shared-logs
                emptyDir: {}
          difficulty: 3

    # ── Challenge 3: NetworkPolicy ─────────────────────────────────────────────
    - id: challenge_3
      block: 2
      difficulty: 3
      concept: Network Policies
      variants:
        - id: v1
          title: "Default Deny All Ingress"
          description: >-
            Write a NetworkPolicy YAML named <code>deny-all-ingress</code> in the
            <code>production</code> namespace that blocks all incoming traffic to every Pod.
          functionSignature: "NetworkPolicy deny-all"
          testCases:
            - input: "Any Pod in production receives traffic by default?"
              output: "no -- all ingress is denied"
            - input: "Egress traffic affected?"
              output: "no -- only Ingress policyType is set"
          hints:
            - title: "\U0001F914 Think about it"
              content: "An empty <code>podSelector: {}</code> matches ALL pods. Listing <code>Ingress</code> in policyTypes without any ingress rules means deny all ingress."
            - title: "\U0001F4A1 Hint"
              content: "The key is: <code>podSelector: {}</code> (match all), <code>policyTypes: [Ingress]</code>, and no <code>ingress</code> rules at all."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  podSelector: {}
                  policyTypes:
                  - Ingress
                  # no ingress rules = deny all</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: deny-all-ingress
              namespace: production
            spec:
              podSelector: {}
              policyTypes:
              - Ingress
          difficulty: 2
        - id: v2
          title: "Allow Frontend to Backend"
          description: >-
            Write a NetworkPolicy YAML named <code>allow-frontend</code> in the <code>default</code>
            namespace that allows Pods with label <code>app: frontend</code> to reach Pods with label
            <code>app: backend</code> on TCP port <code>8080</code>. All other ingress to the
            backend should be denied.
          functionSignature: "NetworkPolicy with podSelector"
          testCases:
            - input: "frontend (app=frontend) -> backend:8080"
              output: "allowed"
            - input: "random-pod -> backend:8080"
              output: "denied"
            - input: "frontend -> backend:3306"
              output: "denied (only port 8080 allowed)"
          hints:
            - title: "\U0001F914 Think about it"
              content: "The <code>podSelector</code> in spec selects which Pods this policy applies TO (the backend). The <code>from</code> in ingress rules specifies who CAN connect."
            - title: "\U0001F4A1 Hint"
              content: "Apply the policy to <code>app: backend</code> pods. Allow ingress from <code>app: frontend</code> pods on port 8080."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  podSelector:
                    matchLabels:
                      app: backend         # policy applies to these
                  ingress:
                  - from:
                    - podSelector:
                        matchLabels:
                          app: frontend    # traffic allowed from these
                    ports:
                    - port: 8080</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-frontend
              namespace: default
            spec:
              podSelector:
                matchLabels:
                  app: backend
              policyTypes:
              - Ingress
              ingress:
              - from:
                - podSelector:
                    matchLabels:
                      app: frontend
                ports:
                - protocol: TCP
                  port: 8080
          difficulty: 2
        - id: v3
          title: "Namespace Isolation"
          description: >-
            Write a NetworkPolicy YAML named <code>namespace-isolation</code> in the
            <code>team-alpha</code> namespace that only allows ingress from Pods in the same namespace
            (label <code>kubernetes.io/metadata.name: team-alpha</code> on the namespace). All traffic
            from other namespaces should be blocked.
          functionSignature: "NetworkPolicy with namespaceSelector"
          testCases:
            - input: "Pod in team-alpha -> Pod in team-alpha"
              output: "allowed"
            - input: "Pod in team-beta -> Pod in team-alpha"
              output: "denied"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Use a <code>namespaceSelector</code> in the ingress from clause to match only the current namespace. Kubernetes automatically adds the label <code>kubernetes.io/metadata.name</code> to namespaces."
            - title: "\U0001F4A1 Hint"
              content: "Apply to all pods (<code>podSelector: {}</code>). Allow ingress from pods in namespaces matching the <code>kubernetes.io/metadata.name: team-alpha</code> label."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  podSelector: {}
                  ingress:
                  - from:
                    - namespaceSelector:
                        matchLabels:
                          kubernetes.io/metadata.name: team-alpha</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: namespace-isolation
              namespace: team-alpha
            spec:
              podSelector: {}
              policyTypes:
              - Ingress
              ingress:
              - from:
                - namespaceSelector:
                    matchLabels:
                      kubernetes.io/metadata.name: team-alpha
          difficulty: 3
        - id: v4
          title: "Deny All Egress with DNS Exception"
          description: >-
            Write a NetworkPolicy YAML named <code>restrict-egress</code> in the <code>secure</code>
            namespace that denies all egress traffic from all Pods, except DNS queries (UDP and TCP
            port 53) to the <code>kube-dns</code> service.
          functionSignature: "NetworkPolicy egress with DNS"
          testCases:
            - input: "Pod can resolve DNS names?"
              output: "yes -- port 53 to kube-dns is allowed"
            - input: "Pod can connect to external HTTP?"
              output: "no -- all other egress is denied"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Without DNS, nothing works -- Pods cannot resolve Service names. You must allow port 53 (both UDP and TCP) to kube-dns when denying egress."
            - title: "\U0001F4A1 Hint"
              content: "Set <code>policyTypes: [Egress]</code> and add one egress rule allowing traffic to kube-dns pods (label <code>k8s-app: kube-dns</code>) on port 53."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  podSelector: {}
                  policyTypes: [Egress]
                  egress:
                  - to:
                    - namespaceSelector: {}     # any namespace
                      podSelector:
                        matchLabels:
                          k8s-app: kube-dns
                    ports:
                    - protocol: UDP
                      port: 53
                    - protocol: TCP
                      port: 53</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: restrict-egress
              namespace: secure
            spec:
              podSelector: {}
              policyTypes:
              - Egress
              egress:
              - to:
                - namespaceSelector: {}
                  podSelector:
                    matchLabels:
                      k8s-app: kube-dns
                ports:
                - protocol: UDP
                  port: 53
                - protocol: TCP
                  port: 53
          difficulty: 3
        - id: v5
          title: "Three-Tier Application Policies"
          description: >-
            Write NetworkPolicies for a three-tier app in the <code>webapp</code> namespace. The tiers
            have labels <code>tier: frontend</code>, <code>tier: backend</code>, and <code>tier:
            database</code>. Rules: (1) Frontend accepts traffic from anywhere on port 80. (2) Backend
            only accepts traffic from frontend on port 3000. (3) Database only accepts traffic from
            backend on port 5432.
          functionSignature: "3 NetworkPolicies"
          testCases:
            - input: "External -> frontend:80"
              output: "allowed"
            - input: "frontend -> backend:3000"
              output: "allowed"
            - input: "frontend -> database:5432"
              output: "denied"
            - input: "backend -> database:5432"
              output: "allowed"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Each tier gets its own NetworkPolicy. The podSelector selects the tier, and the ingress rules specify who can connect. Start with the most restrictive (database) and work outward."
            - title: "\U0001F4A1 Hint"
              content: "Three policies: 1) frontend allows all ingress on port 80, 2) backend allows only tier=frontend on port 3000, 3) database allows only tier=backend on port 5432."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>Policy 1: podSelector tier=frontend, ingress from all on port 80
                Policy 2: podSelector tier=backend, ingress from tier=frontend on port 3000
                Policy 3: podSelector tier=database, ingress from tier=backend on port 5432</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: frontend-policy
              namespace: webapp
            spec:
              podSelector:
                matchLabels:
                  tier: frontend
              policyTypes:
              - Ingress
              ingress:
              - ports:
                - protocol: TCP
                  port: 80
            ---
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: backend-policy
              namespace: webapp
            spec:
              podSelector:
                matchLabels:
                  tier: backend
              policyTypes:
              - Ingress
              ingress:
              - from:
                - podSelector:
                    matchLabels:
                      tier: frontend
                ports:
                - protocol: TCP
                  port: 3000
            ---
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: database-policy
              namespace: webapp
            spec:
              podSelector:
                matchLabels:
                  tier: database
              policyTypes:
              - Ingress
              ingress:
              - from:
                - podSelector:
                    matchLabels:
                      tier: backend
                ports:
                - protocol: TCP
                  port: 5432
          difficulty: 4
        - id: v6
          title: "Allow Cross-Namespace Ingress"
          description: >-
            Write a NetworkPolicy YAML named <code>allow-monitoring</code> in the <code>app</code>
            namespace that allows Pods from the <code>monitoring</code> namespace (label
            <code>kubernetes.io/metadata.name: monitoring</code>) to scrape metrics from Pods labeled
            <code>app: api</code> on TCP port <code>9090</code>.
          functionSignature: "NetworkPolicy with namespaceSelector"
          testCases:
            - input: "monitoring namespace Pod -> app:api:9090"
              output: "allowed"
            - input: "other namespace Pod -> app:api:9090"
              output: "denied"
            - input: "monitoring namespace Pod -> app:api:8080"
              output: "denied (only port 9090)"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Use both <code>namespaceSelector</code> (to match the monitoring namespace) and <code>podSelector</code> in the same from entry. When combined in the same item, they form an AND condition."
            - title: "\U0001F4A1 Hint"
              content: "Apply the policy to <code>app: api</code> pods. Allow ingress from monitoring namespace on port 9090. Note: putting namespaceSelector and podSelector in the same list item means AND, separate items means OR."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>spec:
                  podSelector:
                    matchLabels:
                      app: api
                  ingress:
                  - from:
                    - namespaceSelector:
                        matchLabels:
                          kubernetes.io/metadata.name: monitoring
                    ports:
                    - port: 9090</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-monitoring
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: api
              policyTypes:
              - Ingress
              ingress:
              - from:
                - namespaceSelector:
                    matchLabels:
                      kubernetes.io/metadata.name: monitoring
                ports:
                - protocol: TCP
                  port: 9090
          difficulty: 3
        - id: v7
          title: "Full Lockdown with Selective Allow"
          description: >-
            Write NetworkPolicies for the <code>secure</code> namespace: (1) A default deny-all
            policy for both ingress and egress. (2) An allow policy that lets Pods labeled
            <code>app: web</code> receive ingress on port 443 from anywhere, and send egress to
            Pods labeled <code>app: api</code> on port 8080 plus DNS (port 53).
          functionSignature: "2 NetworkPolicies (deny-all + selective allow)"
          testCases:
            - input: "Random pod in secure namespace receives any traffic?"
              output: "denied by default policy"
            - input: "External -> web:443"
              output: "allowed"
            - input: "web -> api:8080"
              output: "allowed"
            - input: "web -> external:443"
              output: "denied"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Start with a deny-all for both Ingress and Egress. Then add a targeted policy for the web pods that allows specific ingress and egress."
            - title: "\U0001F4A1 Hint"
              content: "First policy: podSelector {} with policyTypes [Ingress, Egress] and no rules. Second policy: podSelector app=web with specific ingress (port 443) and egress (api:8080 + DNS:53) rules."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>Policy 1: deny-all (both directions)
                Policy 2: app=web allows:
                  ingress: any source on port 443
                  egress: app=api on port 8080
                  egress: DNS on port 53</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: deny-all
              namespace: secure
            spec:
              podSelector: {}
              policyTypes:
              - Ingress
              - Egress
            ---
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-web
              namespace: secure
            spec:
              podSelector:
                matchLabels:
                  app: web
              policyTypes:
              - Ingress
              - Egress
              ingress:
              - ports:
                - protocol: TCP
                  port: 443
              egress:
              - to:
                - podSelector:
                    matchLabels:
                      app: api
                ports:
                - protocol: TCP
                  port: 8080
              - to:
                - namespaceSelector: {}
                  podSelector:
                    matchLabels:
                      k8s-app: kube-dns
                ports:
                - protocol: UDP
                  port: 53
                - protocol: TCP
                  port: 53
          difficulty: 4
        - id: v8
          title: "Egress to External CIDR"
          description: >-
            Write a NetworkPolicy YAML named <code>allow-external-api</code> in the <code>app</code>
            namespace that allows Pods labeled <code>app: payment</code> to send egress traffic to
            the external IP range <code>203.0.113.0/24</code> on TCP port <code>443</code>, plus DNS.
            All other egress should be denied for these pods.
          functionSignature: "NetworkPolicy with ipBlock"
          testCases:
            - input: "payment pod -> 203.0.113.50:443"
              output: "allowed"
            - input: "payment pod -> 10.0.0.5:443"
              output: "denied"
            - input: "payment pod -> DNS"
              output: "allowed"
          hints:
            - title: "\U0001F914 Think about it"
              content: "Use <code>ipBlock</code> in the egress to clause to allow traffic to specific external IP ranges. This is useful for whitelisting external APIs."
            - title: "\U0001F4A1 Hint"
              content: "The <code>ipBlock</code> field takes a <code>cidr</code> and an optional <code>except</code> list. Combine it with port 443 in the egress rule. Add a second egress rule for DNS."
            - title: "\U0001F527 Pattern"
              content: |-
                <pre>egress:
                - to:
                  - ipBlock:
                      cidr: 203.0.113.0/24
                  ports:
                  - port: 443
                - to: (DNS rule)
                  ports: (port 53)</pre>
          solution: |-
            apiVersion: networking.k8s.io/v1
            kind: NetworkPolicy
            metadata:
              name: allow-external-api
              namespace: app
            spec:
              podSelector:
                matchLabels:
                  app: payment
              policyTypes:
              - Egress
              egress:
              - to:
                - ipBlock:
                    cidr: 203.0.113.0/24
                ports:
                - protocol: TCP
                  port: 443
              - to:
                - namespaceSelector: {}
                  podSelector:
                    matchLabels:
                      k8s-app: kube-dns
                ports:
                - protocol: UDP
                  port: 53
                - protocol: TCP
                  port: 53
          difficulty: 3
