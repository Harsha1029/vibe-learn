conceptLinks:
  Control Plane Components: "#the-control-plane"
  Data Plane Components: "#the-data-plane-worker-nodes"
  Component Inspection: "#exploring-your-clusters-components"
  Architecture Diagnosis: "#putting-it-all-together"
  Reconciliation Understanding: "#the-reconciliation-loop"
sharedContent: {}
variants:
  warmups:
    - id: warmup_1
      concept: Control Plane Components
      variants:
        - id: v1
          title: API Server Role
          description: >-
            What is the role of the <strong>kube-apiserver</strong> in a Kubernetes cluster? Name at least three things it
            does for every incoming request.
          hints:
            - It is the single entry point for all cluster interactions.
            - "Think about security steps: who are you, can you do this, is this valid?"
          solution: |-
            The API Server is the front door to the cluster. For every request it:
            1. Authenticates the request (verifies identity)
            2. Authorizes the request (checks RBAC permissions)
            3. Validates the request (ensures the object spec is well-formed)
            4. Persists the object to etcd
            5. Notifies watchers (other components) that something changed
          annotations:
            - type: pattern
              label: Single Entry Point
              text: >-
                Every interaction with the cluster goes through the API Server -- kubectl, the dashboard, CI/CD pipelines,
                and all other control plane components. No component talks directly to another.
        - id: v2
          title: etcd Purpose
          description: >-
            What does <strong>etcd</strong> store, and which component is the only one allowed to talk to it directly?
          hints:
            - Think of it as the cluster's database.
            - Only one control plane component reads from and writes to it.
          solution: |-
            etcd is a distributed key-value store that holds ALL cluster state:
            - All Kubernetes objects (Pods, Deployments, Services, ConfigMaps, Secrets)
            - Cluster configuration
            - RBAC policies
            - Lease and leader election data

            Only the API Server talks to etcd directly. No other component
            should read from or write to etcd.
          annotations:
            - type: gotcha
              label: Never Write Directly
              text: >-
                Never write to etcd directly. Direct writes bypass validation, admission controllers, and audit logging.
                Always go through the API Server.
        - id: v3
          title: Scheduler Function
          description: >-
            What does the <strong>kube-scheduler</strong> do? Describe its two-phase decision process.
          hints:
            - It watches for Pods that have no node assigned yet.
            - "Phase 1 eliminates unsuitable nodes. Phase 2 ranks the remaining ones."
          solution: |-
            The Scheduler watches for newly created Pods with no node assigned.
            Its two-phase process:
            1. Filtering -- eliminate nodes that can't run the Pod
               (insufficient CPU, wrong node selector, untolerated taints)
            2. Scoring -- rank remaining nodes
               (spread Pods evenly, prefer cached images, etc.)
            Then it binds the Pod to the highest-scoring node by writing
            spec.nodeName on the Pod object.
          annotations:
            - type: pattern
              label: Scheduler Only Decides
              text: >-
                The Scheduler only writes <code>spec.nodeName</code> on the Pod object. The kubelet on that node sees
                the assignment and does the actual work of starting containers.
        - id: v4
          title: Controller Manager Role
          description: >-
            What does the <strong>kube-controller-manager</strong> do? Name at least four controllers it runs.
          hints:
            - It runs dozens of control loops, each watching a specific resource type.
            - "Think about Deployments, ReplicaSets, Nodes, Jobs..."
          solution: |-
            The Controller Manager runs reconciliation loops (controllers) that
            watch resources and take action to make reality match desired state.

            Key controllers:
            - Deployment controller: watches Deployments, creates/updates ReplicaSets
            - ReplicaSet controller: watches ReplicaSets, creates/deletes Pods
            - Node controller: monitors node health, marks nodes NotReady
            - Job controller: creates Pods for Jobs, tracks completion
            - ServiceAccount controller: creates default ServiceAccounts
            - Namespace controller: cleans up resources when namespaces are deleted
          annotations:
            - type: pattern
              label: Independent Controllers
              text: >-
                Controllers don't talk to each other. Each one watches the API Server for changes to its resource type
                and acts independently.
        - id: v5
          title: Match Component to Function
          description: >-
            Match each control plane component to its function:<br>
            1. kube-apiserver<br>
            2. etcd<br>
            3. kube-scheduler<br>
            4. kube-controller-manager<br><br>
            A. Assigns unscheduled Pods to nodes<br>
            B. Stores all cluster state as key-value pairs<br>
            C. Authenticates, authorizes, and validates every API request<br>
            D. Runs reconciliation loops for Deployments, ReplicaSets, etc.
          hints:
            - The API Server is the front door for all requests.
            - etcd is the database.
          solution: |-
            1-C: kube-apiserver -- Authenticates, authorizes, and validates every API request
            2-B: etcd -- Stores all cluster state as key-value pairs
            3-A: kube-scheduler -- Assigns unscheduled Pods to nodes
            4-D: kube-controller-manager -- Runs reconciliation loops
        - id: v6
          title: API Server Statelessness
          description: >-
            The API Server is described as <strong>stateless</strong>. What does that mean, and how does it enable high
            availability?
          hints:
            - Where does the API Server store data? Not in itself.
            - "Think about running multiple replicas."
          solution: |-
            The API Server is stateless because it does not store any data
            itself -- it reads from and writes to etcd. This means you can
            run multiple API Server replicas behind a load balancer for high
            availability. They don't need to coordinate with each other
            because all state lives in etcd.
          annotations:
            - type: pattern
              label: Stateless Frontend
              text: >-
                Stateless components are easier to scale horizontally. The API Server delegates all persistence to etcd,
                which handles its own replication and consensus.
        - id: v7
          title: etcd Key Structure
          description: >-
            How does etcd organize Kubernetes objects internally? Give an example of what a key path might look like for a
            Pod named <code>nginx</code> in the <code>default</code> namespace.
          hints:
            - Keys look like filesystem paths.
            - "The pattern is: /registry/&lt;resource-type&gt;/&lt;namespace&gt;/&lt;name&gt;"
          solution: |-
            etcd stores objects with keys that resemble filesystem paths:
            /registry/pods/default/nginx

            Other examples:
            /registry/deployments/default/my-app
            /registry/services/default/my-service
            /registry/nodes/worker-1
        - id: v8
          title: Scheduler Pending Pod
          description: >-
            A Pod has been in <code>Pending</code> state for 10 minutes. You see the event: <code>0/3 nodes are available:
            3 Insufficient cpu</code>. Which component generated this event and what does it mean?
          hints:
            - Which component decides where Pods run?
            - The message says no node has enough CPU.
          solution: |-
            The kube-scheduler generated this event. It means:
            - The Scheduler tried to find a node for the Pod
            - It filtered all 3 nodes and none had enough CPU available
            - The Pod stays in Pending state until resources free up
              or a new node is added

            This is the number one reason Pods get stuck in Pending.
          annotations:
            - type: gotcha
              label: Pending Means No Node
              text: >-
                A Pending Pod usually means the Scheduler cannot find a suitable node. Check resource requests, node
                selectors, taints, and tolerations.
        - id: v9
          title: Controller Manager Chain
          description: >-
            When you create a Deployment with 3 replicas, which two controllers in the Controller Manager react, and in
            what order? What does each one create?
          hints:
            - The Deployment controller acts first.
            - The ReplicaSet controller acts second.
          solution: |-
            1. Deployment controller notices the new Deployment object
               and creates a ReplicaSet object.
            2. ReplicaSet controller notices the new ReplicaSet object
               and creates 3 Pod objects (one per replica).

            The controllers don't talk to each other. The Deployment
            controller creates a ReplicaSet, and the ReplicaSet controller
            independently notices it and creates Pods.
        - id: v10
          title: Which Component Talks to etcd?
          description: >-
            True or false: The Scheduler reads Pod assignments directly from etcd. Explain your answer.
          hints:
            - Remember the architecture rule about who talks to etcd.
            - Every arrow in the architecture diagram goes through one component.
          solution: |-
            False. The Scheduler does NOT read from etcd directly.

            Only the API Server talks to etcd. The Scheduler watches the
            API Server for unscheduled Pods (Pods with no spec.nodeName).
            When it makes a scheduling decision, it writes the node
            assignment back through the API Server, which then persists
            it to etcd.
        - id: v11
          title: Control Plane High Availability
          description: >-
            In production, how many control plane (master) nodes are typically run, and why that number?
          hints:
            - Think about consensus and fault tolerance.
            - "Odd numbers are preferred for distributed consensus."
          solution: |-
            In production, typically 3 control plane nodes are run.

            Three is the minimum for high availability because:
            - etcd uses the Raft consensus protocol, which requires a
              majority (quorum) to agree on writes
            - With 3 nodes, you can tolerate 1 failure and still have
              a majority (2 of 3)
            - With 2 nodes, losing 1 means no majority -- the cluster stalls
            - Some large clusters run 5 for extra fault tolerance
        - id: v12
          title: Component Communication Rule
          description: >-
            What is the single most important communication rule in Kubernetes cluster architecture? Why is it designed
            this way?
          hints:
            - Look at the architecture diagram. Where do all the arrows go?
            - Think about auditability and security.
          solution: |-
            Every component communicates through the API Server. No component
            talks directly to another. This is a deliberate design choice:

            - The API Server is the single source of truth
            - All requests are authenticated and authorized
            - All changes are validated and audited
            - Admission controllers can intercept any mutation
            - It simplifies the architecture -- components only need to
              know how to talk to the API Server
    - id: warmup_2
      concept: Data Plane Components
      variants:
        - id: v1
          title: kubelet Role
          description: >-
            What is the <strong>kubelet</strong> and what are its main responsibilities? Where does it run?
          hints:
            - It is an agent that runs on every node.
            - It bridges the Kubernetes API and the container runtime.
          solution: |-
            The kubelet is an agent that runs on every node (including
            control plane nodes). Its responsibilities:
            1. Watches the API Server for Pods assigned to its node
            2. Tells the container runtime to start/stop containers
            3. Monitors container health (liveness and readiness probes)
            4. Reports node status and Pod status back to the API Server
          annotations:
            - type: gotcha
              label: Not a Pod
              text: >-
                The kubelet is the only component that does not run as a Pod (in most setups). It runs as a system
                daemon (systemd service). It has to manage Pods, so it can't be a Pod itself.
        - id: v2
          title: kube-proxy Purpose
          description: >-
            What does <strong>kube-proxy</strong> do, and how does it run on each node?
          hints:
            - It manages network rules for Service routing.
            - It runs as a specific type of workload that ensures one instance per node.
          solution: |-
            kube-proxy runs on every node and manages network rules that
            allow Pods to communicate with Services. When you create a
            Service, kube-proxy ensures that traffic to the Service's
            ClusterIP gets routed to a healthy backend Pod.

            It runs as a DaemonSet (one Pod per node) in the kube-system
            namespace. It can operate in iptables mode (default), IPVS
            mode, or nftables mode.
          annotations:
            - type: pattern
              label: DaemonSet Pattern
              text: >-
                kube-proxy uses the DaemonSet pattern to guarantee exactly one instance per node. This is common for
                node-level networking and monitoring agents.
        - id: v3
          title: Container Runtime
          description: >-
            What is a container runtime in Kubernetes, and what interface does Kubernetes use to communicate with it?
            Name two common runtimes.
          hints:
            - Kubernetes does not run containers itself.
            - "The interface acronym is CRI."
          solution: |-
            The container runtime is the software that actually pulls images
            and runs containers. Kubernetes delegates to a runtime via the
            Container Runtime Interface (CRI).

            Common runtimes:
            - containerd -- the default in most clusters (Docker Desktop,
              kind, GKE, EKS)
            - CRI-O -- used in OpenShift and some bare-metal setups

            Docker Engine was removed as a runtime in K8s 1.24, but
            Docker-built images still work everywhere (they are OCI-compliant).
        - id: v4
          title: Data Plane Component Match
          description: >-
            Match each data plane component to its function:<br>
            1. kubelet<br>
            2. kube-proxy<br>
            3. container runtime (containerd)<br><br>
            A. Actually pulls images and runs containers<br>
            B. Manages network rules so Services route to Pods<br>
            C. Watches API Server for Pod assignments, manages containers via CRI
          hints:
            - The kubelet tells the runtime what to do, not the other way around.
            - kube-proxy handles Service networking, not container management.
          solution: |-
            1-C: kubelet -- Watches API Server for Pod assignments, manages containers via CRI
            2-B: kube-proxy -- Manages network rules so Services route to Pods
            3-A: container runtime -- Actually pulls images and runs containers
        - id: v5
          title: kubelet vs kube-proxy
          description: >-
            Both the kubelet and kube-proxy run on every node. How do they differ in what they manage and how they run?
          hints:
            - One manages Pods/containers, the other manages network rules.
            - One is a system daemon, the other is a DaemonSet Pod.
          solution: |-
            kubelet:
            - Manages Pods and containers on the node
            - Runs as a systemd service (NOT a Pod)
            - Talks to the container runtime via CRI
            - Reports node and Pod status to the API Server

            kube-proxy:
            - Manages network rules for Service routing
            - Runs as a DaemonSet Pod in kube-system
            - Programs iptables/IPVS rules on the node
            - Ensures ClusterIP traffic reaches backend Pods
        - id: v6
          title: Docker Removal Clarification
          description: >-
            In Kubernetes 1.24, "Docker was removed." What does this actually mean? Can you still use Docker-built images?
          hints:
            - Only a specific shim was removed.
            - Think about the OCI image standard.
          solution: |-
            Only the Docker Engine shim (dockershim) was removed. This means
            Kubernetes no longer uses Docker Engine as a container runtime.

            You can absolutely still use Docker-built images. Docker images
            are OCI-compliant, which means they work with containerd, CRI-O,
            and any other OCI-compatible runtime. Your Dockerfiles are fine.

            Most clusters already used containerd under Docker anyway, so
            the change was largely transparent.
          annotations:
            - type: gotcha
              label: Non-event for Most Users
              text: >-
                The "Docker removed" announcement caused panic in 2020, but it was a non-event. Only the runtime shim
                was removed. Docker-built images work everywhere.
        - id: v7
          title: Check Container Runtime
          description: >-
            What kubectl command shows you which container runtime your cluster is using?
          hints:
            - You need wide output from the nodes listing.
            - The CONTAINER-RUNTIME column appears in wide output.
          solution: |-
            kubectl get node -o wide

            This shows the CONTAINER-RUNTIME column, for example:
            containerd://1.6.22

            You can also see it in:
            kubectl describe node <node-name>
            Under "System Info" -> "Container Runtime Version"
        - id: v8
          title: kubelet Chicken-and-Egg
          description: >-
            Why does the kubelet run as a system daemon instead of as a Kubernetes Pod like kube-proxy?
          hints:
            - What manages Pods on a node?
            - What would happen if the Pod manager was itself a Pod?
          solution: |-
            The kubelet runs as a systemd service because it is responsible
            for managing Pods on the node. If the kubelet were a Pod:

            - What would start the kubelet Pod? (chicken-and-egg problem)
            - If the kubelet crashed, nothing would restart it
            - The kubelet needs to be running BEFORE any Pods can start

            It must be a system-level daemon so it can bootstrap and manage
            all other Pods on the node, including control plane static Pods.
        - id: v9
          title: Three Node Components
          description: >-
            Name the three components that run on every Kubernetes worker node and briefly state what each does in one
            sentence.
          hints:
            - "They handle: Pod management, networking, and container execution."
          solution: |-
            1. kubelet -- watches the API Server for Pods assigned to this
               node and tells the container runtime to start/stop containers
            2. kube-proxy -- manages iptables/IPVS rules so that Service
               ClusterIPs route traffic to healthy backend Pods
            3. container runtime (containerd/CRI-O) -- actually pulls
               container images and runs containers on the node
        - id: v10
          title: kube-proxy Modes
          description: >-
            kube-proxy can operate in three different modes. Name them and briefly describe the default mode.
          hints:
            - "The modes involve different Linux networking subsystems."
            - The default mode uses a well-known Linux firewall tool.
          solution: |-
            The three kube-proxy modes:
            1. iptables mode (default) -- programs iptables rules that
               DNAT (Destination NAT) traffic from Service ClusterIPs to
               actual Pod IPs. Simple and reliable.
            2. IPVS mode -- uses Linux IPVS (IP Virtual Server) for more
               efficient load balancing at scale. Better performance with
               thousands of Services.
            3. nftables mode (newer) -- uses nftables instead of iptables.
               Modern replacement for iptables mode.
        - id: v11
          title: Where Events Come From
          description: >-
            When you run <code>kubectl describe pod</code> and see events, the <code>From</code> column shows which
            component generated each event. Which data plane component generates the "Pulling image", "Created container",
            and "Started container" events?
          hints:
            - These are all container lifecycle events.
            - Only one component on the node talks to the container runtime.
          solution: |-
            The kubelet generates all three events:
            - "Pulling image" -- kubelet tells the runtime to pull the image
            - "Created container" -- kubelet tells the runtime to create the container
            - "Started container" -- kubelet tells the runtime to start it

            The From column shows "kubelet" for all container operations.
            The Scheduler shows as "default-scheduler" for scheduling events.
    - id: warmup_3
      concept: Component Inspection
      variants:
        - id: v1
          title: List Cluster Nodes
          description: >-
            What kubectl command lists all nodes in the cluster and shows their status (Ready/NotReady)?
          hints:
            - Nodes are a top-level resource, like Pods.
            - The basic get command shows STATUS.
          solution: |-
            kubectl get nodes

            Output shows:
            NAME             STATUS   ROLES           AGE   VERSION
            docker-desktop   Ready    control-plane   1h    v1.28.2
        - id: v2
          title: List Control Plane Pods
          description: >-
            What kubectl command lists all control plane component Pods? Which namespace are they in?
          hints:
            - Control plane Pods run in a special system namespace.
            - Use <code>-n</code> to specify the namespace.
          solution: |-
            kubectl get pods -n kube-system

            This shows the control plane Pods:
            etcd-<node>
            kube-apiserver-<node>
            kube-controller-manager-<node>
            kube-scheduler-<node>
            kube-proxy-<hash>
            coredns-<hash>
          annotations:
            - type: kubectl
              label: Namespace Flag
              text: >-
                The <code>-n kube-system</code> flag targets the kube-system namespace where control plane components
                run as static Pods.
        - id: v3
          title: Cluster Info Command
          description: >-
            What kubectl command gives you a quick overview of the cluster's control plane endpoints?
          hints:
            - "It is a two-word kubectl command: kubectl cluster-___."
          solution: |-
            kubectl cluster-info

            Output:
            Kubernetes control plane is running at https://127.0.0.1:6443
            CoreDNS is running at https://127.0.0.1:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
        - id: v4
          title: Describe a Node
          description: >-
            What kubectl command shows detailed information about a node, including its capacity, allocatable resources,
            container runtime version, and running Pods?
          hints:
            - "Use the describe verb instead of get."
            - You can describe a specific node by name.
          solution: |-
            kubectl describe node <node-name>

            # Example:
            kubectl describe node docker-desktop

            This shows:
            - System Info (OS, kernel, container runtime, kubelet version)
            - Capacity (total CPU, memory, pods)
            - Allocatable (available CPU, memory, pods)
            - Conditions (MemoryPressure, DiskPressure, Ready)
            - List of all Pods running on the node
          annotations:
            - type: kubectl
              label: Describe for Debug
              text: >-
                <code>kubectl describe node</code> is invaluable for debugging. It shows capacity, allocation,
                conditions, and all Pods on the node.
        - id: v5
          title: Check Container Runtime Version
          description: >-
            Using kubectl, how can you see which container runtime and version each node is using? Show the command.
          hints:
            - "You need the wide output format."
            - There is also a describe approach.
          solution: |-
            # Method 1: wide output
            kubectl get nodes -o wide

            # Shows CONTAINER-RUNTIME column, e.g. containerd://1.6.22

            # Method 2: describe
            kubectl describe node <node-name> | grep "Container Runtime"
            # Container Runtime Version: containerd://1.6.22
        - id: v6
          title: View Cluster Events
          description: >-
            What kubectl command shows cluster events in real time, sorted by creation time?
          hints:
            - Events are a resource you can get/watch.
            - Use <code>--sort-by</code> and <code>--watch</code> flags.
          solution: |-
            kubectl get events --sort-by=.metadata.creationTimestamp --watch

            This streams events as they happen:
            LAST SEEN   TYPE     REASON              OBJECT           MESSAGE
            0s          Normal   ScalingReplicaSet   deployment/web   Scaled up...
            0s          Normal   SuccessfulCreate    replicaset/...   Created pod...
            0s          Normal   Scheduled           pod/...          Assigned...
          annotations:
            - type: kubectl
              label: Event Ordering
              text: >-
                The default event ordering can be confusing. Always use
                <code>--sort-by=.metadata.creationTimestamp</code> for chronological order.
        - id: v7
          title: Inspect API Server Config
          description: >-
            How can you see the command-line flags the kube-apiserver was started with (like which etcd server it connects
            to)?
          hints:
            - The API Server runs as a Pod in kube-system.
            - Use describe to see its container command.
          solution: |-
            kubectl describe pod kube-apiserver-<node-name> -n kube-system

            Under Containers > kube-apiserver > Command, you'll see flags like:
            --etcd-servers=https://127.0.0.1:2379
            --secure-port=6443
            --service-cluster-ip-range=10.96.0.0/12
        - id: v8
          title: List API Resources
          description: >-
            What kubectl command lists all the resource types the API Server knows about, including their short names and
            API groups?
          hints:
            - "It is a two-word kubectl command: kubectl api-___."
            - The output includes SHORTNAMES, APIVERSION, and KIND columns.
          solution: |-
            kubectl api-resources

            Output:
            NAME           SHORTNAMES   APIVERSION   NAMESPACED   KIND
            pods           po           v1           true         Pod
            services       svc          v1           true         Service
            deployments    deploy       apps/v1      true         Deployment
            nodes          no           v1           false        Node
            ...
        - id: v9
          title: Watch Pods in Real Time
          description: >-
            What kubectl command watches Pods being created/updated in real time? How would you watch Pods specifically in
            the <code>kube-system</code> namespace?
          hints:
            - Use the <code>--watch</code> flag.
            - Combine with <code>-n</code> for namespace.
          solution: |-
            # Watch Pods in default namespace:
            kubectl get pods --watch

            # Watch Pods in kube-system namespace:
            kubectl get pods -n kube-system --watch

            The --watch flag keeps the command running and shows changes
            as they happen (STATUS changes, new Pods, deletions).
        - id: v10
          title: Verbose kubectl Output
          description: >-
            How can you see the actual HTTP requests kubectl sends to the API Server? What flag increases verbosity?
          hints:
            - "Use the <code>-v</code> flag with a number."
            - Higher numbers show more detail, including request/response bodies.
          solution: |-
            # See HTTP method and URL:
            kubectl get pods -v=6

            # See request and response headers:
            kubectl get pods -v=8

            # Example output at -v=6:
            # GET https://127.0.0.1:6443/api/v1/namespaces/default/pods 200 OK
          annotations:
            - type: kubectl
              label: Verbosity Levels
              text: >-
                <code>-v=6</code> shows HTTP method and URL. <code>-v=8</code> adds request/response bodies. Useful
                for understanding what kubectl actually does.
        - id: v11
          title: Component Statuses
          description: >-
            What command shows the health status of the scheduler, controller-manager, and etcd? Note any caveats about
            this command.
          hints:
            - "The command uses componentstatuses (or the short name cs)."
            - This resource is deprecated in newer Kubernetes versions.
          solution: |-
            kubectl get componentstatuses
            # or:
            kubectl get cs

            Output:
            NAME                 STATUS    MESSAGE   ERROR
            scheduler            Healthy   ok
            controller-manager   Healthy   ok
            etcd-0               Healthy   ok

            Caveat: componentstatuses is deprecated since v1.19. In newer
            clusters, use health endpoints or check Pod status in kube-system.
          annotations:
            - type: deprecated
              label: Deprecated Resource
              text: >-
                <code>componentstatuses</code> is deprecated. Modern clusters expose health via
                <code>/healthz</code> and <code>/livez</code> endpoints on each component.
        - id: v12
          title: Identify Component from Event
          description: >-
            You see this event:<br>
            <code>Normal  Scheduled  5s  default-scheduler  Successfully assigned default/nginx to worker-1</code><br>
            Which component generated it? What will happen next, and which component handles it?
          hints:
            - The <code>From</code> field tells you the source component.
            - After scheduling, the node's agent takes over.
          solution: |-
            The default-scheduler generated the "Scheduled" event.

            What happens next:
            1. The kubelet on worker-1 notices a Pod was assigned to it
               (by watching the API Server)
            2. The kubelet tells containerd to pull the image
            3. The kubelet tells containerd to create and start the container
            4. The kubelet reports Pod status back to the API Server

            You'd see follow-up events from "kubelet" like:
            Pulling, Pulled, Created, Started
  challenges:
    - id: challenge_1
      block: 1
      difficulty: 1
      concept: Architecture Diagnosis
      variants:
        - id: v1
          title: "Diagnosis: All Pods Pending"
          description: >-
            <strong>Symptom:</strong> You create a Deployment with 3 replicas. All Pods stay in <code>Pending</code>
            state. Running <code>kubectl describe pod</code> shows the event:<br>
            <code>0/3 nodes are available: 3 Insufficient memory</code>.<br><br>
            Which component is reporting this? What is the root cause, and how would you fix it?
          functionSignature: "kubectl describe pod / kubectl get events"
          testCases:
            - input: "3 Pods Pending, event: 0/3 nodes are available: 3 Insufficient memory"
              output: "Scheduler cannot find node with enough memory"
          hints:
            - title: "Think about it"
              content: Which component is responsible for assigning Pods to nodes?
            - title: "Hint"
              content: The event comes from the Scheduler. It filtered all nodes and none had enough memory.
            - title: "Pattern"
              content: >-
                <pre>1. Identify component: kube-scheduler
                2. Root cause: Pod requests more memory than any node has available
                3. Fix: reduce memory requests, add nodes, or free up resources</pre>
          solution: |-
            Component: kube-scheduler

            Root cause: The Pod's memory request exceeds available memory
            on all 3 nodes. The Scheduler's filtering phase eliminates
            every node.

            Fixes:
            1. Reduce the Pod's spec.containers[].resources.requests.memory
            2. Add a node with more memory to the cluster
            3. Free memory by deleting or scaling down other workloads
            4. Check if resource requests are realistic for the application

            Diagnostic commands:
            kubectl describe pod <pod-name>     # see events
            kubectl describe node <node-name>   # see Allocatable vs Allocated
          difficulty: 1
          annotations:
            - type: pattern
              label: Pending = Scheduler Issue
              text: >-
                Pods stuck in Pending almost always indicate a scheduling problem. Check resource requests, node
                selectors, taints, tolerations, and affinity rules.
        - id: v2
          title: "Diagnosis: ImagePullBackOff"
          description: >-
            <strong>Symptom:</strong> A Pod transitions from <code>Pending</code> to <code>ErrImagePull</code> and then
            <code>ImagePullBackOff</code>. The events show:<br>
            <code>Failed to pull image "nginx:99.99": rpc error: manifest unknown</code><br>
            <code>From: kubelet</code><br><br>
            Which component is reporting this? What is the root cause?
          functionSignature: "kubectl describe pod"
          testCases:
            - input: "Pod in ImagePullBackOff, event: Failed to pull image from kubelet"
              output: "kubelet cannot pull the specified image tag"
          hints:
            - title: "Think about it"
              content: Which component on the node actually pulls container images?
            - title: "Hint"
              content: The kubelet asked the container runtime to pull the image, and it failed.
            - title: "Pattern"
              content: >-
                <pre>1. Component: kubelet (via container runtime)
                2. The image tag "nginx:99.99" does not exist
                3. Fix: correct the image name/tag in the Pod spec</pre>
          solution: |-
            Component: kubelet (which delegates to the container runtime)

            Root cause: The image tag "nginx:99.99" does not exist in the
            container registry. The container runtime reports the failure
            back to the kubelet, which reports it to the API Server.

            The Pod was successfully scheduled (it got past the Scheduler)
            but failed at the container creation stage.

            Fix: correct the image reference in the Pod/Deployment spec:
            kubectl set image deployment/<name> <container>=nginx:1.25
          difficulty: 1
          annotations:
            - type: pattern
              label: ImagePullBackOff = Image or Registry Issue
              text: >-
                ImagePullBackOff means the kubelet (via the runtime) cannot pull the image. Check the image name, tag,
                registry authentication, and network connectivity.
        - id: v3
          title: "Diagnosis: Node NotReady"
          description: >-
            <strong>Symptom:</strong> One of three nodes shows <code>NotReady</code> status. Pods on that node are being
            evicted. Running <code>kubectl describe node worker-2</code> shows the condition:<br>
            <code>Ready: False -- KubeletNotReady: container runtime is down</code><br><br>
            Which component stopped responding? Which control plane component detected this? What happens to the Pods?
          functionSignature: "kubectl get nodes / kubectl describe node"
          testCases:
            - input: "Node NotReady, KubeletNotReady, container runtime is down"
              output: "kubelet reports runtime failure, Node controller evicts Pods"
          hints:
            - title: "Think about it"
              content: Which component reports node health? Which controller watches node status?
            - title: "Hint"
              content: The kubelet reports to the API Server. The Node controller in the Controller Manager watches node health.
            - title: "Pattern"
              content: >-
                <pre>1. Container runtime (containerd) crashed on worker-2
                2. kubelet detects runtime failure and reports NotReady
                3. Node controller (in Controller Manager) marks node NotReady
                4. After a grace period, Pods are evicted and rescheduled</pre>
          solution: |-
            Failed component: container runtime (containerd) on worker-2

            Detection chain:
            1. The kubelet on worker-2 detects the runtime is down
            2. The kubelet reports NotReady status to the API Server
            3. The Node controller (in kube-controller-manager) sees the
               node's Ready condition change to False
            4. After a grace period (~5 minutes), the Node controller
               marks Pods on that node for eviction
            5. The Scheduler places replacement Pods on healthy nodes

            Fix: SSH into worker-2 and restart containerd:
            sudo systemctl restart containerd
          difficulty: 2
          annotations:
            - type: pattern
              label: Node Controller Eviction
              text: >-
                The Node controller monitors heartbeats. If a node stops reporting, it marks it NotReady and eventually
                evicts Pods so they can be rescheduled on healthy nodes.
        - id: v4
          title: "Diagnosis: etcd Unreachable"
          description: >-
            <strong>Symptom:</strong> All kubectl commands fail with:<br>
            <code>Error from server: etcdserver: leader changed</code><br>
            Then shortly after, all commands return:<br>
            <code>The connection to the server was refused</code><br><br>
            What is happening? Why does losing etcd affect every operation?
          functionSignature: "kubectl (any command)"
          testCases:
            - input: "All kubectl commands fail, etcdserver: leader changed, then connection refused"
              output: "etcd is down, API Server cannot read/write state"
          hints:
            - title: "Think about it"
              content: What is etcd's role? What happens to the API Server without it?
            - title: "Hint"
              content: >-
                The API Server is the only component that talks to etcd. If etcd is down, the API Server
                cannot read or write any state.
            - title: "Pattern"
              content: >-
                <pre>1. etcd lost its leader (quorum failure)
                2. API Server cannot persist or read state
                3. All kubectl commands fail because they all go through the API Server
                4. Eventually the API Server itself may crash</pre>
          solution: |-
            Root cause: etcd is failing or has lost quorum.

            The sequence:
            1. "leader changed" -- etcd is having trouble electing a leader,
               indicating instability (maybe a node went down)
            2. "connection refused" -- the API Server itself may have crashed
               or is refusing connections because it cannot talk to etcd

            Why this breaks everything:
            - The API Server reads ALL state from etcd
            - Without etcd, the API Server cannot serve any request
            - Every kubectl command, every controller, the Scheduler -- they
              all depend on the API Server, which depends on etcd
            - etcd is the single most critical component in the cluster

            Recovery: restore etcd from backup, or fix the etcd cluster.
          difficulty: 2
          annotations:
            - type: gotcha
              label: etcd = Cluster State
              text: >-
                If etcd dies and you have no backup, your cluster state is gone. Always run etcd with regular backups
                and at least 3 members for production.
        - id: v5
          title: "Diagnosis: Pods Running But No Traffic"
          description: >-
            <strong>Symptom:</strong> You have a Deployment with 3 running Pods and a Service. The Pods show
            <code>Running</code> status but the Service gets no traffic. Running <code>kubectl get endpoints</code> shows
            the Service has 0 endpoints.<br>
            <code>kubectl get pods -n kube-system</code> shows the kube-proxy Pod is in
            <code>CrashLoopBackOff</code>.<br><br>
            Which component is failing and why does this cause the symptom?
          functionSignature: "kubectl get endpoints / kubectl get pods -n kube-system"
          testCases:
            - input: "Pods Running, Service has 0 endpoints, kube-proxy CrashLoopBackOff"
              output: "kube-proxy is down, Service routing rules are not being programmed"
          hints:
            - title: "Think about it"
              content: Which component creates the iptables/IPVS rules that route Service traffic to Pods?
            - title: "Hint"
              content: >-
                kube-proxy watches Services and Endpoints and programs network rules. Without it, Service ClusterIPs
                don't route to anywhere.
            - title: "Pattern"
              content: >-
                <pre>1. kube-proxy is crashing on this node
                2. Without kube-proxy, iptables rules for the Service are not created
                3. Traffic to the Service ClusterIP goes nowhere
                4. Note: the Endpoints controller (separate from kube-proxy) populates
                   the Endpoints resource, so 0 endpoints might also indicate a label
                   mismatch between the Service selector and Pod labels</pre>
          solution: |-
            Failing component: kube-proxy

            kube-proxy is responsible for programming iptables/IPVS rules that
            route traffic from Service ClusterIPs to backend Pod IPs. When it
            is in CrashLoopBackOff:
            - No routing rules are created for the Service
            - Traffic to the Service ClusterIP is dropped

            However, the 0 endpoints issue is actually a separate concern:
            Endpoints are populated by the Endpoints controller in the
            Controller Manager, not kube-proxy. Zero endpoints usually means
            the Service selector doesn't match the Pod labels.

            Debug steps:
            1. Fix kube-proxy: kubectl logs -n kube-system kube-proxy-<hash>
            2. Check labels: kubectl get pods --show-labels
            3. Check Service selector: kubectl describe svc <name>
          difficulty: 2
          annotations:
            - type: gotcha
              label: Endpoints vs kube-proxy
              text: >-
                Endpoints are populated by the Endpoints controller in the Controller Manager. kube-proxy reads
                Endpoints and programs routing rules. They are separate components.
        - id: v6
          title: "Diagnosis: Scheduler Down"
          description: >-
            <strong>Symptom:</strong> Existing Pods continue running fine. But when you create a new Deployment, all new
            Pods stay in <code>Pending</code> state forever. Events show no <code>Scheduled</code> event at all. Running
            <code>kubectl get pods -n kube-system</code> shows <code>kube-scheduler</code> is in
            <code>CrashLoopBackOff</code>.<br><br>
            Why do existing Pods keep running while new ones are stuck?
          functionSignature: "kubectl describe pod / kubectl get pods -n kube-system"
          testCases:
            - input: "New Pods stuck Pending, no Scheduled event, kube-scheduler CrashLoopBackOff"
              output: "Scheduler is down, cannot assign new Pods to nodes"
          hints:
            - title: "Think about it"
              content: What is the Scheduler's job? Does it affect already-running Pods?
            - title: "Hint"
              content: The Scheduler only assigns NEW Pods to nodes. Once a Pod is running, the kubelet manages it directly.
            - title: "Pattern"
              content: >-
                <pre>1. Scheduler is down -- cannot assign Pods to nodes
                2. Existing Pods already have spec.nodeName set
                3. The kubelet manages running Pods independently
                4. Controllers still create Pod objects, they just can't be scheduled</pre>
          solution: |-
            Failed component: kube-scheduler

            Why existing Pods keep running:
            - Existing Pods already have spec.nodeName assigned
            - The kubelet on each node independently manages its Pods
            - The kubelet doesn't need the Scheduler to keep containers running

            Why new Pods are stuck:
            - The Deployment controller creates Pod objects (this still works)
            - But no Scheduler is running to assign them to nodes
            - Pods without spec.nodeName stay in Pending forever
            - No "Scheduled" event appears because the Scheduler never ran

            Fix: investigate why the Scheduler crashed:
            kubectl logs -n kube-system kube-scheduler-<node>
          difficulty: 3
          annotations:
            - type: pattern
              label: Components Are Independent
              text: >-
                Each component has a specific role. The Scheduler being down does not affect running Pods because the
                kubelet manages them independently. This modularity limits the blast radius of failures.
        - id: v7
          title: "Diagnosis: Controller Manager Down"
          description: >-
            <strong>Symptom:</strong> You delete a Pod managed by a Deployment. Normally a replacement Pod appears within
            seconds. This time, no replacement Pod is created. Existing Pods keep running.
            <code>kube-controller-manager</code> is in <code>CrashLoopBackOff</code>.<br><br>
            Explain why no replacement Pod is created and what other features stop working.
          functionSignature: "kubectl get pods -n kube-system / kubectl describe deployment"
          testCases:
            - input: "Deleted Pod not replaced, controller-manager in CrashLoopBackOff"
              output: "ReplicaSet controller not running, no reconciliation"
          hints:
            - title: "Think about it"
              content: Which component watches the ReplicaSet and creates replacement Pods?
            - title: "Hint"
              content: >-
                The ReplicaSet controller (inside the Controller Manager) detects that actual < desired
                and creates new Pods. Without it, no reconciliation happens.
            - title: "Pattern"
              content: >-
                <pre>Without the Controller Manager:
                - No new Pods created when replicas drift
                - Deployments can't roll out updates
                - No node health monitoring
                - No namespace cleanup
                - No Job completion tracking</pre>
          solution: |-
            Failed component: kube-controller-manager

            No replacement Pod because:
            - The ReplicaSet controller (inside Controller Manager) is the
              component that notices "desired=3, actual=2" and creates a Pod
            - With Controller Manager down, no reconciliation loops run
            - The API Server still accepts the delete, but nothing reacts

            Other features that stop working:
            - Deployment rolling updates (Deployment controller)
            - Node health monitoring (Node controller)
            - Namespace cleanup on deletion (Namespace controller)
            - Job completion tracking (Job controller)
            - Default ServiceAccount creation (ServiceAccount controller)

            Existing Pods keep running because:
            - The kubelet manages them independently
            - They already have containers running on their nodes
          difficulty: 3
          annotations:
            - type: pattern
              label: Controller Manager = Reconciliation Engine
              text: >-
                The Controller Manager runs all reconciliation loops. Without it, the cluster becomes "read-only" --
                existing state persists but no new state is reconciled.
        - id: v8
          title: "Diagnosis: API Server Intermittent Failures"
          description: >-
            <strong>Symptom:</strong> kubectl commands sometimes work and sometimes fail with
            <code>connection refused</code>. When they work, responses are slow (5-10 seconds). The cluster has 3 control
            plane nodes. <code>kubectl get pods -n kube-system</code> (when it works) shows one API Server Pod is
            <code>Running</code> and two are in <code>CrashLoopBackOff</code>.<br><br>
            Explain the symptom pattern. Why do commands sometimes work?
          functionSignature: "kubectl get pods -n kube-system"
          testCases:
            - input: "Intermittent kubectl failures, 1/3 API Servers running, slow responses"
              output: "2 API Servers down, load balancer routes to surviving instance"
          hints:
            - title: "Think about it"
              content: >-
                How do multiple API Server replicas work behind a load balancer? What happens when the load balancer
                sends traffic to a crashed instance?
            - title: "Hint"
              content: >-
                The load balancer distributes requests across all 3 API Server IPs. Requests hitting crashed
                instances fail; requests hitting the surviving instance succeed.
            - title: "Pattern"
              content: >-
                <pre>1. Load balancer sends requests round-robin to 3 API Servers
                2. Two are crashed -- those requests get "connection refused"
                3. The surviving instance handles all successful requests
                4. It's overloaded, so responses are slow
                5. Fix: investigate and restart the crashed API Server Pods</pre>
          solution: |-
            Root cause: 2 of 3 API Server instances have crashed.

            Why intermittent failures:
            - A load balancer distributes kubectl requests across all 3
              API Server endpoints
            - ~2/3 of requests hit crashed instances -> "connection refused"
            - ~1/3 of requests hit the surviving instance -> slow but works
            - The surviving instance is overloaded handling all requests
              that would normally be split across 3, causing slow responses

            The API Server is stateless, so the one surviving instance
            can serve all requests -- it just can't handle the full load
            efficiently.

            Debug steps:
            1. Check API Server logs on the crashed instances
            2. Check if etcd is healthy (API Server depends on it)
            3. Check node resources on the control plane nodes
          difficulty: 3
    - id: challenge_2
      block: 1
      difficulty: 2
      concept: Reconciliation Understanding
      variants:
        - id: v1
          title: "Trace: kubectl apply Deployment"
          description: >-
            Trace the full lifecycle when you run <code>kubectl apply -f deployment.yaml</code> for a new Deployment with
            2 replicas. List every component involved in order, and what each one does.
          functionSignature: "kubectl apply -f deployment.yaml"
          testCases:
            - input: "kubectl apply -f deployment.yaml (2 replicas, new Deployment)"
              output: "API Server -> etcd -> Deployment ctrl -> ReplicaSet ctrl -> Scheduler -> kubelet"
          hints:
            - title: "Think about it"
              content: Start with kubectl. Where does the request go first? Then think about who reacts.
            - title: "Hint"
              content: >-
                The chain is: kubectl -> API Server -> etcd -> Deployment controller -> ReplicaSet controller
                -> Scheduler -> kubelet -> container runtime.
            - title: "Pattern"
              content: >-
                <pre>1. kubectl sends POST to API Server
                2. API Server validates & stores in etcd
                3. Deployment controller: creates ReplicaSet
                4. ReplicaSet controller: creates 2 Pods
                5. Scheduler: assigns each Pod to a node
                6. kubelet: pulls image, starts containers</pre>
          solution: |-
            Full trace of kubectl apply -f deployment.yaml:

            1. kubectl: sends HTTP POST to the API Server
               POST /apis/apps/v1/namespaces/default/deployments

            2. API Server:
               - Authenticates the request (who are you?)
               - Authorizes (can you create Deployments?)
               - Validates (is this a well-formed Deployment spec?)
               - Runs admission controllers
               - Persists the Deployment object to etcd
               - Notifies watchers

            3. Deployment controller (in Controller Manager):
               - Notices the new Deployment via its watch
               - Creates a ReplicaSet object via the API Server

            4. ReplicaSet controller (in Controller Manager):
               - Notices the new ReplicaSet via its watch
               - Creates 2 Pod objects (no spec.nodeName yet)

            5. Scheduler:
               - Notices 2 unscheduled Pods via its watch
               - Filters and scores nodes for each Pod
               - Writes spec.nodeName on each Pod

            6. kubelet (on each assigned node):
               - Notices a Pod assigned to its node
               - Tells container runtime to pull the image
               - Tells container runtime to create & start container
               - Reports Pod status back to API Server
          difficulty: 2
          annotations:
            - type: pattern
              label: Event-Driven Chain
              text: >-
                No component tells another what to do directly. Each watches the API Server and reacts to changes
                independently. This is a watch-based, event-driven architecture.
        - id: v2
          title: "Trace: Pod Deleted from Deployment"
          description: >-
            You have a Deployment with <code>replicas: 3</code> and all 3 Pods are running. You run
            <code>kubectl delete pod web-abc12</code>. Trace what happens step by step. Which controllers react and why?
          functionSignature: "kubectl delete pod"
          testCases:
            - input: "Delete 1 Pod from a Deployment with replicas: 3"
              output: "ReplicaSet controller detects actual=2 < desired=3, creates new Pod"
          hints:
            - title: "Think about it"
              content: When a Pod is deleted, which controller notices the replica count is wrong?
            - title: "Hint"
              content: >-
                The ReplicaSet controller watches Pod count. When actual (2) < desired (3), it creates a new Pod.
                Then the Scheduler and kubelet take over.
            - title: "Pattern"
              content: >-
                <pre>1. API Server deletes Pod from etcd
                2. kubelet on old node stops the container
                3. ReplicaSet controller: actual=2, desired=3 -> create Pod
                4. Scheduler: assigns new Pod to a node
                5. kubelet on new node: starts container</pre>
          solution: |-
            Step-by-step trace:

            1. kubectl sends DELETE request to API Server
            2. API Server marks Pod for deletion in etcd

            3. kubelet on the Pod's node:
               - Notices Pod is terminating
               - Sends SIGTERM to the container
               - After grace period, sends SIGKILL
               - Reports Pod terminated to API Server

            4. ReplicaSet controller:
               - Its reconciliation loop detects actual=2, desired=3
               - Creates a NEW Pod object via the API Server
               - (The Deployment controller does NOT react -- the
                 ReplicaSet is unchanged)

            5. Scheduler:
               - Notices the new unscheduled Pod
               - Assigns it to a node (could be same or different)

            6. kubelet on the assigned node:
               - Pulls image (if not cached)
               - Creates and starts the container
               - Reports Running status

            The whole process typically takes seconds.
          difficulty: 2
        - id: v3
          title: "Trace: Scale Up"
          description: >-
            You run <code>kubectl scale deployment web --replicas=5</code> (was 3). Which components are involved in
            getting from 3 to 5 running Pods? Does the Deployment controller react?
          functionSignature: "kubectl scale deployment"
          testCases:
            - input: "Scale Deployment from 3 to 5 replicas"
              output: "API Server updates Deployment, controllers create 2 new Pods, Scheduler assigns, kubelet starts"
          hints:
            - title: "Think about it"
              content: When replicas change on the Deployment, what object gets updated? Does the Deployment controller or the ReplicaSet controller create the Pods?
            - title: "Hint"
              content: >-
                kubectl scale updates the Deployment spec. The Deployment controller updates the ReplicaSet's replica
                count. The ReplicaSet controller creates the 2 new Pods.
            - title: "Pattern"
              content: >-
                <pre>1. API Server: updates Deployment replicas to 5 in etcd
                2. Deployment controller: updates ReplicaSet replicas to 5
                3. ReplicaSet controller: actual=3, desired=5 -> create 2 Pods
                4. Scheduler: assigns 2 new Pods to nodes
                5. kubelet: starts 2 new containers</pre>
          solution: |-
            Trace of kubectl scale deployment web --replicas=5:

            1. kubectl sends PATCH to API Server
               PATCH /apis/apps/v1/namespaces/default/deployments/web
               Body: {"spec":{"replicas":5}}

            2. API Server updates Deployment in etcd (replicas: 3 -> 5)

            3. Deployment controller:
               - YES, it reacts. It notices the Deployment changed.
               - Updates the existing ReplicaSet's replica count to 5

            4. ReplicaSet controller:
               - Notices ReplicaSet desired=5 but only 3 Pods exist
               - Creates 2 new Pod objects

            5. Scheduler:
               - Assigns each new Pod to a node

            6. kubelet (on assigned nodes):
               - Pulls image, creates containers, starts them
               - Reports Running status

            Both the Deployment AND ReplicaSet controllers react during
            a scale operation.
          difficulty: 2
        - id: v4
          title: "Trace: Image Update Rolling Deployment"
          description: >-
            You run <code>kubectl set image deployment/web nginx=nginx:1.26</code> (was 1.25). Trace the rolling update
            process. How many ReplicaSets are involved?
          functionSignature: "kubectl set image deployment"
          testCases:
            - input: "Update image from nginx:1.25 to nginx:1.26"
              output: "Deployment controller creates new ReplicaSet, scales up new and down old"
          hints:
            - title: "Think about it"
              content: An image change means the Pod template changed. Does the Deployment update the existing ReplicaSet or create a new one?
            - title: "Hint"
              content: >-
                The Deployment controller creates a NEW ReplicaSet for the new image. It scales up the new ReplicaSet
                and scales down the old one, one Pod at a time (rolling update).
            - title: "Pattern"
              content: >-
                <pre>1. API Server: updates Deployment template image to nginx:1.26
                2. Deployment controller: creates NEW ReplicaSet (nginx:1.26)
                3. Deployment controller: scales new RS up, old RS down
                4. For each new Pod: Scheduler assigns, kubelet starts
                5. Old ReplicaSet ends with 0 replicas (kept for rollback)</pre>
          solution: |-
            Trace of image update rolling deployment:

            1. kubectl sends PATCH to API Server
               Updates Deployment template image to nginx:1.26

            2. API Server persists the change to etcd

            3. Deployment controller:
               - Detects the Pod template changed (image is different)
               - Creates a NEW ReplicaSet with the nginx:1.26 template
               - Begins rolling update:
                 a. Scales new ReplicaSet to 1
                 b. Waits for new Pod to be Ready
                 c. Scales old ReplicaSet down by 1
                 d. Repeats until new RS has 3, old RS has 0

            4. For each new Pod:
               - ReplicaSet controller creates the Pod
               - Scheduler assigns it to a node
               - kubelet pulls nginx:1.26 and starts it

            TWO ReplicaSets are involved:
            - Old RS (nginx:1.25): scaled from 3 to 0
            - New RS (nginx:1.26): scaled from 0 to 3
            - The old RS is kept at 0 replicas for rollback history
          difficulty: 3
          annotations:
            - type: pattern
              label: Rolling Update Mechanics
              text: >-
                The Deployment controller manages rolling updates by creating a new ReplicaSet and gradually shifting
                replicas. The old ReplicaSet is kept for rollback capability.
        - id: v5
          title: "Reconciliation: Node Crash"
          description: >-
            A worker node running 5 Pods crashes at 3 AM. Nobody is awake. Describe the complete chain of events that
            Kubernetes executes automatically to recover. Include timing.
          functionSignature: "Automatic recovery"
          testCases:
            - input: "Worker node crash with 5 Pods"
              output: "Node controller detects failure, evicts Pods, controllers recreate on other nodes"
          hints:
            - title: "Think about it"
              content: How does Kubernetes detect a node is down? It's not instant.
            - title: "Hint"
              content: >-
                The kubelet sends heartbeats. The Node controller watches for missed heartbeats. After a grace period
                (~5 minutes), it evicts Pods. Then ReplicaSet controllers create replacements.
            - title: "Pattern"
              content: >-
                <pre>1. kubelet heartbeat stops (node crashed)
                2. Node controller waits ~40s, marks node Unknown
                3. After ~5min, Node controller marks Pods for eviction
                4. ReplicaSet controllers create replacement Pods
                5. Scheduler assigns them to healthy nodes
                6. kubelets start containers on new nodes</pre>
          solution: |-
            Automatic recovery chain after node crash:

            1. T+0: Node crashes. kubelet heartbeats stop arriving.

            2. T+40s: Node controller (in Controller Manager) notices
               missing heartbeats. Marks node condition to Unknown.

            3. T+5min: Node controller sets a pod-eviction taint on
               the node. Pods are marked for deletion.

            4. T+5min: For each evicted Pod that was managed by a controller:
               - ReplicaSet controllers notice actual < desired
               - They create replacement Pod objects via the API Server

               (Standalone Pods with no controller are gone forever)

            5. Scheduler assigns each new Pod to a healthy node.

            6. kubelets on healthy nodes pull images and start containers.

            Result: By T+7-10min, all managed workloads are running on
            the remaining nodes. No human intervention needed.

            This is why you never create standalone Pods -- always use
            Deployments so controllers can recreate them.
          difficulty: 3
          annotations:
            - type: pattern
              label: Self-healing
              text: >-
                This entire recovery happens without human intervention. The reconciliation loop at every level
                (Node controller, ReplicaSet controller, Scheduler, kubelet) works together to restore desired state.
        - id: v6
          title: "Reconciliation: Desired vs Actual State"
          description: >-
            A Deployment has <code>replicas: 5</code>. Currently there are 7 Pods running (someone manually
            created 2 extra Pods with matching labels). What happens, and which controller acts?
          functionSignature: "kubectl get pods"
          testCases:
            - input: "Deployment replicas: 5, but 7 Pods with matching labels exist"
              output: "ReplicaSet controller deletes 2 excess Pods to match desired=5"
          hints:
            - title: "Think about it"
              content: The reconciliation loop doesn't just scale up. It also scales down when actual > desired.
            - title: "Hint"
              content: >-
                The ReplicaSet controller counts Pods matching its selector. If it sees 7 but wants 5, it
                deletes 2 Pods to reconcile.
            - title: "Pattern"
              content: >-
                <pre>1. ReplicaSet controller runs reconciliation loop
                2. Counts Pods matching its label selector: actual=7
                3. Compares to desired: 5
                4. Deletes 2 excess Pods to reconcile
                5. Now actual=5, desired=5 -- no further action</pre>
          solution: |-
            The ReplicaSet controller handles this:

            1. ReplicaSet controller's reconciliation loop runs
            2. It queries the API Server for Pods matching its selector
            3. It counts 7 Pods but desired is 5
            4. It selects 2 Pods to delete (typically the newest ones)
            5. It sends DELETE requests to the API Server
            6. kubelets on those nodes terminate the containers
            7. Now actual=5, desired=5 -- reconciled

            Key insight: The reconciliation loop works both ways:
            - actual < desired -> create Pods
            - actual > desired -> delete Pods
            - actual == desired -> do nothing

            This is why manually creating Pods with labels matching a
            ReplicaSet selector can cause unexpected deletions.
          difficulty: 2
          annotations:
            - type: gotcha
              label: Label Selector Matching
              text: >-
                The ReplicaSet controller uses label selectors to find its Pods. Manually creating Pods with matching
                labels will be adopted (and potentially deleted) by the controller.
        - id: v7
          title: "Reconciliation: Multiple Controller Interaction"
          description: >-
            Explain why the Deployment controller and ReplicaSet controller are separate. What would be the problem if a
            single controller handled both Deployments and Pods directly?
          functionSignature: "Conceptual understanding"
          testCases:
            - input: "Why are Deployment and ReplicaSet controllers separate?"
              output: "Separation enables rolling updates, rollback history, and independent reconciliation"
          hints:
            - title: "Think about it"
              content: What does the ReplicaSet give you that a direct Deployment-to-Pod relationship wouldn't?
            - title: "Hint"
              content: >-
                Think about rolling updates. You need the old set of Pods AND the new set during a transition.
                Two ReplicaSets managed by the Deployment controller makes this possible.
            - title: "Pattern"
              content: >-
                <pre>Deployment -> manages ReplicaSets (one per revision)
                ReplicaSet -> manages Pods (one set of identical Pods)

                During rolling update:
                  Deployment manages OLD RS + NEW RS simultaneously
                  Each RS independently maintains its Pod count</pre>
          solution: |-
            Why they are separate:

            1. Rolling updates need two sets of Pods simultaneously:
               - Old ReplicaSet (scaling down)
               - New ReplicaSet (scaling up)
               If Deployment managed Pods directly, there would be no way
               to track which Pods belong to the old vs new template.

            2. Rollback history:
               - Each ReplicaSet represents a revision
               - Deployment keeps old ReplicaSets (at 0 replicas)
               - kubectl rollout undo simply scales the old RS back up
               - Without ReplicaSets, there is no rollback capability

            3. Independent reconciliation:
               - Deployment controller: "do I need a new ReplicaSet?"
               - ReplicaSet controller: "do I have the right Pod count?"
               - Each has a simpler, more focused responsibility

            4. Single Responsibility Principle:
               - Each controller does one thing well
               - Simpler to reason about, debug, and test
               - A bug in one controller doesn't break the other
          difficulty: 3
          annotations:
            - type: pattern
              label: Layered Controllers
              text: >-
                Kubernetes uses layered controllers where each layer manages the next: Deployment -> ReplicaSet -> Pod.
                This separation enables rolling updates, rollback, and simpler individual controllers.
